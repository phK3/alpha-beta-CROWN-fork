{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import schedulefree\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../auto_LiRPA/\")\n",
    "import auto_LiRPA\n",
    "from auto_LiRPA.operators.gurobi_maxpool_lp import compute_maxpool_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since solving a series of linear programs for every unstable MaxPool neuron takes a prohibitive amount of time, we want to learn a neural network to approximate the optimal value of the series of linear programs.\n",
    "\n",
    "Subsequently, we want to verify that network, so it can be used instead of the LPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    "To allow the NN to learn the LP solutions for globally valid parameters of\n",
    "- lower bounds\n",
    "- upper bounds and\n",
    "- slope values\n",
    "\n",
    "we **normalize the bounds** to $[0,1]$, s.t. the smallest lower bound gets mapped to $0$ and the largest upper bound gets mapped to $1$.\n",
    "Similarly, we restrict the allowable slope values to $[0,1]$ (**TODO**: Show that this is sufficient for MaxPool)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2x2 MaxPool\n",
    "\n",
    "We start with the easier case of lower dimensional MaxPool neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l =  tensor([[[[ 0.3786, -0.1183],\n",
      "          [-0.6204,  0.1453]]]])\n",
      "u =  tensor([[[[ 0.9778,  0.7224],\n",
      "          [-0.2365,  2.6166]]]])\n"
     ]
    }
   ],
   "source": [
    "# (batch, channels, w, h), we only look at a single neuron for now\n",
    "l = torch.randn(1, 1, 2, 2)\n",
    "u = torch.abs(torch.randn(1, 1, 2, 2)) + l\n",
    "alpha = torch.rand(1, 1, 2, 2)\n",
    "\n",
    "print(\"l = \", l)\n",
    "print(\"u = \", u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9637]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_maxpool_bias(l, u, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 188.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# now for a lot of neurons\n",
    "n_neurons = 100\n",
    "l = torch.randn(n_neurons, 1, 2, 2)\n",
    "u = torch.abs(torch.randn(n_neurons, 1, 2, 2)) + l\n",
    "alpha = torch.rand(n_neurons, 1, 2, 2)\n",
    "\n",
    "biases = compute_maxpool_bias(l, u, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmin = l.flatten(-2).min(dim=-1)[0]\n",
    "umax = u.flatten(-2).max(dim=-1)[0]\n",
    "\n",
    "lmin = lmin.unsqueeze(1)\n",
    "umax = umax.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_norm = (l.flatten(-2) - lmin) / (umax - lmin)\n",
    "u_norm = (u.flatten(-2) - lmin) / (umax - lmin)\n",
    "l_norm = l_norm.view(l.shape)\n",
    "u_norm = u_norm.view(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 207.94it/s]\n"
     ]
    }
   ],
   "source": [
    "biases_norm = compute_maxpool_bias(l_norm, u_norm, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases_unnorm = biases_norm.unsqueeze(1) * (umax - lmin) - (alpha.flatten(-2).sum(dim=-1) - 1).unsqueeze(1) * lmin\n",
    "biases_unnorm = biases_unnorm.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error falls within the `float32` range.\n",
    "\n",
    "So normalization seems to work :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.5367e-07)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(biases_unnorm - biases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization: Now in a Single Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bounds(l, u):\n",
    "    \"\"\"\n",
    "    Takes bounds tensors and normalizes them to [0, 1], s.t. smallest lower bound is mapped to 0\n",
    "    and largest upper bound is mapped to 1\n",
    "\n",
    "    args:\n",
    "        l (batch x channels x w x h) - concrete lower bounds\n",
    "        u (batch x channels x w x h) - concrete upper bounds\n",
    "\n",
    "    returns:\n",
    "        l_norm (batch x channels x w x h) - normalized concrete lower bounds\n",
    "        u_norm (batch x channels x w x h) - normalized concrete upper bounds\n",
    "    \"\"\"\n",
    "    lmin = l.flatten(-2).min(dim=-1)[0]\n",
    "    umax = u.flatten(-2).max(dim=-1)[0]\n",
    "    lmin = lmin.unsqueeze(1)\n",
    "    umax = umax.unsqueeze(1)\n",
    "\n",
    "    l_norm = (l.flatten(-2) - lmin) / (umax - lmin)\n",
    "    u_norm = (u.flatten(-2) - lmin) / (umax - lmin)\n",
    "    l_norm = l_norm.view(l.shape)\n",
    "    u_norm = u_norm.view(u.shape)\n",
    "\n",
    "    return l_norm, u_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_bias(l, u, alpha, bias):\n",
    "    \"\"\" \n",
    "    Converts biases obtained from the normalized problem to the biases for the unnormalized problem.\n",
    "\n",
    "    args:\n",
    "        l (batch x channels x w x h) - unnormalized concrete lower bounds\n",
    "        u (batch x channels x w x h) - unnormalized concrete upper bounds\n",
    "        alpha (batch x channels x w x h) - slope values\n",
    "        bias (batch x channels) - normalized bias values\n",
    "\n",
    "    returns:\n",
    "        bias_unnorm (batch x channels) - biases for unnormalized problem\n",
    "    \"\"\"\n",
    "    lmin = l.flatten(-2).min(dim=-1)[0]\n",
    "    umax = u.flatten(-2).max(dim=-1)[0]\n",
    "    lmin = lmin.unsqueeze(1)\n",
    "    umax = umax.unsqueeze(1)\n",
    "\n",
    "    biases_unnorm = bias.unsqueeze(1) * (umax - lmin) - (alpha.flatten(-2).sum(dim=-1) - 1).unsqueeze(1) * lmin\n",
    "    biases_unnorm = biases_unnorm.squeeze(1)\n",
    "\n",
    "    return biases_unnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n_neurons, h, w):\n",
    "    # since the normalized version suffices, just stick to that\n",
    "    x1 = torch.rand(n_neurons, 1, h, w)\n",
    "    x2 = torch.rand(n_neurons, 1, h, w)\n",
    "\n",
    "    l = torch.where(x1 <= x2, x1, x2)\n",
    "    u = torch.where(x1  > x2, x1, x2)\n",
    "\n",
    "    alpha = torch.rand(n_neurons, 1, h, w)\n",
    "\n",
    "    biases = compute_maxpool_bias(l, u, alpha)\n",
    "\n",
    "    return l, u, alpha, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dataset(n_neurons_train, n_neurons_val, h, w):\n",
    "    l, u, alpha, bias = create_dataset(n_neurons_train, h, w)\n",
    "    X = torch.cat((l, u, alpha), dim=1)\n",
    "    dataset_train = TensorDataset(X, bias)\n",
    "\n",
    "    l, u, alpha, bias = create_dataset(n_neurons_val, h, w)\n",
    "    X = torch.cat((l, u, alpha), dim=1)\n",
    "    dataset_val = TensorDataset(X, bias)\n",
    "\n",
    "    return dataset_train, dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [05:28<00:00, 152.25it/s]\n",
      "100%|██████████| 5000/5000 [00:32<00:00, 155.86it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_train = 50000\n",
    "n_val = 5000\n",
    "\n",
    "ds_train, ds_val = create_tensor_dataset(n_train, n_val, 2, 2)\n",
    "train_dataloader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(ds_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(net, train_dataloader, val_dataloader, patience=10, num_epochs=100, lossfun='mse', opt='adam'):\n",
    "    if lossfun == 'mse':\n",
    "        criterion = nn.MSELoss()\n",
    "    elif lossfun == 'mae':\n",
    "        criterion = nn.L1Loss()\n",
    "    else:\n",
    "        raise ValueError('Unknown loss function!')\n",
    "    \n",
    "    if opt == 'adam':\n",
    "        optimizer = optim.Adam(net.parameters())\n",
    "    elif opt == 'schedulefree':\n",
    "        optimizer = schedulefree.AdamWScheduleFree(net.parameters(), lr=0.0025)\n",
    "    else:\n",
    "        raise ValueError('Uknown optimizer!')\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    train_maes = []\n",
    "    val_losses = []\n",
    "    val_maes = []\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_cnt = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "\n",
    "        if opt == 'schedulefree':\n",
    "            optimizer.train()\n",
    "\n",
    "        train_loss = 0.\n",
    "        train_mae = 0.\n",
    "        for batch_X, batch_y in train_dataloader:\n",
    "            y_hat = net(batch_X)\n",
    "            loss = criterion(y_hat, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_mae += torch.abs(y_hat - batch_y).mean().item()\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_mae /= len(train_dataloader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_maes.append(train_mae)\n",
    "\n",
    "\n",
    "        net.eval()\n",
    "\n",
    "        if opt == 'schedulefree':\n",
    "            optimizer.eval()\n",
    "            \n",
    "        val_loss = 0\n",
    "        val_mae = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_dataloader:\n",
    "                y_hat = net(batch_X)\n",
    "                loss = criterion(y_hat, batch_y)\n",
    "                val_loss += loss.item()\n",
    "                val_mae += torch.abs(y_hat - batch_y).mean().item()\n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_mae /= len(val_dataloader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_maes.append(val_mae)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - train_loss: {train_loss:.4f}, val_loss: {val_loss:.4f}, train_mae: {train_mae:.4f}, val_mae: {val_mae:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stopping_cnt = 0\n",
    "            best_net_state = net.state_dict()\n",
    "        else:\n",
    "            early_stopping_cnt += 1\n",
    "            if early_stopping_cnt >= patience:\n",
    "                print(\"Stopping early (patience of {patience} reached)\")\n",
    "                break\n",
    "\n",
    "\n",
    "    print(\"Training completed\")\n",
    "    return train_losses, val_losses, train_maes, val_maes, best_net_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1x30 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net2x30 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), \n",
    "                              torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net3x30 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), \n",
    "                              torch.nn.ReLU(), torch.nn.Linear(30, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - train_loss: 0.0024, val_loss: 0.0027, train_mae: 0.0390, val_mae: 0.0414\n",
      "Epoch [2/1000] - train_loss: 0.0024, val_loss: 0.0024, train_mae: 0.0383, val_mae: 0.0386\n",
      "Epoch [3/1000] - train_loss: 0.0024, val_loss: 0.0023, train_mae: 0.0382, val_mae: 0.0376\n",
      "Epoch [4/1000] - train_loss: 0.0023, val_loss: 0.0023, train_mae: 0.0376, val_mae: 0.0376\n",
      "Epoch [5/1000] - train_loss: 0.0023, val_loss: 0.0023, train_mae: 0.0377, val_mae: 0.0379\n",
      "Epoch [6/1000] - train_loss: 0.0023, val_loss: 0.0022, train_mae: 0.0374, val_mae: 0.0364\n",
      "Epoch [7/1000] - train_loss: 0.0022, val_loss: 0.0022, train_mae: 0.0372, val_mae: 0.0364\n",
      "Epoch [8/1000] - train_loss: 0.0022, val_loss: 0.0023, train_mae: 0.0371, val_mae: 0.0372\n",
      "Epoch [9/1000] - train_loss: 0.0022, val_loss: 0.0022, train_mae: 0.0370, val_mae: 0.0368\n",
      "Epoch [10/1000] - train_loss: 0.0022, val_loss: 0.0024, train_mae: 0.0366, val_mae: 0.0389\n",
      "Epoch [11/1000] - train_loss: 0.0021, val_loss: 0.0022, train_mae: 0.0363, val_mae: 0.0366\n",
      "Epoch [12/1000] - train_loss: 0.0021, val_loss: 0.0021, train_mae: 0.0362, val_mae: 0.0359\n",
      "Epoch [13/1000] - train_loss: 0.0021, val_loss: 0.0021, train_mae: 0.0360, val_mae: 0.0361\n",
      "Epoch [14/1000] - train_loss: 0.0021, val_loss: 0.0020, train_mae: 0.0360, val_mae: 0.0349\n",
      "Epoch [15/1000] - train_loss: 0.0021, val_loss: 0.0021, train_mae: 0.0359, val_mae: 0.0366\n",
      "Epoch [16/1000] - train_loss: 0.0021, val_loss: 0.0020, train_mae: 0.0359, val_mae: 0.0355\n",
      "Epoch [17/1000] - train_loss: 0.0021, val_loss: 0.0020, train_mae: 0.0357, val_mae: 0.0350\n",
      "Epoch [18/1000] - train_loss: 0.0020, val_loss: 0.0021, train_mae: 0.0356, val_mae: 0.0367\n",
      "Epoch [19/1000] - train_loss: 0.0021, val_loss: 0.0021, train_mae: 0.0357, val_mae: 0.0350\n",
      "Epoch [20/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0356, val_mae: 0.0348\n",
      "Epoch [21/1000] - train_loss: 0.0020, val_loss: 0.0021, train_mae: 0.0354, val_mae: 0.0357\n",
      "Epoch [22/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0353, val_mae: 0.0356\n",
      "Epoch [23/1000] - train_loss: 0.0020, val_loss: 0.0022, train_mae: 0.0355, val_mae: 0.0367\n",
      "Epoch [24/1000] - train_loss: 0.0020, val_loss: 0.0022, train_mae: 0.0354, val_mae: 0.0380\n",
      "Epoch [25/1000] - train_loss: 0.0020, val_loss: 0.0021, train_mae: 0.0354, val_mae: 0.0360\n",
      "Epoch [26/1000] - train_loss: 0.0020, val_loss: 0.0022, train_mae: 0.0353, val_mae: 0.0362\n",
      "Epoch [27/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0352, val_mae: 0.0347\n",
      "Epoch [28/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0354, val_mae: 0.0355\n",
      "Epoch [29/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0352, val_mae: 0.0351\n",
      "Epoch [30/1000] - train_loss: 0.0020, val_loss: 0.0021, train_mae: 0.0351, val_mae: 0.0368\n",
      "Epoch [31/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0352, val_mae: 0.0356\n",
      "Epoch [32/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0351, val_mae: 0.0356\n",
      "Epoch [33/1000] - train_loss: 0.0020, val_loss: 0.0022, train_mae: 0.0351, val_mae: 0.0374\n",
      "Epoch [34/1000] - train_loss: 0.0020, val_loss: 0.0019, train_mae: 0.0351, val_mae: 0.0345\n",
      "Epoch [35/1000] - train_loss: 0.0020, val_loss: 0.0023, train_mae: 0.0348, val_mae: 0.0384\n",
      "Epoch [36/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0348, val_mae: 0.0347\n",
      "Epoch [37/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0347, val_mae: 0.0356\n",
      "Epoch [38/1000] - train_loss: 0.0019, val_loss: 0.0021, train_mae: 0.0347, val_mae: 0.0370\n",
      "Epoch [39/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0346, val_mae: 0.0348\n",
      "Epoch [40/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0345, val_mae: 0.0348\n",
      "Epoch [41/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0345, val_mae: 0.0340\n",
      "Epoch [42/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0343, val_mae: 0.0340\n",
      "Epoch [43/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0344, val_mae: 0.0344\n",
      "Epoch [44/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0344, val_mae: 0.0345\n",
      "Epoch [45/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0343, val_mae: 0.0354\n",
      "Epoch [46/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0343, val_mae: 0.0358\n",
      "Epoch [47/1000] - train_loss: 0.0019, val_loss: 0.0023, train_mae: 0.0340, val_mae: 0.0384\n",
      "Epoch [48/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0341, val_mae: 0.0343\n",
      "Epoch [49/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0340, val_mae: 0.0359\n",
      "Epoch [50/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0340, val_mae: 0.0356\n",
      "Epoch [51/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0339, val_mae: 0.0346\n",
      "Epoch [52/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0338, val_mae: 0.0337\n",
      "Epoch [53/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0335, val_mae: 0.0339\n",
      "Epoch [54/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0334, val_mae: 0.0333\n",
      "Epoch [55/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0334, val_mae: 0.0337\n",
      "Epoch [56/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0335, val_mae: 0.0331\n",
      "Epoch [57/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0334, val_mae: 0.0332\n",
      "Epoch [58/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0332, val_mae: 0.0340\n",
      "Epoch [59/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0333, val_mae: 0.0332\n",
      "Epoch [60/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0332, val_mae: 0.0328\n",
      "Epoch [61/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0332, val_mae: 0.0330\n",
      "Epoch [62/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0331, val_mae: 0.0338\n",
      "Epoch [63/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0330, val_mae: 0.0336\n",
      "Epoch [64/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0331, val_mae: 0.0329\n",
      "Epoch [65/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0331, val_mae: 0.0324\n",
      "Epoch [66/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0329, val_mae: 0.0336\n",
      "Epoch [67/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0330, val_mae: 0.0328\n",
      "Epoch [68/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0330, val_mae: 0.0331\n",
      "Epoch [69/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0330, val_mae: 0.0336\n",
      "Epoch [70/1000] - train_loss: 0.0018, val_loss: 0.0017, train_mae: 0.0329, val_mae: 0.0321\n",
      "Epoch [71/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0327, val_mae: 0.0336\n",
      "Epoch [72/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0329, val_mae: 0.0331\n",
      "Epoch [73/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0327, val_mae: 0.0328\n",
      "Epoch [74/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0329, val_mae: 0.0330\n",
      "Epoch [75/1000] - train_loss: 0.0017, val_loss: 0.0025, train_mae: 0.0327, val_mae: 0.0407\n",
      "Epoch [76/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0336\n",
      "Epoch [77/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0328, val_mae: 0.0342\n",
      "Epoch [78/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0329\n",
      "Epoch [79/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0334\n",
      "Epoch [80/1000] - train_loss: 0.0018, val_loss: 0.0017, train_mae: 0.0328, val_mae: 0.0323\n",
      "Epoch [81/1000] - train_loss: 0.0018, val_loss: 0.0017, train_mae: 0.0328, val_mae: 0.0321\n",
      "Epoch [82/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0336\n",
      "Epoch [83/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0327, val_mae: 0.0328\n",
      "Epoch [84/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0328\n",
      "Epoch [85/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0327, val_mae: 0.0326\n",
      "Epoch [86/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0327, val_mae: 0.0343\n",
      "Epoch [87/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0327, val_mae: 0.0325\n",
      "Epoch [88/1000] - train_loss: 0.0017, val_loss: 0.0021, train_mae: 0.0325, val_mae: 0.0353\n",
      "Epoch [89/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0321\n",
      "Epoch [90/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0326\n",
      "Epoch [91/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0327, val_mae: 0.0330\n",
      "Epoch [92/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0322\n",
      "Epoch [93/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0327, val_mae: 0.0327\n",
      "Epoch [94/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0320\n",
      "Epoch [95/1000] - train_loss: 0.0017, val_loss: 0.0022, train_mae: 0.0327, val_mae: 0.0377\n",
      "Epoch [96/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0327, val_mae: 0.0333\n",
      "Epoch [97/1000] - train_loss: 0.0017, val_loss: 0.0021, train_mae: 0.0327, val_mae: 0.0373\n",
      "Epoch [98/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0325, val_mae: 0.0336\n",
      "Epoch [99/1000] - train_loss: 0.0018, val_loss: 0.0017, train_mae: 0.0327, val_mae: 0.0322\n",
      "Epoch [100/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0326, val_mae: 0.0336\n",
      "Epoch [101/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0326\n",
      "Epoch [102/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0326\n",
      "Epoch [103/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0328\n",
      "Epoch [104/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0331\n",
      "Epoch [105/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0323\n",
      "Epoch [106/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0326\n",
      "Epoch [107/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0319\n",
      "Epoch [108/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0323\n",
      "Epoch [109/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0341\n",
      "Epoch [110/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0328, val_mae: 0.0347\n",
      "Epoch [111/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0328\n",
      "Epoch [112/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0333\n",
      "Epoch [113/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0327, val_mae: 0.0348\n",
      "Epoch [114/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0322\n",
      "Epoch [115/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0329\n",
      "Epoch [116/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0326, val_mae: 0.0346\n",
      "Epoch [117/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0326\n",
      "Epoch [118/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0326, val_mae: 0.0349\n",
      "Epoch [119/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0326, val_mae: 0.0335\n",
      "Epoch [120/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0324, val_mae: 0.0325\n",
      "Epoch [121/1000] - train_loss: 0.0017, val_loss: 0.0021, train_mae: 0.0324, val_mae: 0.0350\n",
      "Epoch [122/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0323\n",
      "Epoch [123/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0331\n",
      "Epoch [124/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0324, val_mae: 0.0347\n",
      "Epoch [125/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0324, val_mae: 0.0348\n",
      "Epoch [126/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0325\n",
      "Epoch [127/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0324\n",
      "Epoch [128/1000] - train_loss: 0.0017, val_loss: 0.0022, train_mae: 0.0324, val_mae: 0.0381\n",
      "Epoch [129/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0326\n",
      "Epoch [130/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0341\n",
      "Epoch [131/1000] - train_loss: 0.0017, val_loss: 0.0020, train_mae: 0.0325, val_mae: 0.0354\n",
      "Epoch [132/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0340\n",
      "Epoch [133/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0333\n",
      "Epoch [134/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0322\n",
      "Epoch [135/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0321\n",
      "Epoch [136/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0326\n",
      "Epoch [137/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0320\n",
      "Epoch [138/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0320\n",
      "Epoch [139/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0321\n",
      "Epoch [140/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0324, val_mae: 0.0323\n",
      "Epoch [141/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0324, val_mae: 0.0327\n",
      "Epoch [142/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0325, val_mae: 0.0349\n",
      "Epoch [143/1000] - train_loss: 0.0017, val_loss: 0.0023, train_mae: 0.0323, val_mae: 0.0387\n",
      "Epoch [144/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0320\n",
      "Epoch [145/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0338\n",
      "Epoch [146/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0320\n",
      "Epoch [147/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0318\n",
      "Epoch [148/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0319\n",
      "Epoch [149/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0325, val_mae: 0.0334\n",
      "Epoch [150/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0323\n",
      "Epoch [151/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0333\n",
      "Epoch [152/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0322\n",
      "Epoch [153/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0335\n",
      "Epoch [154/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0322\n",
      "Epoch [155/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0326\n",
      "Epoch [156/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0327\n",
      "Epoch [157/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0324, val_mae: 0.0329\n",
      "Epoch [158/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0332\n",
      "Epoch [159/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0319\n",
      "Epoch [160/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0322\n",
      "Epoch [161/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0320\n",
      "Epoch [162/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0326\n",
      "Epoch [163/1000] - train_loss: 0.0017, val_loss: 0.0025, train_mae: 0.0324, val_mae: 0.0412\n",
      "Epoch [164/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0327\n",
      "Epoch [165/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0330\n",
      "Epoch [166/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0325, val_mae: 0.0325\n",
      "Epoch [167/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0325\n",
      "Epoch [168/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0327\n",
      "Epoch [169/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0324, val_mae: 0.0327\n",
      "Epoch [170/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0324, val_mae: 0.0345\n",
      "Epoch [171/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0322\n",
      "Epoch [172/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0326\n",
      "Epoch [173/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0320\n",
      "Epoch [174/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0335\n",
      "Epoch [175/1000] - train_loss: 0.0017, val_loss: 0.0020, train_mae: 0.0325, val_mae: 0.0343\n",
      "Epoch [176/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0324, val_mae: 0.0325\n",
      "Epoch [177/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0323, val_mae: 0.0347\n",
      "Epoch [178/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0323, val_mae: 0.0351\n",
      "Epoch [179/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0328\n",
      "Epoch [180/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0322\n",
      "Epoch [181/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0331\n",
      "Epoch [182/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0332\n",
      "Epoch [183/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0329\n",
      "Epoch [184/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0322\n",
      "Epoch [185/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0322\n",
      "Epoch [186/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0322\n",
      "Epoch [187/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0322\n",
      "Epoch [188/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0319\n",
      "Epoch [189/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0326\n",
      "Epoch [190/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0318\n",
      "Epoch [191/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0321, val_mae: 0.0344\n",
      "Epoch [192/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0322\n",
      "Epoch [193/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0328\n",
      "Epoch [194/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0341\n",
      "Epoch [195/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0317\n",
      "Epoch [196/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0316\n",
      "Epoch [197/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0322\n",
      "Epoch [198/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0321\n",
      "Epoch [199/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0321\n",
      "Epoch [200/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0321\n",
      "Epoch [201/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0320\n",
      "Epoch [202/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0337\n",
      "Epoch [203/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0322\n",
      "Epoch [204/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0318\n",
      "Epoch [205/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0322, val_mae: 0.0336\n",
      "Epoch [206/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0323\n",
      "Epoch [207/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0323\n",
      "Epoch [208/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0326\n",
      "Epoch [209/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0320, val_mae: 0.0346\n",
      "Epoch [210/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0322\n",
      "Epoch [211/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0319, val_mae: 0.0328\n",
      "Epoch [212/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0330\n",
      "Epoch [213/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0317\n",
      "Epoch [214/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0320, val_mae: 0.0349\n",
      "Epoch [215/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0321, val_mae: 0.0331\n",
      "Epoch [216/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0319\n",
      "Epoch [217/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0334\n",
      "Epoch [218/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0321\n",
      "Epoch [219/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0327\n",
      "Epoch [220/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0320, val_mae: 0.0349\n",
      "Epoch [221/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0319, val_mae: 0.0323\n",
      "Epoch [222/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0326\n",
      "Epoch [223/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0319, val_mae: 0.0317\n",
      "Epoch [224/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0319, val_mae: 0.0331\n",
      "Epoch [225/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0319\n",
      "Epoch [226/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0328\n",
      "Epoch [227/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0315\n",
      "Epoch [228/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0319, val_mae: 0.0346\n",
      "Epoch [229/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0326\n",
      "Epoch [230/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0321, val_mae: 0.0317\n",
      "Epoch [231/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0322\n",
      "Epoch [232/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0326\n",
      "Epoch [233/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0320\n",
      "Epoch [234/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0321\n",
      "Epoch [235/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0322\n",
      "Epoch [236/1000] - train_loss: 0.0017, val_loss: 0.0021, train_mae: 0.0319, val_mae: 0.0371\n",
      "Epoch [237/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0325\n",
      "Epoch [238/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0323\n",
      "Epoch [239/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0320\n",
      "Epoch [240/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0317\n",
      "Epoch [241/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0321\n",
      "Epoch [242/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0341\n",
      "Epoch [243/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0319, val_mae: 0.0331\n",
      "Epoch [244/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0318\n",
      "Epoch [245/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0323\n",
      "Epoch [246/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0339\n",
      "Epoch [247/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0319, val_mae: 0.0316\n",
      "Epoch [248/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0317\n",
      "Epoch [249/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0322\n",
      "Epoch [250/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0316\n",
      "Epoch [251/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0317, val_mae: 0.0331\n",
      "Epoch [252/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0319\n",
      "Epoch [253/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0317\n",
      "Epoch [254/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0317\n",
      "Epoch [255/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0324\n",
      "Epoch [256/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0321\n",
      "Epoch [257/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0318, val_mae: 0.0341\n",
      "Epoch [258/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0318, val_mae: 0.0332\n",
      "Epoch [259/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0318\n",
      "Epoch [260/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0317\n",
      "Epoch [261/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0319\n",
      "Epoch [262/1000] - train_loss: 0.0016, val_loss: 0.0020, train_mae: 0.0318, val_mae: 0.0362\n",
      "Epoch [263/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0318, val_mae: 0.0323\n",
      "Epoch [264/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0323\n",
      "Epoch [265/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0319, val_mae: 0.0331\n",
      "Epoch [266/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0320, val_mae: 0.0316\n",
      "Epoch [267/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0323\n",
      "Epoch [268/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0318, val_mae: 0.0330\n",
      "Epoch [269/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0317, val_mae: 0.0332\n",
      "Epoch [270/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0326\n",
      "Epoch [271/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0318\n",
      "Epoch [272/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0316\n",
      "Epoch [273/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0319\n",
      "Epoch [274/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0316\n",
      "Epoch [275/1000] - train_loss: 0.0016, val_loss: 0.0021, train_mae: 0.0318, val_mae: 0.0372\n",
      "Epoch [276/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0329\n",
      "Epoch [277/1000] - train_loss: 0.0016, val_loss: 0.0024, train_mae: 0.0317, val_mae: 0.0399\n",
      "Epoch [278/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0315\n",
      "Epoch [279/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0315\n",
      "Epoch [280/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0320\n",
      "Epoch [281/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0326\n",
      "Epoch [282/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0317\n",
      "Epoch [283/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0322\n",
      "Epoch [284/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0318, val_mae: 0.0335\n",
      "Epoch [285/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0320, val_mae: 0.0315\n",
      "Epoch [286/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0316\n",
      "Epoch [287/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0320\n",
      "Epoch [288/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0318, val_mae: 0.0333\n",
      "Epoch [289/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0323\n",
      "Epoch [290/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0323\n",
      "Epoch [291/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0316\n",
      "Epoch [292/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0317\n",
      "Epoch [293/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0318\n",
      "Epoch [294/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0314\n",
      "Epoch [295/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0325\n",
      "Epoch [296/1000] - train_loss: 0.0016, val_loss: 0.0023, train_mae: 0.0317, val_mae: 0.0390\n",
      "Epoch [297/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0322\n",
      "Epoch [298/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0322\n",
      "Epoch [299/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0317\n",
      "Epoch [300/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0317, val_mae: 0.0331\n",
      "Epoch [301/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0332\n",
      "Epoch [302/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0312\n",
      "Epoch [303/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0322\n",
      "Epoch [304/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0316, val_mae: 0.0333\n",
      "Epoch [305/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0315\n",
      "Epoch [306/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0320\n",
      "Epoch [307/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0321\n",
      "Epoch [308/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0317, val_mae: 0.0323\n",
      "Epoch [309/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0317\n",
      "Epoch [310/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0319\n",
      "Epoch [311/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0311\n",
      "Epoch [312/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0315\n",
      "Epoch [313/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0319\n",
      "Epoch [314/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0321\n",
      "Epoch [315/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0316\n",
      "Epoch [316/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0319\n",
      "Epoch [317/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0329\n",
      "Epoch [318/1000] - train_loss: 0.0016, val_loss: 0.0020, train_mae: 0.0315, val_mae: 0.0356\n",
      "Epoch [319/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0318\n",
      "Epoch [320/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0315, val_mae: 0.0323\n",
      "Epoch [321/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0317, val_mae: 0.0328\n",
      "Epoch [322/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0317\n",
      "Epoch [323/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0326\n",
      "Epoch [324/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0317\n",
      "Epoch [325/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0318\n",
      "Epoch [326/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0324\n",
      "Epoch [327/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0318\n",
      "Epoch [328/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0316\n",
      "Epoch [329/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0317\n",
      "Epoch [330/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0315\n",
      "Epoch [331/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0317, val_mae: 0.0334\n",
      "Epoch [332/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0315\n",
      "Epoch [333/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0322\n",
      "Epoch [334/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0317\n",
      "Epoch [335/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0315\n",
      "Epoch [336/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0325\n",
      "Epoch [337/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0319\n",
      "Epoch [338/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0312\n",
      "Epoch [339/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0318\n",
      "Epoch [340/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0315\n",
      "Epoch [341/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0318\n",
      "Epoch [342/1000] - train_loss: 0.0016, val_loss: 0.0020, train_mae: 0.0316, val_mae: 0.0343\n",
      "Epoch [343/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0314\n",
      "Epoch [344/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0317\n",
      "Epoch [345/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0316\n",
      "Epoch [346/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0325\n",
      "Epoch [347/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0321\n",
      "Epoch [348/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0324\n",
      "Epoch [349/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0314, val_mae: 0.0318\n",
      "Epoch [350/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0318\n",
      "Epoch [351/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0314\n",
      "Epoch [352/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0317\n",
      "Epoch [353/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0318\n",
      "Epoch [354/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0322\n",
      "Epoch [355/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0311\n",
      "Epoch [356/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0314, val_mae: 0.0323\n",
      "Epoch [357/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0315, val_mae: 0.0341\n",
      "Epoch [358/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0315, val_mae: 0.0332\n",
      "Epoch [359/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0318\n",
      "Epoch [360/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0314\n",
      "Epoch [361/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0315, val_mae: 0.0336\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "train_losses1x30, val_losses1x30, train_maes1x30, val_maes1x30, best_state1x30 = train_loop(net1x30, train_dataloader, val_dataloader, patience=50, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0252, val_mae: 0.0249\n",
      "Epoch [2/1000] - train_loss: 0.0010, val_loss: 0.0015, train_mae: 0.0249, val_mae: 0.0313\n",
      "Epoch [3/1000] - train_loss: 0.0010, val_loss: 0.0009, train_mae: 0.0243, val_mae: 0.0237\n",
      "Epoch [4/1000] - train_loss: 0.0009, val_loss: 0.0010, train_mae: 0.0240, val_mae: 0.0246\n",
      "Epoch [5/1000] - train_loss: 0.0009, val_loss: 0.0010, train_mae: 0.0238, val_mae: 0.0248\n",
      "Epoch [6/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0237, val_mae: 0.0228\n",
      "Epoch [7/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0230, val_mae: 0.0220\n",
      "Epoch [8/1000] - train_loss: 0.0009, val_loss: 0.0010, train_mae: 0.0229, val_mae: 0.0252\n",
      "Epoch [9/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0228, val_mae: 0.0214\n",
      "Epoch [10/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0227, val_mae: 0.0218\n",
      "Epoch [11/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0225, val_mae: 0.0220\n",
      "Epoch [12/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0221, val_mae: 0.0210\n",
      "Epoch [13/1000] - train_loss: 0.0008, val_loss: 0.0009, train_mae: 0.0219, val_mae: 0.0230\n",
      "Epoch [14/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0219, val_mae: 0.0219\n",
      "Epoch [15/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0218, val_mae: 0.0201\n",
      "Epoch [16/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0213, val_mae: 0.0213\n",
      "Epoch [17/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0213, val_mae: 0.0215\n",
      "Epoch [18/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0208, val_mae: 0.0221\n",
      "Epoch [19/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0210, val_mae: 0.0201\n",
      "Epoch [20/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0207, val_mae: 0.0203\n",
      "Epoch [21/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0206, val_mae: 0.0195\n",
      "Epoch [22/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0205, val_mae: 0.0208\n",
      "Epoch [23/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0205, val_mae: 0.0204\n",
      "Epoch [24/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0203, val_mae: 0.0191\n",
      "Epoch [25/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0203, val_mae: 0.0193\n",
      "Epoch [26/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0202, val_mae: 0.0195\n",
      "Epoch [27/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0201, val_mae: 0.0195\n",
      "Epoch [28/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0200, val_mae: 0.0191\n",
      "Epoch [29/1000] - train_loss: 0.0006, val_loss: 0.0009, train_mae: 0.0198, val_mae: 0.0236\n",
      "Epoch [30/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0201, val_mae: 0.0204\n",
      "Epoch [31/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0197, val_mae: 0.0189\n",
      "Epoch [32/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0198, val_mae: 0.0195\n",
      "Epoch [33/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0195, val_mae: 0.0194\n",
      "Epoch [34/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0195, val_mae: 0.0208\n",
      "Epoch [35/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0197, val_mae: 0.0179\n",
      "Epoch [36/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0192, val_mae: 0.0190\n",
      "Epoch [37/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0196, val_mae: 0.0205\n",
      "Epoch [38/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0192, val_mae: 0.0196\n",
      "Epoch [39/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0191, val_mae: 0.0212\n",
      "Epoch [40/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0190, val_mae: 0.0203\n",
      "Epoch [41/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0190, val_mae: 0.0182\n",
      "Epoch [42/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0187, val_mae: 0.0182\n",
      "Epoch [43/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0190, val_mae: 0.0192\n",
      "Epoch [44/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0188, val_mae: 0.0184\n",
      "Epoch [45/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0188, val_mae: 0.0171\n",
      "Epoch [46/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0187, val_mae: 0.0195\n",
      "Epoch [47/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0188, val_mae: 0.0171\n",
      "Epoch [48/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0185, val_mae: 0.0182\n",
      "Epoch [49/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0186, val_mae: 0.0177\n",
      "Epoch [50/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0186, val_mae: 0.0176\n",
      "Epoch [51/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0185, val_mae: 0.0173\n",
      "Epoch [52/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0185, val_mae: 0.0204\n",
      "Epoch [53/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0184, val_mae: 0.0174\n",
      "Epoch [54/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0183, val_mae: 0.0171\n",
      "Epoch [55/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0184, val_mae: 0.0168\n",
      "Epoch [56/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0183, val_mae: 0.0187\n",
      "Epoch [57/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0183, val_mae: 0.0187\n",
      "Epoch [58/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0183, val_mae: 0.0179\n",
      "Epoch [59/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0182, val_mae: 0.0186\n",
      "Epoch [60/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0181, val_mae: 0.0178\n",
      "Epoch [61/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0182, val_mae: 0.0200\n",
      "Epoch [62/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0182, val_mae: 0.0167\n",
      "Epoch [63/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0180, val_mae: 0.0165\n",
      "Epoch [64/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0179, val_mae: 0.0181\n",
      "Epoch [65/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0182, val_mae: 0.0184\n",
      "Epoch [66/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0180, val_mae: 0.0172\n",
      "Epoch [67/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0180, val_mae: 0.0168\n",
      "Epoch [68/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0178, val_mae: 0.0165\n",
      "Epoch [69/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0177, val_mae: 0.0176\n",
      "Epoch [70/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0180, val_mae: 0.0170\n",
      "Epoch [71/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0176, val_mae: 0.0187\n",
      "Epoch [72/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0179, val_mae: 0.0180\n",
      "Epoch [73/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0177, val_mae: 0.0178\n",
      "Epoch [74/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0178, val_mae: 0.0177\n",
      "Epoch [75/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0176, val_mae: 0.0192\n",
      "Epoch [76/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0175, val_mae: 0.0173\n",
      "Epoch [77/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0176, val_mae: 0.0180\n",
      "Epoch [78/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0177, val_mae: 0.0192\n",
      "Epoch [79/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0173, val_mae: 0.0168\n",
      "Epoch [80/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0174, val_mae: 0.0165\n",
      "Epoch [81/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0175, val_mae: 0.0175\n",
      "Epoch [82/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0173, val_mae: 0.0164\n",
      "Epoch [83/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0173, val_mae: 0.0171\n",
      "Epoch [84/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0172, val_mae: 0.0169\n",
      "Epoch [85/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0174, val_mae: 0.0164\n",
      "Epoch [86/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0170\n",
      "Epoch [87/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0175, val_mae: 0.0165\n",
      "Epoch [88/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0170, val_mae: 0.0159\n",
      "Epoch [89/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0170, val_mae: 0.0190\n",
      "Epoch [90/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0171\n",
      "Epoch [91/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0170, val_mae: 0.0162\n",
      "Epoch [92/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0171, val_mae: 0.0187\n",
      "Epoch [93/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0171, val_mae: 0.0190\n",
      "Epoch [94/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0169, val_mae: 0.0197\n",
      "Epoch [95/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0169, val_mae: 0.0164\n",
      "Epoch [96/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0166, val_mae: 0.0164\n",
      "Epoch [97/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0159\n",
      "Epoch [98/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0167, val_mae: 0.0174\n",
      "Epoch [99/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0158\n",
      "Epoch [100/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0167, val_mae: 0.0167\n",
      "Epoch [101/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0160\n",
      "Epoch [102/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0164\n",
      "Epoch [103/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0165, val_mae: 0.0180\n",
      "Epoch [104/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0156\n",
      "Epoch [105/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0165, val_mae: 0.0164\n",
      "Epoch [106/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0166, val_mae: 0.0170\n",
      "Epoch [107/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0158\n",
      "Epoch [108/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0159\n",
      "Epoch [109/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0165, val_mae: 0.0203\n",
      "Epoch [110/1000] - train_loss: 0.0004, val_loss: 0.0006, train_mae: 0.0164, val_mae: 0.0198\n",
      "Epoch [111/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0159\n",
      "Epoch [112/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0165, val_mae: 0.0160\n",
      "Epoch [113/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0158\n",
      "Epoch [114/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0153\n",
      "Epoch [115/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0157\n",
      "Epoch [116/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0162, val_mae: 0.0171\n",
      "Epoch [117/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0177\n",
      "Epoch [118/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0159\n",
      "Epoch [119/1000] - train_loss: 0.0004, val_loss: 0.0008, train_mae: 0.0162, val_mae: 0.0228\n",
      "Epoch [120/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0162, val_mae: 0.0170\n",
      "Epoch [121/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0155\n",
      "Epoch [122/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0155\n",
      "Epoch [123/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0152\n",
      "Epoch [124/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0150\n",
      "Epoch [125/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0155\n",
      "Epoch [126/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0160, val_mae: 0.0184\n",
      "Epoch [127/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0160, val_mae: 0.0178\n",
      "Epoch [128/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0156\n",
      "Epoch [129/1000] - train_loss: 0.0004, val_loss: 0.0006, train_mae: 0.0162, val_mae: 0.0204\n",
      "Epoch [130/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0163\n",
      "Epoch [131/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0160\n",
      "Epoch [132/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0159, val_mae: 0.0162\n",
      "Epoch [133/1000] - train_loss: 0.0004, val_loss: 0.0006, train_mae: 0.0158, val_mae: 0.0186\n",
      "Epoch [134/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0152\n",
      "Epoch [135/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0158\n",
      "Epoch [136/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0158\n",
      "Epoch [137/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0153\n",
      "Epoch [138/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0155\n",
      "Epoch [139/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0151\n",
      "Epoch [140/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0159\n",
      "Epoch [141/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0160\n",
      "Epoch [142/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0148\n",
      "Epoch [143/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0152\n",
      "Epoch [144/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0158, val_mae: 0.0166\n",
      "Epoch [145/1000] - train_loss: 0.0004, val_loss: 0.0006, train_mae: 0.0157, val_mae: 0.0187\n",
      "Epoch [146/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0156, val_mae: 0.0167\n",
      "Epoch [147/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0161\n",
      "Epoch [148/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0152\n",
      "Epoch [149/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0151\n",
      "Epoch [150/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0159\n",
      "Epoch [151/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0158\n",
      "Epoch [152/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0154\n",
      "Epoch [153/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0157\n",
      "Epoch [154/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0160\n",
      "Epoch [155/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0153\n",
      "Epoch [156/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0157\n",
      "Epoch [157/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0155, val_mae: 0.0182\n",
      "Epoch [158/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0152\n",
      "Epoch [159/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0158, val_mae: 0.0187\n",
      "Epoch [160/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0156\n",
      "Epoch [161/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0151\n",
      "Epoch [162/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0161\n",
      "Epoch [163/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0155, val_mae: 0.0166\n",
      "Epoch [164/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0151\n",
      "Epoch [165/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0157\n",
      "Epoch [166/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0151\n",
      "Epoch [167/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0150\n",
      "Epoch [168/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0151\n",
      "Epoch [169/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0159\n",
      "Epoch [170/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0155\n",
      "Epoch [171/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0157\n",
      "Epoch [172/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0147\n",
      "Epoch [173/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0162\n",
      "Epoch [174/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0156\n",
      "Epoch [175/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0155, val_mae: 0.0180\n",
      "Epoch [176/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0150\n",
      "Epoch [177/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0149\n",
      "Epoch [178/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0148\n",
      "Epoch [179/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0149\n",
      "Epoch [180/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0146\n",
      "Epoch [181/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0152, val_mae: 0.0181\n",
      "Epoch [182/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0149\n",
      "Epoch [183/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0154\n",
      "Epoch [184/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0153\n",
      "Epoch [185/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0155\n",
      "Epoch [186/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0160\n",
      "Epoch [187/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0152\n",
      "Epoch [188/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0152, val_mae: 0.0142\n",
      "Epoch [189/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0152, val_mae: 0.0167\n",
      "Epoch [190/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0160\n",
      "Epoch [191/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0144\n",
      "Epoch [192/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0146\n",
      "Epoch [193/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0160\n",
      "Epoch [194/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0145\n",
      "Epoch [195/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0155\n",
      "Epoch [196/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0158\n",
      "Epoch [197/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0162\n",
      "Epoch [198/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0160\n",
      "Epoch [199/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0161\n",
      "Epoch [200/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0156\n",
      "Epoch [201/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0140\n",
      "Epoch [202/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0153\n",
      "Epoch [203/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0160\n",
      "Epoch [204/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0144\n",
      "Epoch [205/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0150, val_mae: 0.0163\n",
      "Epoch [206/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0142\n",
      "Epoch [207/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0151, val_mae: 0.0184\n",
      "Epoch [208/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0150, val_mae: 0.0165\n",
      "Epoch [209/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0153\n",
      "Epoch [210/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0156\n",
      "Epoch [211/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0152\n",
      "Epoch [212/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0157\n",
      "Epoch [213/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0161\n",
      "Epoch [214/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0142\n",
      "Epoch [215/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0153\n",
      "Epoch [216/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0156\n",
      "Epoch [217/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0145\n",
      "Epoch [218/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0144\n",
      "Epoch [219/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0144\n",
      "Epoch [220/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0148\n",
      "Epoch [221/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0150\n",
      "Epoch [222/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0146\n",
      "Epoch [223/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0157\n",
      "Epoch [224/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0144\n",
      "Epoch [225/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0163\n",
      "Epoch [226/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0142\n",
      "Epoch [227/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0145\n",
      "Epoch [228/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0139\n",
      "Epoch [229/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0148, val_mae: 0.0164\n",
      "Epoch [230/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0149\n",
      "Epoch [231/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0145\n",
      "Epoch [232/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0156\n",
      "Epoch [233/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0153\n",
      "Epoch [234/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0149\n",
      "Epoch [235/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0149\n",
      "Epoch [236/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0149\n",
      "Epoch [237/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0157\n",
      "Epoch [238/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0146, val_mae: 0.0185\n",
      "Epoch [239/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0149\n",
      "Epoch [240/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0152\n",
      "Epoch [241/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0156\n",
      "Epoch [242/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0142\n",
      "Epoch [243/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0141\n",
      "Epoch [244/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0143\n",
      "Epoch [245/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0163\n",
      "Epoch [246/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0161\n",
      "Epoch [247/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0146, val_mae: 0.0165\n",
      "Epoch [248/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0142\n",
      "Epoch [249/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0147, val_mae: 0.0174\n",
      "Epoch [250/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0154\n",
      "Epoch [251/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0157\n",
      "Epoch [252/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0147, val_mae: 0.0171\n",
      "Epoch [253/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0150\n",
      "Epoch [254/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0150\n",
      "Epoch [255/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0145\n",
      "Epoch [256/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0150\n",
      "Epoch [257/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0140\n",
      "Epoch [258/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0142\n",
      "Epoch [259/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0140\n",
      "Epoch [260/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0142\n",
      "Epoch [261/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0153\n",
      "Epoch [262/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0159\n",
      "Epoch [263/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0138\n",
      "Epoch [264/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0143\n",
      "Epoch [265/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0153\n",
      "Epoch [266/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0144\n",
      "Epoch [267/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0142\n",
      "Epoch [268/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0167\n",
      "Epoch [269/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0143\n",
      "Epoch [270/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0148\n",
      "Epoch [271/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0147\n",
      "Epoch [272/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0155\n",
      "Epoch [273/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0148\n",
      "Epoch [274/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0144\n",
      "Epoch [275/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0139\n",
      "Epoch [276/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0147\n",
      "Epoch [277/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0146\n",
      "Epoch [278/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0145\n",
      "Epoch [279/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0144\n",
      "Epoch [280/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0149\n",
      "Epoch [281/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0143, val_mae: 0.0149\n",
      "Epoch [282/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0141\n",
      "Epoch [283/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0138\n",
      "Epoch [284/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0144\n",
      "Epoch [285/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0145, val_mae: 0.0170\n",
      "Epoch [286/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0142\n",
      "Epoch [287/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0164\n",
      "Epoch [288/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0142\n",
      "Epoch [289/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0150\n",
      "Epoch [290/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0148\n",
      "Epoch [291/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0138\n",
      "Epoch [292/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0147\n",
      "Epoch [293/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0142\n",
      "Epoch [294/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0140\n",
      "Epoch [295/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0139\n",
      "Epoch [296/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0145\n",
      "Epoch [297/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0143, val_mae: 0.0162\n",
      "Epoch [298/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0147\n",
      "Epoch [299/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0143, val_mae: 0.0169\n",
      "Epoch [300/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0166\n",
      "Epoch [301/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0142, val_mae: 0.0149\n",
      "Epoch [302/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0138\n",
      "Epoch [303/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0142, val_mae: 0.0150\n",
      "Epoch [304/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0144, val_mae: 0.0175\n",
      "Epoch [305/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0143, val_mae: 0.0148\n",
      "Epoch [306/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0146\n",
      "Epoch [307/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0143\n",
      "Epoch [308/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0142\n",
      "Epoch [309/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0135\n",
      "Epoch [310/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0142, val_mae: 0.0169\n",
      "Epoch [311/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0141, val_mae: 0.0152\n",
      "Epoch [312/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0142, val_mae: 0.0157\n",
      "Epoch [313/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0143, val_mae: 0.0171\n",
      "Epoch [314/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0141\n",
      "Epoch [315/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0138\n",
      "Epoch [316/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0140\n",
      "Epoch [317/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0142\n",
      "Epoch [318/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0142, val_mae: 0.0154\n",
      "Epoch [319/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0141, val_mae: 0.0146\n",
      "Epoch [320/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0137\n",
      "Epoch [321/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0141, val_mae: 0.0149\n",
      "Epoch [322/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0140, val_mae: 0.0157\n",
      "Epoch [323/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0143\n",
      "Epoch [324/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0132\n",
      "Epoch [325/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0136\n",
      "Epoch [326/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0139, val_mae: 0.0153\n",
      "Epoch [327/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0144\n",
      "Epoch [328/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0136\n",
      "Epoch [329/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0139, val_mae: 0.0149\n",
      "Epoch [330/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0138\n",
      "Epoch [331/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0144\n",
      "Epoch [332/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0142\n",
      "Epoch [333/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0146\n",
      "Epoch [334/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0140, val_mae: 0.0150\n",
      "Epoch [335/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0139, val_mae: 0.0149\n",
      "Epoch [336/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0140, val_mae: 0.0147\n",
      "Epoch [337/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0139, val_mae: 0.0166\n",
      "Epoch [338/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0138, val_mae: 0.0155\n",
      "Epoch [339/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0137\n",
      "Epoch [340/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0139\n",
      "Epoch [341/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0138, val_mae: 0.0151\n",
      "Epoch [342/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0139\n",
      "Epoch [343/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0144\n",
      "Epoch [344/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0139\n",
      "Epoch [345/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0137\n",
      "Epoch [346/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0139\n",
      "Epoch [347/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0138, val_mae: 0.0157\n",
      "Epoch [348/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0138, val_mae: 0.0148\n",
      "Epoch [349/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0146\n",
      "Epoch [350/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0137, val_mae: 0.0152\n",
      "Epoch [351/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0140\n",
      "Epoch [352/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0140\n",
      "Epoch [353/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0146\n",
      "Epoch [354/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0131\n",
      "Epoch [355/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0142\n",
      "Epoch [356/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0145\n",
      "Epoch [357/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0135\n",
      "Epoch [358/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0139\n",
      "Epoch [359/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0138, val_mae: 0.0149\n",
      "Epoch [360/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [361/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0134\n",
      "Epoch [362/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0137, val_mae: 0.0144\n",
      "Epoch [363/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0128\n",
      "Epoch [364/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0139\n",
      "Epoch [365/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0136, val_mae: 0.0151\n",
      "Epoch [366/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0138\n",
      "Epoch [367/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0135, val_mae: 0.0177\n",
      "Epoch [368/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0141\n",
      "Epoch [369/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0142\n",
      "Epoch [370/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0133\n",
      "Epoch [371/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0139\n",
      "Epoch [372/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0135, val_mae: 0.0158\n",
      "Epoch [373/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0136, val_mae: 0.0151\n",
      "Epoch [374/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0143\n",
      "Epoch [375/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0139\n",
      "Epoch [376/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0139\n",
      "Epoch [377/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0135, val_mae: 0.0155\n",
      "Epoch [378/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0133\n",
      "Epoch [379/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0145\n",
      "Epoch [380/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0132\n",
      "Epoch [381/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0131\n",
      "Epoch [382/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0145\n",
      "Epoch [383/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0133\n",
      "Epoch [384/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0132\n",
      "Epoch [385/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0138\n",
      "Epoch [386/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0132\n",
      "Epoch [387/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0128\n",
      "Epoch [388/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0137\n",
      "Epoch [389/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0135, val_mae: 0.0150\n",
      "Epoch [390/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0133\n",
      "Epoch [391/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0137\n",
      "Epoch [392/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0130\n",
      "Epoch [393/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0139\n",
      "Epoch [394/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0135\n",
      "Epoch [395/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0142\n",
      "Epoch [396/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0132\n",
      "Epoch [397/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [398/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0133\n",
      "Epoch [399/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [400/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0135\n",
      "Epoch [401/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0130\n",
      "Epoch [402/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0140\n",
      "Epoch [403/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0134, val_mae: 0.0163\n",
      "Epoch [404/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0132\n",
      "Epoch [405/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0131\n",
      "Epoch [406/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0137\n",
      "Epoch [407/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0130\n",
      "Epoch [408/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [409/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [410/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0124\n",
      "Epoch [411/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0139\n",
      "Epoch [412/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0137\n",
      "Epoch [413/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0143\n",
      "Epoch [414/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0125\n",
      "Epoch [415/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0141\n",
      "Epoch [416/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0140\n",
      "Epoch [417/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0129\n",
      "Epoch [418/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0126\n",
      "Epoch [419/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0137\n",
      "Epoch [420/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0131\n",
      "Epoch [421/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0140\n",
      "Epoch [422/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0132\n",
      "Epoch [423/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0130, val_mae: 0.0156\n",
      "Epoch [424/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0135\n",
      "Epoch [425/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0133\n",
      "Epoch [426/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0132\n",
      "Epoch [427/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0130, val_mae: 0.0150\n",
      "Epoch [428/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0137\n",
      "Epoch [429/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0130\n",
      "Epoch [430/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0129\n",
      "Epoch [431/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0126\n",
      "Epoch [432/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0133\n",
      "Epoch [433/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0128\n",
      "Epoch [434/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0130\n",
      "Epoch [435/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0132\n",
      "Epoch [436/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0130, val_mae: 0.0164\n",
      "Epoch [437/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0141\n",
      "Epoch [438/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0134\n",
      "Epoch [439/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0131, val_mae: 0.0161\n",
      "Epoch [440/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0125\n",
      "Epoch [441/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0124\n",
      "Epoch [442/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [443/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [444/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0125\n",
      "Epoch [445/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0130, val_mae: 0.0148\n",
      "Epoch [446/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0144\n",
      "Epoch [447/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0135\n",
      "Epoch [448/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [449/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0137\n",
      "Epoch [450/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0145\n",
      "Epoch [451/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0130\n",
      "Epoch [452/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0127\n",
      "Epoch [453/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0131\n",
      "Epoch [454/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [455/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0132\n",
      "Epoch [456/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0138\n",
      "Epoch [457/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0125\n",
      "Epoch [458/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0128\n",
      "Epoch [459/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0141\n",
      "Epoch [460/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0134\n",
      "Epoch [461/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0126\n",
      "Epoch [462/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0127\n",
      "Epoch [463/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0136\n",
      "Epoch [464/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0129\n",
      "Epoch [465/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0124\n",
      "Epoch [466/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0130\n",
      "Epoch [467/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0131\n",
      "Epoch [468/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0127\n",
      "Epoch [469/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0139\n",
      "Epoch [470/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0126\n",
      "Epoch [471/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [472/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0131\n",
      "Epoch [473/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [474/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0127, val_mae: 0.0165\n",
      "Epoch [475/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0139\n",
      "Epoch [476/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0130\n",
      "Epoch [477/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0124\n",
      "Epoch [478/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0127\n",
      "Epoch [479/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0129\n",
      "Epoch [480/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [481/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0122\n",
      "Epoch [482/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0127\n",
      "Epoch [483/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0141\n",
      "Epoch [484/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0133\n",
      "Epoch [485/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0131\n",
      "Epoch [486/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0139\n",
      "Epoch [487/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [488/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [489/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0127\n",
      "Epoch [490/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0124\n",
      "Epoch [491/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0125\n",
      "Epoch [492/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0125\n",
      "Epoch [493/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0125\n",
      "Epoch [494/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0123\n",
      "Epoch [495/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0134\n",
      "Epoch [496/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0123\n",
      "Epoch [497/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0122\n",
      "Epoch [498/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0128\n",
      "Epoch [499/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0128, val_mae: 0.0155\n",
      "Epoch [500/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0125\n",
      "Epoch [501/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0128\n",
      "Epoch [502/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0139\n",
      "Epoch [503/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0124\n",
      "Epoch [504/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0132\n",
      "Epoch [505/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0126\n",
      "Epoch [506/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0124\n",
      "Epoch [507/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0126\n",
      "Epoch [508/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0124\n",
      "Epoch [509/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0124\n",
      "Epoch [510/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0125\n",
      "Epoch [511/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0125\n",
      "Epoch [512/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0133\n",
      "Epoch [513/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0126, val_mae: 0.0159\n",
      "Epoch [514/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0127\n",
      "Epoch [515/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0136\n",
      "Epoch [516/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0134\n",
      "Epoch [517/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0124\n",
      "Epoch [518/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0131\n",
      "Epoch [519/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0127, val_mae: 0.0160\n",
      "Epoch [520/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0139\n",
      "Epoch [521/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0130\n",
      "Epoch [522/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [523/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0124\n",
      "Epoch [524/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0135\n",
      "Epoch [525/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0125\n",
      "Epoch [526/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0129\n",
      "Epoch [527/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0128\n",
      "Epoch [528/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0127\n",
      "Epoch [529/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0125\n",
      "Epoch [530/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0125\n",
      "Epoch [531/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0123\n",
      "Epoch [532/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0134\n",
      "Epoch [533/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0126\n",
      "Epoch [534/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0131\n",
      "Epoch [535/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0133\n",
      "Epoch [536/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0143\n",
      "Epoch [537/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [538/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0124\n",
      "Epoch [539/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0126\n",
      "Epoch [540/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [541/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0128\n",
      "Epoch [542/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0128\n",
      "Epoch [543/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0138\n",
      "Epoch [544/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0127, val_mae: 0.0147\n",
      "Epoch [545/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0120\n",
      "Epoch [546/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0125\n",
      "Epoch [547/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0126\n",
      "Epoch [548/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0126, val_mae: 0.0165\n",
      "Epoch [549/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0126\n",
      "Epoch [550/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0125\n",
      "Epoch [551/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0147\n",
      "Epoch [552/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0124\n",
      "Epoch [553/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0120\n",
      "Epoch [554/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0126\n",
      "Epoch [555/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0140\n",
      "Epoch [556/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0131\n",
      "Epoch [557/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0128\n",
      "Epoch [558/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0132\n",
      "Epoch [559/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0123\n",
      "Epoch [560/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0133\n",
      "Epoch [561/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0125\n",
      "Epoch [562/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0136\n",
      "Epoch [563/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0125\n",
      "Epoch [564/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0122\n",
      "Epoch [565/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0125\n",
      "Epoch [566/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0124\n",
      "Epoch [567/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0144\n",
      "Epoch [568/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0123\n",
      "Epoch [569/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0125\n",
      "Epoch [570/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0137\n",
      "Epoch [571/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0123\n",
      "Epoch [572/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0143\n",
      "Epoch [573/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0127\n",
      "Epoch [574/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0119\n",
      "Epoch [575/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0126\n",
      "Epoch [576/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0120\n",
      "Epoch [577/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0129\n",
      "Epoch [578/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0123\n",
      "Epoch [579/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0126\n",
      "Epoch [580/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0127\n",
      "Epoch [581/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0139\n",
      "Epoch [582/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0129\n",
      "Epoch [583/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0133\n",
      "Epoch [584/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0126\n",
      "Epoch [585/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [586/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0134\n",
      "Epoch [587/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0124\n",
      "Epoch [588/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0140\n",
      "Epoch [589/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0135\n",
      "Epoch [590/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0129\n",
      "Epoch [591/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0125\n",
      "Epoch [592/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0128\n",
      "Epoch [593/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0124, val_mae: 0.0124\n",
      "Epoch [594/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0119\n",
      "Epoch [595/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0124, val_mae: 0.0183\n",
      "Epoch [596/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0131\n",
      "Epoch [597/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0125, val_mae: 0.0152\n",
      "Epoch [598/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0126\n",
      "Epoch [599/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0133\n",
      "Epoch [600/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0124\n",
      "Epoch [601/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0122\n",
      "Epoch [602/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0123\n",
      "Epoch [603/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0133\n",
      "Epoch [604/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0125\n",
      "Epoch [605/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0120\n",
      "Epoch [606/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0139\n",
      "Epoch [607/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0124\n",
      "Epoch [608/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [609/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0125\n",
      "Epoch [610/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0124\n",
      "Epoch [611/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0135\n",
      "Epoch [612/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0125\n",
      "Epoch [613/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0120\n",
      "Epoch [614/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0126, val_mae: 0.0176\n",
      "Epoch [615/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0120\n",
      "Epoch [616/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0122\n",
      "Epoch [617/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0124, val_mae: 0.0122\n",
      "Epoch [618/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0128\n",
      "Epoch [619/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0137\n",
      "Epoch [620/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0126\n",
      "Epoch [621/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0124, val_mae: 0.0138\n",
      "Epoch [622/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0124, val_mae: 0.0125\n",
      "Epoch [623/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0127\n",
      "Epoch [624/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0122\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "train_losses2x30, val_losses2x30, train_maes2x30, val_maes2x30, best_state2x30 = train_loop(net2x30, train_dataloader, val_dataloader, patience=50, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - train_loss: 0.0012, val_loss: 0.0013, train_mae: 0.0273, val_mae: 0.0287\n",
      "Epoch [2/1000] - train_loss: 0.0012, val_loss: 0.0012, train_mae: 0.0268, val_mae: 0.0269\n",
      "Epoch [3/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0262, val_mae: 0.0261\n",
      "Epoch [4/1000] - train_loss: 0.0011, val_loss: 0.0010, train_mae: 0.0262, val_mae: 0.0245\n",
      "Epoch [5/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0252, val_mae: 0.0251\n",
      "Epoch [6/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0252, val_mae: 0.0241\n",
      "Epoch [7/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0247, val_mae: 0.0240\n",
      "Epoch [8/1000] - train_loss: 0.0010, val_loss: 0.0012, train_mae: 0.0245, val_mae: 0.0266\n",
      "Epoch [9/1000] - train_loss: 0.0010, val_loss: 0.0009, train_mae: 0.0244, val_mae: 0.0235\n",
      "Epoch [10/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0238, val_mae: 0.0228\n",
      "Epoch [11/1000] - train_loss: 0.0009, val_loss: 0.0012, train_mae: 0.0237, val_mae: 0.0285\n",
      "Epoch [12/1000] - train_loss: 0.0009, val_loss: 0.0010, train_mae: 0.0237, val_mae: 0.0244\n",
      "Epoch [13/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0233, val_mae: 0.0218\n",
      "Epoch [14/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0230, val_mae: 0.0228\n",
      "Epoch [15/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0229, val_mae: 0.0218\n",
      "Epoch [16/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0229, val_mae: 0.0230\n",
      "Epoch [17/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0226, val_mae: 0.0226\n",
      "Epoch [18/1000] - train_loss: 0.0008, val_loss: 0.0011, train_mae: 0.0223, val_mae: 0.0254\n",
      "Epoch [19/1000] - train_loss: 0.0008, val_loss: 0.0009, train_mae: 0.0222, val_mae: 0.0229\n",
      "Epoch [20/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0220, val_mae: 0.0210\n",
      "Epoch [21/1000] - train_loss: 0.0008, val_loss: 0.0010, train_mae: 0.0218, val_mae: 0.0257\n",
      "Epoch [22/1000] - train_loss: 0.0008, val_loss: 0.0010, train_mae: 0.0216, val_mae: 0.0247\n",
      "Epoch [23/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0215, val_mae: 0.0199\n",
      "Epoch [24/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0213, val_mae: 0.0206\n",
      "Epoch [25/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0212, val_mae: 0.0210\n",
      "Epoch [26/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0209, val_mae: 0.0195\n",
      "Epoch [27/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0207, val_mae: 0.0221\n",
      "Epoch [28/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0208, val_mae: 0.0196\n",
      "Epoch [29/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0205, val_mae: 0.0209\n",
      "Epoch [30/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0206, val_mae: 0.0198\n",
      "Epoch [31/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0204, val_mae: 0.0205\n",
      "Epoch [32/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0204, val_mae: 0.0212\n",
      "Epoch [33/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0201, val_mae: 0.0191\n",
      "Epoch [34/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0202, val_mae: 0.0193\n",
      "Epoch [35/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0199, val_mae: 0.0179\n",
      "Epoch [36/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0201, val_mae: 0.0204\n",
      "Epoch [37/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0200, val_mae: 0.0210\n",
      "Epoch [38/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0196, val_mae: 0.0185\n",
      "Epoch [39/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0197, val_mae: 0.0197\n",
      "Epoch [40/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0195, val_mae: 0.0179\n",
      "Epoch [41/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0193, val_mae: 0.0195\n",
      "Epoch [42/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0193, val_mae: 0.0195\n",
      "Epoch [43/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0189, val_mae: 0.0186\n",
      "Epoch [44/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0191, val_mae: 0.0178\n",
      "Epoch [45/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0190, val_mae: 0.0196\n",
      "Epoch [46/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0187, val_mae: 0.0186\n",
      "Epoch [47/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0189, val_mae: 0.0183\n",
      "Epoch [48/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0187, val_mae: 0.0178\n",
      "Epoch [49/1000] - train_loss: 0.0006, val_loss: 0.0009, train_mae: 0.0186, val_mae: 0.0243\n",
      "Epoch [50/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0183, val_mae: 0.0165\n",
      "Epoch [51/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0182, val_mae: 0.0185\n",
      "Epoch [52/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0183, val_mae: 0.0182\n",
      "Epoch [53/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0184, val_mae: 0.0167\n",
      "Epoch [54/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0182, val_mae: 0.0196\n",
      "Epoch [55/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0180, val_mae: 0.0190\n",
      "Epoch [56/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0177, val_mae: 0.0182\n",
      "Epoch [57/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0179, val_mae: 0.0174\n",
      "Epoch [58/1000] - train_loss: 0.0005, val_loss: 0.0007, train_mae: 0.0178, val_mae: 0.0207\n",
      "Epoch [59/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0177, val_mae: 0.0173\n",
      "Epoch [60/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0176, val_mae: 0.0165\n",
      "Epoch [61/1000] - train_loss: 0.0005, val_loss: 0.0007, train_mae: 0.0175, val_mae: 0.0200\n",
      "Epoch [62/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0175, val_mae: 0.0165\n",
      "Epoch [63/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0175, val_mae: 0.0164\n",
      "Epoch [64/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0174, val_mae: 0.0181\n",
      "Epoch [65/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0172, val_mae: 0.0174\n",
      "Epoch [66/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0172\n",
      "Epoch [67/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0172, val_mae: 0.0169\n",
      "Epoch [68/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0171, val_mae: 0.0160\n",
      "Epoch [69/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0169, val_mae: 0.0177\n",
      "Epoch [70/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0158\n",
      "Epoch [71/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0171, val_mae: 0.0156\n",
      "Epoch [72/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0162\n",
      "Epoch [73/1000] - train_loss: 0.0005, val_loss: 0.0007, train_mae: 0.0167, val_mae: 0.0209\n",
      "Epoch [74/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0165, val_mae: 0.0180\n",
      "Epoch [75/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0159\n",
      "Epoch [76/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0152\n",
      "Epoch [77/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0162, val_mae: 0.0168\n",
      "Epoch [78/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0176\n",
      "Epoch [79/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0150\n",
      "Epoch [80/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0161, val_mae: 0.0168\n",
      "Epoch [81/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0170\n",
      "Epoch [82/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0152\n",
      "Epoch [83/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0158\n",
      "Epoch [84/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0152\n",
      "Epoch [85/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0146\n",
      "Epoch [86/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0160\n",
      "Epoch [87/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0148\n",
      "Epoch [88/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0158, val_mae: 0.0170\n",
      "Epoch [89/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0156, val_mae: 0.0173\n",
      "Epoch [90/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0168\n",
      "Epoch [91/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0160\n",
      "Epoch [92/1000] - train_loss: 0.0004, val_loss: 0.0006, train_mae: 0.0154, val_mae: 0.0193\n",
      "Epoch [93/1000] - train_loss: 0.0004, val_loss: 0.0006, train_mae: 0.0155, val_mae: 0.0195\n",
      "Epoch [94/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0153, val_mae: 0.0140\n",
      "Epoch [95/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0149\n",
      "Epoch [96/1000] - train_loss: 0.0004, val_loss: 0.0006, train_mae: 0.0153, val_mae: 0.0203\n",
      "Epoch [97/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0153, val_mae: 0.0144\n",
      "Epoch [98/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0154, val_mae: 0.0169\n",
      "Epoch [99/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0146\n",
      "Epoch [100/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0152, val_mae: 0.0183\n",
      "Epoch [101/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0157\n",
      "Epoch [102/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0145\n",
      "Epoch [103/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0150\n",
      "Epoch [104/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0149, val_mae: 0.0168\n",
      "Epoch [105/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0138\n",
      "Epoch [106/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [107/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0156\n",
      "Epoch [108/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0139\n",
      "Epoch [109/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0137\n",
      "Epoch [110/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0152, val_mae: 0.0145\n",
      "Epoch [111/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0137\n",
      "Epoch [112/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0150\n",
      "Epoch [113/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0146\n",
      "Epoch [114/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0149\n",
      "Epoch [115/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0145\n",
      "Epoch [116/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0138\n",
      "Epoch [117/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0133\n",
      "Epoch [118/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0148, val_mae: 0.0190\n",
      "Epoch [119/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0137\n",
      "Epoch [120/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0143\n",
      "Epoch [121/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0153\n",
      "Epoch [122/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0141\n",
      "Epoch [123/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0157\n",
      "Epoch [124/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0151\n",
      "Epoch [125/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0136\n",
      "Epoch [126/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0153\n",
      "Epoch [127/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0145\n",
      "Epoch [128/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0144\n",
      "Epoch [129/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0135\n",
      "Epoch [130/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0137\n",
      "Epoch [131/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0131\n",
      "Epoch [132/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0139\n",
      "Epoch [133/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0166\n",
      "Epoch [134/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0129\n",
      "Epoch [135/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0142\n",
      "Epoch [136/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0154\n",
      "Epoch [137/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0146\n",
      "Epoch [138/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0135\n",
      "Epoch [139/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0137\n",
      "Epoch [140/1000] - train_loss: 0.0003, val_loss: 0.0006, train_mae: 0.0144, val_mae: 0.0198\n",
      "Epoch [141/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0134\n",
      "Epoch [142/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0130\n",
      "Epoch [143/1000] - train_loss: 0.0003, val_loss: 0.0006, train_mae: 0.0141, val_mae: 0.0197\n",
      "Epoch [144/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0134\n",
      "Epoch [145/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0152\n",
      "Epoch [146/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0143, val_mae: 0.0161\n",
      "Epoch [147/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0138\n",
      "Epoch [148/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0148\n",
      "Epoch [149/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0135\n",
      "Epoch [150/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0143, val_mae: 0.0161\n",
      "Epoch [151/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0143\n",
      "Epoch [152/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0133\n",
      "Epoch [153/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0134\n",
      "Epoch [154/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0132\n",
      "Epoch [155/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0138\n",
      "Epoch [156/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [157/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0140, val_mae: 0.0159\n",
      "Epoch [158/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0128\n",
      "Epoch [159/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0137\n",
      "Epoch [160/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0141, val_mae: 0.0187\n",
      "Epoch [161/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [162/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0141\n",
      "Epoch [163/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0140, val_mae: 0.0150\n",
      "Epoch [164/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0140, val_mae: 0.0155\n",
      "Epoch [165/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0144\n",
      "Epoch [166/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0142, val_mae: 0.0161\n",
      "Epoch [167/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0144\n",
      "Epoch [168/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0137\n",
      "Epoch [169/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [170/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0128\n",
      "Epoch [171/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0138\n",
      "Epoch [172/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0126\n",
      "Epoch [173/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0125\n",
      "Epoch [174/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0136\n",
      "Epoch [175/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0138, val_mae: 0.0163\n",
      "Epoch [176/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0134\n",
      "Epoch [177/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0140\n",
      "Epoch [178/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0122\n",
      "Epoch [179/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0138\n",
      "Epoch [180/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0141\n",
      "Epoch [181/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0135, val_mae: 0.0169\n",
      "Epoch [182/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0136, val_mae: 0.0147\n",
      "Epoch [183/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0143\n",
      "Epoch [184/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0133\n",
      "Epoch [185/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0137\n",
      "Epoch [186/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0129\n",
      "Epoch [187/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [188/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0126\n",
      "Epoch [189/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0127\n",
      "Epoch [190/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0128\n",
      "Epoch [191/1000] - train_loss: 0.0003, val_loss: 0.0006, train_mae: 0.0136, val_mae: 0.0193\n",
      "Epoch [192/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0140\n",
      "Epoch [193/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [194/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0132\n",
      "Epoch [195/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0134\n",
      "Epoch [196/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0137\n",
      "Epoch [197/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0134\n",
      "Epoch [198/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0127\n",
      "Epoch [199/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0131, val_mae: 0.0121\n",
      "Epoch [200/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0129\n",
      "Epoch [201/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0132, val_mae: 0.0155\n",
      "Epoch [202/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0132, val_mae: 0.0117\n",
      "Epoch [203/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [204/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0130, val_mae: 0.0119\n",
      "Epoch [205/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0139\n",
      "Epoch [206/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0134\n",
      "Epoch [207/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [208/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0117\n",
      "Epoch [209/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0134\n",
      "Epoch [210/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0137\n",
      "Epoch [211/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0129\n",
      "Epoch [212/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0120\n",
      "Epoch [213/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0129, val_mae: 0.0116\n",
      "Epoch [214/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0130\n",
      "Epoch [215/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0129\n",
      "Epoch [216/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0122\n",
      "Epoch [217/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [218/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0138\n",
      "Epoch [219/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0129, val_mae: 0.0119\n",
      "Epoch [220/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0136\n",
      "Epoch [221/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0114\n",
      "Epoch [222/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0129\n",
      "Epoch [223/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0129, val_mae: 0.0120\n",
      "Epoch [224/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0123, val_mae: 0.0124\n",
      "Epoch [225/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0124\n",
      "Epoch [226/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0136\n",
      "Epoch [227/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0124, val_mae: 0.0126\n",
      "Epoch [228/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0130\n",
      "Epoch [229/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0136\n",
      "Epoch [230/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0119\n",
      "Epoch [231/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0134\n",
      "Epoch [232/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0123, val_mae: 0.0123\n",
      "Epoch [233/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0123, val_mae: 0.0157\n",
      "Epoch [234/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0120\n",
      "Epoch [235/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0123, val_mae: 0.0136\n",
      "Epoch [236/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [237/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0122\n",
      "Epoch [238/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0120\n",
      "Epoch [239/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0120\n",
      "Epoch [240/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0119\n",
      "Epoch [241/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0118\n",
      "Epoch [242/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0122\n",
      "Epoch [243/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0118\n",
      "Epoch [244/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0111\n",
      "Epoch [245/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0123, val_mae: 0.0129\n",
      "Epoch [246/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0109\n",
      "Epoch [247/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [248/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0121, val_mae: 0.0153\n",
      "Epoch [249/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0120\n",
      "Epoch [250/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0122, val_mae: 0.0135\n",
      "Epoch [251/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [252/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0123\n",
      "Epoch [253/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0113\n",
      "Epoch [254/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0120, val_mae: 0.0149\n",
      "Epoch [255/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0116\n",
      "Epoch [256/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0119\n",
      "Epoch [257/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0122, val_mae: 0.0126\n",
      "Epoch [258/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0121, val_mae: 0.0141\n",
      "Epoch [259/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0116\n",
      "Epoch [260/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0121, val_mae: 0.0128\n",
      "Epoch [261/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0118\n",
      "Epoch [262/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0122, val_mae: 0.0132\n",
      "Epoch [263/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [264/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0120\n",
      "Epoch [265/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0120, val_mae: 0.0127\n",
      "Epoch [266/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0115\n",
      "Epoch [267/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0108\n",
      "Epoch [268/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0120, val_mae: 0.0124\n",
      "Epoch [269/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0118, val_mae: 0.0127\n",
      "Epoch [270/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0117\n",
      "Epoch [271/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0109\n",
      "Epoch [272/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0120, val_mae: 0.0128\n",
      "Epoch [273/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0120, val_mae: 0.0163\n",
      "Epoch [274/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [275/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [276/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0120, val_mae: 0.0151\n",
      "Epoch [277/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0118, val_mae: 0.0132\n",
      "Epoch [278/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0117, val_mae: 0.0136\n",
      "Epoch [279/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0107\n",
      "Epoch [280/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0121\n",
      "Epoch [281/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0117, val_mae: 0.0141\n",
      "Epoch [282/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0119, val_mae: 0.0127\n",
      "Epoch [283/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0116\n",
      "Epoch [284/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0118\n",
      "Epoch [285/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0115\n",
      "Epoch [286/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0117\n",
      "Epoch [287/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0119, val_mae: 0.0128\n",
      "Epoch [288/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0114\n",
      "Epoch [289/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0116\n",
      "Epoch [290/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0107\n",
      "Epoch [291/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0113\n",
      "Epoch [292/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0118, val_mae: 0.0127\n",
      "Epoch [293/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0118, val_mae: 0.0128\n",
      "Epoch [294/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0117, val_mae: 0.0124\n",
      "Epoch [295/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0117\n",
      "Epoch [296/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0112\n",
      "Epoch [297/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0115\n",
      "Epoch [298/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0105\n",
      "Epoch [299/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0110\n",
      "Epoch [300/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0119\n",
      "Epoch [301/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0114\n",
      "Epoch [302/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0106\n",
      "Epoch [303/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0107\n",
      "Epoch [304/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0115\n",
      "Epoch [305/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0114\n",
      "Epoch [306/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [307/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0120\n",
      "Epoch [308/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0107\n",
      "Epoch [309/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0116, val_mae: 0.0128\n",
      "Epoch [310/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0116\n",
      "Epoch [311/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0119\n",
      "Epoch [312/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0104\n",
      "Epoch [313/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0119\n",
      "Epoch [314/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0117, val_mae: 0.0124\n",
      "Epoch [315/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0108\n",
      "Epoch [316/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0115, val_mae: 0.0129\n",
      "Epoch [317/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0121\n",
      "Epoch [318/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0121\n",
      "Epoch [319/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0103\n",
      "Epoch [320/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0110\n",
      "Epoch [321/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0110\n",
      "Epoch [322/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0115\n",
      "Epoch [323/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [324/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0106\n",
      "Epoch [325/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0106\n",
      "Epoch [326/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0118, val_mae: 0.0136\n",
      "Epoch [327/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0112\n",
      "Epoch [328/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0118, val_mae: 0.0127\n",
      "Epoch [329/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0107\n",
      "Epoch [330/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0114, val_mae: 0.0131\n",
      "Epoch [331/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0117\n",
      "Epoch [332/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0104\n",
      "Epoch [333/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0110\n",
      "Epoch [334/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0117\n",
      "Epoch [335/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0113\n",
      "Epoch [336/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0104\n",
      "Epoch [337/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0106\n",
      "Epoch [338/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0124\n",
      "Epoch [339/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0115, val_mae: 0.0151\n",
      "Epoch [340/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0103\n",
      "Epoch [341/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0114\n",
      "Epoch [342/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0118\n",
      "Epoch [343/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0113\n",
      "Epoch [344/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0112\n",
      "Epoch [345/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0103\n",
      "Epoch [346/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0119\n",
      "Epoch [347/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0123\n",
      "Epoch [348/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0108\n",
      "Epoch [349/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0113\n",
      "Epoch [350/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0105\n",
      "Epoch [351/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0103\n",
      "Epoch [352/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0114\n",
      "Epoch [353/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0106\n",
      "Epoch [354/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0109\n",
      "Epoch [355/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0101\n",
      "Epoch [356/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0108\n",
      "Epoch [357/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0119\n",
      "Epoch [358/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0121\n",
      "Epoch [359/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0117\n",
      "Epoch [360/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0120\n",
      "Epoch [361/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0114, val_mae: 0.0140\n",
      "Epoch [362/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0117\n",
      "Epoch [363/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0106\n",
      "Epoch [364/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0115\n",
      "Epoch [365/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0114, val_mae: 0.0141\n",
      "Epoch [366/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0120\n",
      "Epoch [367/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0114, val_mae: 0.0171\n",
      "Epoch [368/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0115\n",
      "Epoch [369/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0108\n",
      "Epoch [370/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0106\n",
      "Epoch [371/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0113, val_mae: 0.0148\n",
      "Epoch [372/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0119\n",
      "Epoch [373/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0113, val_mae: 0.0159\n",
      "Epoch [374/1000] - train_loss: 0.0002, val_loss: 0.0006, train_mae: 0.0113, val_mae: 0.0200\n",
      "Epoch [375/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0104\n",
      "Epoch [376/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0101\n",
      "Epoch [377/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0116\n",
      "Epoch [378/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0101\n",
      "Epoch [379/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0122\n",
      "Epoch [380/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0105\n",
      "Epoch [381/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0108\n",
      "Epoch [382/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0106\n",
      "Epoch [383/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0115\n",
      "Epoch [384/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0113\n",
      "Epoch [385/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0113\n",
      "Epoch [386/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0099\n",
      "Epoch [387/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0113, val_mae: 0.0159\n",
      "Epoch [388/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0111, val_mae: 0.0126\n",
      "Epoch [389/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0110\n",
      "Epoch [390/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0114\n",
      "Epoch [391/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0111, val_mae: 0.0132\n",
      "Epoch [392/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0105\n",
      "Epoch [393/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0112, val_mae: 0.0129\n",
      "Epoch [394/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0104\n",
      "Epoch [395/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0097\n",
      "Epoch [396/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0112, val_mae: 0.0126\n",
      "Epoch [397/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0111, val_mae: 0.0126\n",
      "Epoch [398/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0112\n",
      "Epoch [399/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0101\n",
      "Epoch [400/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0111, val_mae: 0.0148\n",
      "Epoch [401/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0105\n",
      "Epoch [402/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0107\n",
      "Epoch [403/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0112, val_mae: 0.0135\n",
      "Epoch [404/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0117\n",
      "Epoch [405/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0103\n",
      "Epoch [406/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0111\n",
      "Epoch [407/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0115\n",
      "Epoch [408/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0112\n",
      "Epoch [409/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0105\n",
      "Epoch [410/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0111\n",
      "Epoch [411/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0107\n",
      "Epoch [412/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0109\n",
      "Epoch [413/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0111, val_mae: 0.0130\n",
      "Epoch [414/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0105\n",
      "Epoch [415/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0108\n",
      "Epoch [416/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0109\n",
      "Epoch [417/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0119\n",
      "Epoch [418/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0122\n",
      "Epoch [419/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0102\n",
      "Epoch [420/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0101\n",
      "Epoch [421/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0106\n",
      "Epoch [422/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0106\n",
      "Epoch [423/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0113, val_mae: 0.0127\n",
      "Epoch [424/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0105\n",
      "Epoch [425/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0102\n",
      "Epoch [426/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0122\n",
      "Epoch [427/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0109, val_mae: 0.0145\n",
      "Epoch [428/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0113\n",
      "Epoch [429/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0103\n",
      "Epoch [430/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0110\n",
      "Epoch [431/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0113\n",
      "Epoch [432/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0110\n",
      "Epoch [433/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0110\n",
      "Epoch [434/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0103\n",
      "Epoch [435/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0114\n",
      "Epoch [436/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0105\n",
      "Epoch [437/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0110\n",
      "Epoch [438/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0115\n",
      "Epoch [439/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0105\n",
      "Epoch [440/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0114\n",
      "Epoch [441/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0103\n",
      "Epoch [442/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0105\n",
      "Epoch [443/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0113\n",
      "Epoch [444/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0118\n",
      "Epoch [445/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0109, val_mae: 0.0127\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "train_losses3x30, val_losses3x30, train_maes3x30, val_maes3x30, best_state3x30 = train_loop(net3x30, train_dataloader, val_dataloader, patience=50, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "net6x50 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - train_loss: 0.0123, val_loss: 0.0032, train_mae: 0.0737, val_mae: 0.0450\n",
      "Epoch [2/1000] - train_loss: 0.0029, val_loss: 0.0029, train_mae: 0.0425, val_mae: 0.0423\n",
      "Epoch [3/1000] - train_loss: 0.0022, val_loss: 0.0020, train_mae: 0.0372, val_mae: 0.0359\n",
      "Epoch [4/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0335\n",
      "Epoch [5/1000] - train_loss: 0.0015, val_loss: 0.0012, train_mae: 0.0304, val_mae: 0.0266\n",
      "Epoch [6/1000] - train_loss: 0.0013, val_loss: 0.0012, train_mae: 0.0286, val_mae: 0.0279\n",
      "Epoch [7/1000] - train_loss: 0.0012, val_loss: 0.0011, train_mae: 0.0269, val_mae: 0.0262\n",
      "Epoch [8/1000] - train_loss: 0.0011, val_loss: 0.0009, train_mae: 0.0255, val_mae: 0.0241\n",
      "Epoch [9/1000] - train_loss: 0.0010, val_loss: 0.0014, train_mae: 0.0246, val_mae: 0.0302\n",
      "Epoch [10/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0237, val_mae: 0.0242\n",
      "Epoch [11/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0233, val_mae: 0.0223\n",
      "Epoch [12/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0220, val_mae: 0.0204\n",
      "Epoch [13/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0218, val_mae: 0.0212\n",
      "Epoch [14/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0213, val_mae: 0.0222\n",
      "Epoch [15/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0203, val_mae: 0.0199\n",
      "Epoch [16/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0203, val_mae: 0.0213\n",
      "Epoch [17/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0197, val_mae: 0.0201\n",
      "Epoch [18/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0193, val_mae: 0.0172\n",
      "Epoch [19/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0186, val_mae: 0.0170\n",
      "Epoch [20/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0181, val_mae: 0.0167\n",
      "Epoch [21/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0184, val_mae: 0.0174\n",
      "Epoch [22/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0177, val_mae: 0.0170\n",
      "Epoch [23/1000] - train_loss: 0.0005, val_loss: 0.0007, train_mae: 0.0174, val_mae: 0.0209\n",
      "Epoch [24/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0171, val_mae: 0.0153\n",
      "Epoch [25/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0168, val_mae: 0.0152\n",
      "Epoch [26/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0156\n",
      "Epoch [27/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0177\n",
      "Epoch [28/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0149\n",
      "Epoch [29/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0167\n",
      "Epoch [30/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0151\n",
      "Epoch [31/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0152, val_mae: 0.0141\n",
      "Epoch [32/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0154\n",
      "Epoch [33/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0145\n",
      "Epoch [34/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0140\n",
      "Epoch [35/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0128\n",
      "Epoch [36/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0135\n",
      "Epoch [37/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0130\n",
      "Epoch [38/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0139, val_mae: 0.0162\n",
      "Epoch [39/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0143\n",
      "Epoch [40/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0137, val_mae: 0.0119\n",
      "Epoch [41/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0132\n",
      "Epoch [42/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0135, val_mae: 0.0167\n",
      "Epoch [43/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0131\n",
      "Epoch [44/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [45/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [46/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [47/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0133\n",
      "Epoch [48/1000] - train_loss: 0.0003, val_loss: 0.0004, train_mae: 0.0131, val_mae: 0.0157\n",
      "Epoch [49/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0129\n",
      "Epoch [50/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0108\n",
      "Epoch [51/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0124, val_mae: 0.0137\n",
      "Epoch [52/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0120\n",
      "Epoch [53/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0113\n",
      "Epoch [54/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0122, val_mae: 0.0129\n",
      "Epoch [55/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0116\n",
      "Epoch [56/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0105\n",
      "Epoch [57/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0123\n",
      "Epoch [58/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0109\n",
      "Epoch [59/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0120\n",
      "Epoch [60/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0118\n",
      "Epoch [61/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0119, val_mae: 0.0128\n",
      "Epoch [62/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [63/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0117, val_mae: 0.0132\n",
      "Epoch [64/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0106\n",
      "Epoch [65/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0105\n",
      "Epoch [66/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0106\n",
      "Epoch [67/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0107\n",
      "Epoch [68/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0116, val_mae: 0.0128\n",
      "Epoch [69/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0113, val_mae: 0.0128\n",
      "Epoch [70/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0115\n",
      "Epoch [71/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0101\n",
      "Epoch [72/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0111\n",
      "Epoch [73/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0109\n",
      "Epoch [74/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0112\n",
      "Epoch [75/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0101\n",
      "Epoch [76/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0102\n",
      "Epoch [77/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0102\n",
      "Epoch [78/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0113\n",
      "Epoch [79/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0113\n",
      "Epoch [80/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0108, val_mae: 0.0099\n",
      "Epoch [81/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0106, val_mae: 0.0099\n",
      "Epoch [82/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0124\n",
      "Epoch [83/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0109, val_mae: 0.0152\n",
      "Epoch [84/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0106, val_mae: 0.0095\n",
      "Epoch [85/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0107, val_mae: 0.0111\n",
      "Epoch [86/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0106, val_mae: 0.0095\n",
      "Epoch [87/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0106, val_mae: 0.0098\n",
      "Epoch [88/1000] - train_loss: 0.0002, val_loss: 0.0005, train_mae: 0.0106, val_mae: 0.0172\n",
      "Epoch [89/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0104, val_mae: 0.0106\n",
      "Epoch [90/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0104, val_mae: 0.0099\n",
      "Epoch [91/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0106, val_mae: 0.0101\n",
      "Epoch [92/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0107\n",
      "Epoch [93/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0104, val_mae: 0.0102\n",
      "Epoch [94/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0104, val_mae: 0.0111\n",
      "Epoch [95/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0104, val_mae: 0.0125\n",
      "Epoch [96/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0101, val_mae: 0.0127\n",
      "Epoch [97/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0102, val_mae: 0.0097\n",
      "Epoch [98/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0102, val_mae: 0.0092\n",
      "Epoch [99/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0103, val_mae: 0.0100\n",
      "Epoch [100/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0101, val_mae: 0.0092\n",
      "Epoch [101/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0107\n",
      "Epoch [102/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0101, val_mae: 0.0090\n",
      "Epoch [103/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0099\n",
      "Epoch [104/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0099, val_mae: 0.0091\n",
      "Epoch [105/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0096\n",
      "Epoch [106/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0098, val_mae: 0.0120\n",
      "Epoch [107/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0103, val_mae: 0.0093\n",
      "Epoch [108/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0117\n",
      "Epoch [109/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0100, val_mae: 0.0106\n",
      "Epoch [110/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0102\n",
      "Epoch [111/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0099, val_mae: 0.0094\n",
      "Epoch [112/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0108\n",
      "Epoch [113/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0099\n",
      "Epoch [114/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0098, val_mae: 0.0103\n",
      "Epoch [115/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0109\n",
      "Epoch [116/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0098, val_mae: 0.0122\n",
      "Epoch [117/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0098, val_mae: 0.0099\n",
      "Epoch [118/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0096, val_mae: 0.0088\n",
      "Epoch [119/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0097, val_mae: 0.0092\n",
      "Epoch [120/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0098\n",
      "Epoch [121/1000] - train_loss: 0.0002, val_loss: 0.0003, train_mae: 0.0096, val_mae: 0.0134\n",
      "Epoch [122/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0096, val_mae: 0.0090\n",
      "Epoch [123/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0097, val_mae: 0.0090\n",
      "Epoch [124/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0100\n",
      "Epoch [125/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0095, val_mae: 0.0094\n",
      "Epoch [126/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0098, val_mae: 0.0091\n",
      "Epoch [127/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0105\n",
      "Epoch [128/1000] - train_loss: 0.0001, val_loss: 0.0004, train_mae: 0.0093, val_mae: 0.0156\n",
      "Epoch [129/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0095, val_mae: 0.0094\n",
      "Epoch [130/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0100\n",
      "Epoch [131/1000] - train_loss: 0.0001, val_loss: 0.0003, train_mae: 0.0095, val_mae: 0.0151\n",
      "Epoch [132/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0100\n",
      "Epoch [133/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0097\n",
      "Epoch [134/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0112\n",
      "Epoch [135/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0112\n",
      "Epoch [136/1000] - train_loss: 0.0001, val_loss: 0.0003, train_mae: 0.0093, val_mae: 0.0138\n",
      "Epoch [137/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0102\n",
      "Epoch [138/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0105\n",
      "Epoch [139/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0093, val_mae: 0.0106\n",
      "Epoch [140/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0089\n",
      "Epoch [141/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0093, val_mae: 0.0103\n",
      "Epoch [142/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0092, val_mae: 0.0098\n",
      "Epoch [143/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0088\n",
      "Epoch [144/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0094, val_mae: 0.0091\n",
      "Epoch [145/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0082\n",
      "Epoch [146/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0090, val_mae: 0.0097\n",
      "Epoch [147/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0089\n",
      "Epoch [148/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0084\n",
      "Epoch [149/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0087\n",
      "Epoch [150/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0090, val_mae: 0.0108\n",
      "Epoch [151/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0090, val_mae: 0.0099\n",
      "Epoch [152/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0087\n",
      "Epoch [153/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0081\n",
      "Epoch [154/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0081\n",
      "Epoch [155/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0090, val_mae: 0.0107\n",
      "Epoch [156/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0091, val_mae: 0.0103\n",
      "Epoch [157/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0090, val_mae: 0.0095\n",
      "Epoch [158/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0090, val_mae: 0.0104\n",
      "Epoch [159/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0081\n",
      "Epoch [160/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0084\n",
      "Epoch [161/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [162/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0094\n",
      "Epoch [163/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0084\n",
      "Epoch [164/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [165/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0083\n",
      "Epoch [166/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0092\n",
      "Epoch [167/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0086\n",
      "Epoch [168/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0089, val_mae: 0.0104\n",
      "Epoch [169/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0090, val_mae: 0.0107\n",
      "Epoch [170/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0078\n",
      "Epoch [171/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0087\n",
      "Epoch [172/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0088, val_mae: 0.0104\n",
      "Epoch [173/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0082\n",
      "Epoch [174/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0079\n",
      "Epoch [175/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0084\n",
      "Epoch [176/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0088\n",
      "Epoch [177/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0087\n",
      "Epoch [178/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0086\n",
      "Epoch [179/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0079\n",
      "Epoch [180/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0088\n",
      "Epoch [181/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0078\n",
      "Epoch [182/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0088\n",
      "Epoch [183/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0081\n",
      "Epoch [184/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0085, val_mae: 0.0083\n",
      "Epoch [185/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0092\n",
      "Epoch [186/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0085, val_mae: 0.0089\n",
      "Epoch [187/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0083\n",
      "Epoch [188/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0085, val_mae: 0.0090\n",
      "Epoch [189/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0111\n",
      "Epoch [190/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0085, val_mae: 0.0083\n",
      "Epoch [191/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0085\n",
      "Epoch [192/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0083\n",
      "Epoch [193/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0085, val_mae: 0.0087\n",
      "Epoch [194/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0075\n",
      "Epoch [195/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0123\n",
      "Epoch [196/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0087\n",
      "Epoch [197/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0079\n",
      "Epoch [198/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0091\n",
      "Epoch [199/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0086, val_mae: 0.0075\n",
      "Epoch [200/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0088\n",
      "Epoch [201/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0110\n",
      "Epoch [202/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0086\n",
      "Epoch [203/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0085, val_mae: 0.0080\n",
      "Epoch [204/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0085\n",
      "Epoch [205/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0124\n",
      "Epoch [206/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0081\n",
      "Epoch [207/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0089\n",
      "Epoch [208/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0095\n",
      "Epoch [209/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0081, val_mae: 0.0100\n",
      "Epoch [210/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0079\n",
      "Epoch [211/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0080\n",
      "Epoch [212/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0085\n",
      "Epoch [213/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0082, val_mae: 0.0082\n",
      "Epoch [214/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0082, val_mae: 0.0091\n",
      "Epoch [215/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0091\n",
      "Epoch [216/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0082, val_mae: 0.0105\n",
      "Epoch [217/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0076\n",
      "Epoch [218/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0081, val_mae: 0.0080\n",
      "Epoch [219/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0082, val_mae: 0.0112\n",
      "Epoch [220/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0082, val_mae: 0.0117\n",
      "Epoch [221/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0082, val_mae: 0.0073\n",
      "Epoch [222/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0076\n",
      "Epoch [223/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0081\n",
      "Epoch [224/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0081, val_mae: 0.0081\n",
      "Epoch [225/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0082, val_mae: 0.0095\n",
      "Epoch [226/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0076\n",
      "Epoch [227/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0082, val_mae: 0.0082\n",
      "Epoch [228/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0080, val_mae: 0.0101\n",
      "Epoch [229/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0081, val_mae: 0.0097\n",
      "Epoch [230/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0077\n",
      "Epoch [231/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0076\n",
      "Epoch [232/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0081, val_mae: 0.0093\n",
      "Epoch [233/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0096\n",
      "Epoch [234/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0078\n",
      "Epoch [235/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0074\n",
      "Epoch [236/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0092\n",
      "Epoch [237/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0079, val_mae: 0.0098\n",
      "Epoch [238/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0082, val_mae: 0.0089\n",
      "Epoch [239/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0078\n",
      "Epoch [240/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0081, val_mae: 0.0075\n",
      "Epoch [241/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0091\n",
      "Epoch [242/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0077\n",
      "Epoch [243/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0076\n",
      "Epoch [244/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0075\n",
      "Epoch [245/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0077\n",
      "Epoch [246/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0075\n",
      "Epoch [247/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0076\n",
      "Epoch [248/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0077\n",
      "Epoch [249/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0079\n",
      "Epoch [250/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0078\n",
      "Epoch [251/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0080, val_mae: 0.0100\n",
      "Epoch [252/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0081\n",
      "Epoch [253/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0075\n",
      "Epoch [254/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0078, val_mae: 0.0098\n",
      "Epoch [255/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0083\n",
      "Epoch [256/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0078\n",
      "Epoch [257/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0079, val_mae: 0.0118\n",
      "Epoch [258/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0080\n",
      "Epoch [259/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0072\n",
      "Epoch [260/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0079\n",
      "Epoch [261/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0083\n",
      "Epoch [262/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0088\n",
      "Epoch [263/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0073\n",
      "Epoch [264/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0083\n",
      "Epoch [265/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0076\n",
      "Epoch [266/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0077\n",
      "Epoch [267/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0077\n",
      "Epoch [268/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0074\n",
      "Epoch [269/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0076\n",
      "Epoch [270/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0078, val_mae: 0.0100\n",
      "Epoch [271/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0077\n",
      "Epoch [272/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0073\n",
      "Epoch [273/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0080\n",
      "Epoch [274/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0090\n",
      "Epoch [275/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0082\n",
      "Epoch [276/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0086\n",
      "Epoch [277/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0077\n",
      "Epoch [278/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0077, val_mae: 0.0078\n",
      "Epoch [279/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0078\n",
      "Epoch [280/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0075\n",
      "Epoch [281/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0076\n",
      "Epoch [282/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0090\n",
      "Epoch [283/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0074\n",
      "Epoch [284/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0076, val_mae: 0.0102\n",
      "Epoch [285/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0087\n",
      "Epoch [286/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0076\n",
      "Epoch [287/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0072\n",
      "Epoch [288/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0074\n",
      "Epoch [289/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0073\n",
      "Epoch [290/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0072\n",
      "Epoch [291/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0096\n",
      "Epoch [292/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0084\n",
      "Epoch [293/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0078\n",
      "Epoch [294/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0076, val_mae: 0.0089\n",
      "Epoch [295/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0075, val_mae: 0.0104\n",
      "Epoch [296/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0080\n",
      "Epoch [297/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0073, val_mae: 0.0114\n",
      "Epoch [298/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0079\n",
      "Epoch [299/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0079\n",
      "Epoch [300/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0076\n",
      "Epoch [301/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0079\n",
      "Epoch [302/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0072\n",
      "Epoch [303/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0071\n",
      "Epoch [304/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0092\n",
      "Epoch [305/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0072\n",
      "Epoch [306/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0082\n",
      "Epoch [307/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0071\n",
      "Epoch [308/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0071\n",
      "Epoch [309/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0069\n",
      "Epoch [310/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0070\n",
      "Epoch [311/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0077\n",
      "Epoch [312/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0070\n",
      "Epoch [313/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0069\n",
      "Epoch [314/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0083\n",
      "Epoch [315/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0075\n",
      "Epoch [316/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0079\n",
      "Epoch [317/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0082\n",
      "Epoch [318/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0072, val_mae: 0.0125\n",
      "Epoch [319/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0076\n",
      "Epoch [320/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0071\n",
      "Epoch [321/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0072\n",
      "Epoch [322/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0073, val_mae: 0.0099\n",
      "Epoch [323/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0077\n",
      "Epoch [324/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0081\n",
      "Epoch [325/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0069\n",
      "Epoch [326/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0081\n",
      "Epoch [327/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0066\n",
      "Epoch [328/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0068\n",
      "Epoch [329/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0065\n",
      "Epoch [330/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0079\n",
      "Epoch [331/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0080\n",
      "Epoch [332/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0084\n",
      "Epoch [333/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0075\n",
      "Epoch [334/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0070\n",
      "Epoch [335/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0069\n",
      "Epoch [336/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0066\n",
      "Epoch [337/1000] - train_loss: 0.0001, val_loss: 0.0003, train_mae: 0.0074, val_mae: 0.0131\n",
      "Epoch [338/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0072\n",
      "Epoch [339/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0092\n",
      "Epoch [340/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0071\n",
      "Epoch [341/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0075\n",
      "Epoch [342/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0073\n",
      "Epoch [343/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0081\n",
      "Epoch [344/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0081\n",
      "Epoch [345/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0078\n",
      "Epoch [346/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0082\n",
      "Epoch [347/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0086\n",
      "Epoch [348/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0072\n",
      "Epoch [349/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0077\n",
      "Epoch [350/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0078\n",
      "Epoch [351/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0081\n",
      "Epoch [352/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0071\n",
      "Epoch [353/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0070\n",
      "Epoch [354/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0067\n",
      "Epoch [355/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0069\n",
      "Epoch [356/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0080\n",
      "Epoch [357/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0078\n",
      "Epoch [358/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0092\n",
      "Epoch [359/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0068\n",
      "Epoch [360/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0070, val_mae: 0.0097\n",
      "Epoch [361/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0068\n",
      "Epoch [362/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0067\n",
      "Epoch [363/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0068\n",
      "Epoch [364/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0079\n",
      "Epoch [365/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0074\n",
      "Epoch [366/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0072\n",
      "Epoch [367/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0075\n",
      "Epoch [368/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0070, val_mae: 0.0070\n",
      "Epoch [369/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0068, val_mae: 0.0100\n",
      "Epoch [370/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0070\n",
      "Epoch [371/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0069\n",
      "Epoch [372/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0071\n",
      "Epoch [373/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0065\n",
      "Epoch [374/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0069, val_mae: 0.0111\n",
      "Epoch [375/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0065\n",
      "Epoch [376/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0070\n",
      "Epoch [377/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0074\n",
      "Epoch [378/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0068\n",
      "Epoch [379/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0063\n",
      "Epoch [380/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0078\n",
      "Epoch [381/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0070\n",
      "Epoch [382/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0071\n",
      "Epoch [383/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0072\n",
      "Epoch [384/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0064\n",
      "Epoch [385/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0069\n",
      "Epoch [386/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0068\n",
      "Epoch [387/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0074\n",
      "Epoch [388/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0070\n",
      "Epoch [389/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0066\n",
      "Epoch [390/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0060\n",
      "Epoch [391/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0066\n",
      "Epoch [392/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0070\n",
      "Epoch [393/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0065\n",
      "Epoch [394/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0071\n",
      "Epoch [395/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0075\n",
      "Epoch [396/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0070\n",
      "Epoch [397/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0084\n",
      "Epoch [398/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0078\n",
      "Epoch [399/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0091\n",
      "Epoch [400/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0099\n",
      "Epoch [401/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0061\n",
      "Epoch [402/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0063\n",
      "Epoch [403/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0066, val_mae: 0.0102\n",
      "Epoch [404/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0067\n",
      "Epoch [405/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0081\n",
      "Epoch [406/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0078\n",
      "Epoch [407/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0063\n",
      "Epoch [408/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0063\n",
      "Epoch [409/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0059\n",
      "Epoch [410/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0077\n",
      "Epoch [411/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0074\n",
      "Epoch [412/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0073\n",
      "Epoch [413/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0065\n",
      "Epoch [414/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0064\n",
      "Epoch [415/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0065\n",
      "Epoch [416/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0066, val_mae: 0.0104\n",
      "Epoch [417/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0074\n",
      "Epoch [418/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0065\n",
      "Epoch [419/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0066\n",
      "Epoch [420/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0076\n",
      "Epoch [421/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0071\n",
      "Epoch [422/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0066\n",
      "Epoch [423/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0077\n",
      "Epoch [424/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0063\n",
      "Epoch [425/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0063\n",
      "Epoch [426/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0063\n",
      "Epoch [427/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0063\n",
      "Epoch [428/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0070\n",
      "Epoch [429/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0060\n",
      "Epoch [430/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0077\n",
      "Epoch [431/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0060\n",
      "Epoch [432/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0067\n",
      "Epoch [433/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0066\n",
      "Epoch [434/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0062\n",
      "Epoch [435/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0063\n",
      "Epoch [436/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0063\n",
      "Epoch [437/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0067\n",
      "Epoch [438/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0068\n",
      "Epoch [439/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0060\n",
      "Epoch [440/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0060\n",
      "Epoch [441/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0058\n",
      "Epoch [442/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0066\n",
      "Epoch [443/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0067\n",
      "Epoch [444/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0064\n",
      "Epoch [445/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0059\n",
      "Epoch [446/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0084\n",
      "Epoch [447/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0062\n",
      "Epoch [448/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0060\n",
      "Epoch [449/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0067\n",
      "Epoch [450/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0097\n",
      "Epoch [451/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0061\n",
      "Epoch [452/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0069\n",
      "Epoch [453/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0059\n",
      "Epoch [454/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0069\n",
      "Epoch [455/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0086\n",
      "Epoch [456/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0067\n",
      "Epoch [457/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0087\n",
      "Epoch [458/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0066\n",
      "Epoch [459/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0067\n",
      "Epoch [460/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0057\n",
      "Epoch [461/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0067\n",
      "Epoch [462/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0059\n",
      "Epoch [463/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0083\n",
      "Epoch [464/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0062\n",
      "Epoch [465/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0061\n",
      "Epoch [466/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0095\n",
      "Epoch [467/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0066\n",
      "Epoch [468/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0077\n",
      "Epoch [469/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0067\n",
      "Epoch [470/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0065\n",
      "Epoch [471/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0075\n",
      "Epoch [472/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0078\n",
      "Epoch [473/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0063\n",
      "Epoch [474/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0060\n",
      "Epoch [475/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0062\n",
      "Epoch [476/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0066\n",
      "Epoch [477/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0064, val_mae: 0.0060\n",
      "Epoch [478/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0060\n",
      "Epoch [479/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0060\n",
      "Epoch [480/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0064\n",
      "Epoch [481/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0070\n",
      "Epoch [482/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0059\n",
      "Epoch [483/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0062\n",
      "Epoch [484/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0064\n",
      "Epoch [485/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0075\n",
      "Epoch [486/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0060\n",
      "Epoch [487/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0088\n",
      "Epoch [488/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0056\n",
      "Epoch [489/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0059\n",
      "Epoch [490/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0060\n",
      "Epoch [491/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0056\n",
      "Epoch [492/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0058\n",
      "Epoch [493/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0072\n",
      "Epoch [494/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0065\n",
      "Epoch [495/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0064\n",
      "Epoch [496/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0070\n",
      "Epoch [497/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0058\n",
      "Epoch [498/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0078\n",
      "Epoch [499/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0056\n",
      "Epoch [500/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0060\n",
      "Epoch [501/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0060\n",
      "Epoch [502/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0059\n",
      "Epoch [503/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0066\n",
      "Epoch [504/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0056\n",
      "Epoch [505/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0060\n",
      "Epoch [506/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0078\n",
      "Epoch [507/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0092\n",
      "Epoch [508/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0066\n",
      "Epoch [509/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0072\n",
      "Epoch [510/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0068\n",
      "Epoch [511/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0066\n",
      "Epoch [512/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0069\n",
      "Epoch [513/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0068\n",
      "Epoch [514/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0059\n",
      "Epoch [515/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0064\n",
      "Epoch [516/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0063\n",
      "Epoch [517/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0060\n",
      "Epoch [518/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0060\n",
      "Epoch [519/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0059\n",
      "Epoch [520/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0069\n",
      "Epoch [521/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0065\n",
      "Epoch [522/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0079\n",
      "Epoch [523/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0058\n",
      "Epoch [524/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0071\n",
      "Epoch [525/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0061\n",
      "Epoch [526/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0058\n",
      "Epoch [527/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0059\n",
      "Epoch [528/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0075\n",
      "Epoch [529/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [530/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0063\n",
      "Epoch [531/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0064\n",
      "Epoch [532/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0064\n",
      "Epoch [533/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0060\n",
      "Epoch [534/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0057\n",
      "Epoch [535/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0074\n",
      "Epoch [536/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0070\n",
      "Epoch [537/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0055\n",
      "Epoch [538/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0067\n",
      "Epoch [539/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0070\n",
      "Epoch [540/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [541/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0068\n",
      "Epoch [542/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0076\n",
      "Epoch [543/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0067\n",
      "Epoch [544/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0058\n",
      "Epoch [545/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [546/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [547/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0058\n",
      "Epoch [548/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0068\n",
      "Epoch [549/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [550/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0063\n",
      "Epoch [551/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0060\n",
      "Epoch [552/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0057\n",
      "Epoch [553/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0071\n",
      "Epoch [554/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0057\n",
      "Epoch [555/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0057\n",
      "Epoch [556/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0058\n",
      "Epoch [557/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0063\n",
      "Epoch [558/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0071\n",
      "Epoch [559/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0087\n",
      "Epoch [560/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0061\n",
      "Epoch [561/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0069\n",
      "Epoch [562/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0064\n",
      "Epoch [563/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0058\n",
      "Epoch [564/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0055\n",
      "Epoch [565/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0068\n",
      "Epoch [566/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0058\n",
      "Epoch [567/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0060\n",
      "Epoch [568/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0058\n",
      "Epoch [569/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0063\n",
      "Epoch [570/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0055\n",
      "Epoch [571/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0059\n",
      "Epoch [572/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0066\n",
      "Epoch [573/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0080\n",
      "Epoch [574/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [575/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0055\n",
      "Epoch [576/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0064\n",
      "Epoch [577/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [578/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0069\n",
      "Epoch [579/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0055\n",
      "Epoch [580/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0070\n",
      "Epoch [581/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0055\n",
      "Epoch [582/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [583/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0078\n",
      "Epoch [584/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0064\n",
      "Epoch [585/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0062\n",
      "Epoch [586/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0061\n",
      "Epoch [587/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0065\n",
      "Epoch [588/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0069\n",
      "Epoch [589/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0066\n",
      "Epoch [590/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0067\n",
      "Epoch [591/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0059\n",
      "Epoch [592/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0062\n",
      "Epoch [593/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0055\n",
      "Epoch [594/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0067\n",
      "Epoch [595/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0053\n",
      "Epoch [596/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0066\n",
      "Epoch [597/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0063\n",
      "Epoch [598/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0059, val_mae: 0.0053\n",
      "Epoch [599/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0053\n",
      "Epoch [600/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0062\n",
      "Epoch [601/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0068\n",
      "Epoch [602/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0055\n",
      "Epoch [603/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0067\n",
      "Epoch [604/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0063\n",
      "Epoch [605/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0055\n",
      "Epoch [606/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0066\n",
      "Epoch [607/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0061\n",
      "Epoch [608/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0090\n",
      "Epoch [609/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0064\n",
      "Epoch [610/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [611/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0058\n",
      "Epoch [612/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0055\n",
      "Epoch [613/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [614/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0066\n",
      "Epoch [615/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0054\n",
      "Epoch [616/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0062\n",
      "Epoch [617/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0070\n",
      "Epoch [618/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0055\n",
      "Epoch [619/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0055\n",
      "Epoch [620/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0060\n",
      "Epoch [621/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0060\n",
      "Epoch [622/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0070\n",
      "Epoch [623/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [624/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0061\n",
      "Epoch [625/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0067\n",
      "Epoch [626/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0053\n",
      "Epoch [627/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0056\n",
      "Epoch [628/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0059\n",
      "Epoch [629/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0061\n",
      "Epoch [630/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0067\n",
      "Epoch [631/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0055\n",
      "Epoch [632/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [633/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0079\n",
      "Epoch [634/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0058\n",
      "Epoch [635/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0066\n",
      "Epoch [636/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0057\n",
      "Epoch [637/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0055\n",
      "Epoch [638/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0059\n",
      "Epoch [639/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0054\n",
      "Epoch [640/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0063\n",
      "Epoch [641/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0054\n",
      "Epoch [642/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0071\n",
      "Epoch [643/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [644/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0056\n",
      "Epoch [645/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0064\n",
      "Epoch [646/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0060\n",
      "Epoch [647/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0053\n",
      "Epoch [648/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0063\n",
      "Epoch [649/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0058, val_mae: 0.0052\n",
      "Epoch [650/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0064\n",
      "Epoch [651/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0062\n",
      "Epoch [652/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0056\n",
      "Epoch [653/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0055\n",
      "Epoch [654/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0067\n",
      "Epoch [655/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0052\n",
      "Epoch [656/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0060\n",
      "Epoch [657/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0071\n",
      "Epoch [658/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0058\n",
      "Epoch [659/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0052\n",
      "Epoch [660/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0069\n",
      "Epoch [661/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0061\n",
      "Epoch [662/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0060\n",
      "Epoch [663/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0057\n",
      "Epoch [664/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0057\n",
      "Epoch [665/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0080\n",
      "Epoch [666/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0057\n",
      "Epoch [667/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0059\n",
      "Epoch [668/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0052\n",
      "Epoch [669/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0055\n",
      "Epoch [670/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0051\n",
      "Epoch [671/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0058\n",
      "Epoch [672/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0063\n",
      "Epoch [673/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0053\n",
      "Epoch [674/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0069\n",
      "Epoch [675/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0055\n",
      "Epoch [676/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0068\n",
      "Epoch [677/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0056\n",
      "Epoch [678/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0074\n",
      "Epoch [679/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0050\n",
      "Epoch [680/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0062\n",
      "Epoch [681/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0066\n",
      "Epoch [682/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0061\n",
      "Epoch [683/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0058\n",
      "Epoch [684/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0055, val_mae: 0.0051\n",
      "Epoch [685/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0049\n",
      "Epoch [686/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0066\n",
      "Epoch [687/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0057\n",
      "Epoch [688/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0056\n",
      "Epoch [689/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0067\n",
      "Epoch [690/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0057\n",
      "Epoch [691/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0055\n",
      "Epoch [692/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0064\n",
      "Epoch [693/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0059\n",
      "Epoch [694/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0059\n",
      "Epoch [695/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0060\n",
      "Epoch [696/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0063\n",
      "Epoch [697/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0056\n",
      "Epoch [698/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0067\n",
      "Epoch [699/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0059\n",
      "Epoch [700/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0057\n",
      "Epoch [701/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0074\n",
      "Epoch [702/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0053\n",
      "Epoch [703/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0053\n",
      "Epoch [704/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0061\n",
      "Epoch [705/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0063\n",
      "Epoch [706/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0063\n",
      "Epoch [707/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0055, val_mae: 0.0050\n",
      "Epoch [708/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0055, val_mae: 0.0050\n",
      "Epoch [709/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0052\n",
      "Epoch [710/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0066\n",
      "Epoch [711/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0068\n",
      "Epoch [712/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0066\n",
      "Epoch [713/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0064\n",
      "Epoch [714/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0051\n",
      "Epoch [715/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0094\n",
      "Epoch [716/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0055\n",
      "Epoch [717/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0053\n",
      "Epoch [718/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0058\n",
      "Epoch [719/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0056\n",
      "Epoch [720/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0080\n",
      "Epoch [721/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0055\n",
      "Epoch [722/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0057\n",
      "Epoch [723/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0053\n",
      "Epoch [724/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0060\n",
      "Epoch [725/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0056\n",
      "Epoch [726/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0050\n",
      "Epoch [727/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0059\n",
      "Epoch [728/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0054, val_mae: 0.0066\n",
      "Epoch [729/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0055, val_mae: 0.0050\n",
      "Epoch [730/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0057\n",
      "Epoch [731/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0060\n",
      "Epoch [732/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0069\n",
      "Epoch [733/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0062\n",
      "Epoch [734/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0055\n",
      "Epoch [735/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0061\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "train_losses6x50, val_losses6x50, train_maes6x50, val_maes6x50, best_state6x50 = train_loop(net6x50, train_dataloader, val_dataloader, patience=50, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "net6x50mae = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - train_loss: 0.0779, val_loss: 0.0554, train_mae: 0.0779, val_mae: 0.0554\n",
      "Epoch [2/1000] - train_loss: 0.0441, val_loss: 0.0393, train_mae: 0.0441, val_mae: 0.0393\n",
      "Epoch [3/1000] - train_loss: 0.0385, val_loss: 0.0406, train_mae: 0.0385, val_mae: 0.0406\n",
      "Epoch [4/1000] - train_loss: 0.0346, val_loss: 0.0305, train_mae: 0.0346, val_mae: 0.0305\n",
      "Epoch [5/1000] - train_loss: 0.0324, val_loss: 0.0321, train_mae: 0.0324, val_mae: 0.0321\n",
      "Epoch [6/1000] - train_loss: 0.0301, val_loss: 0.0272, train_mae: 0.0301, val_mae: 0.0272\n",
      "Epoch [7/1000] - train_loss: 0.0282, val_loss: 0.0284, train_mae: 0.0282, val_mae: 0.0284\n",
      "Epoch [8/1000] - train_loss: 0.0269, val_loss: 0.0291, train_mae: 0.0269, val_mae: 0.0291\n",
      "Epoch [9/1000] - train_loss: 0.0257, val_loss: 0.0245, train_mae: 0.0257, val_mae: 0.0245\n",
      "Epoch [10/1000] - train_loss: 0.0251, val_loss: 0.0246, train_mae: 0.0251, val_mae: 0.0246\n",
      "Epoch [11/1000] - train_loss: 0.0239, val_loss: 0.0228, train_mae: 0.0239, val_mae: 0.0228\n",
      "Epoch [12/1000] - train_loss: 0.0230, val_loss: 0.0235, train_mae: 0.0230, val_mae: 0.0235\n",
      "Epoch [13/1000] - train_loss: 0.0226, val_loss: 0.0257, train_mae: 0.0226, val_mae: 0.0257\n",
      "Epoch [14/1000] - train_loss: 0.0225, val_loss: 0.0211, train_mae: 0.0225, val_mae: 0.0211\n",
      "Epoch [15/1000] - train_loss: 0.0217, val_loss: 0.0217, train_mae: 0.0217, val_mae: 0.0217\n",
      "Epoch [16/1000] - train_loss: 0.0215, val_loss: 0.0192, train_mae: 0.0215, val_mae: 0.0192\n",
      "Epoch [17/1000] - train_loss: 0.0205, val_loss: 0.0226, train_mae: 0.0205, val_mae: 0.0226\n",
      "Epoch [18/1000] - train_loss: 0.0202, val_loss: 0.0205, train_mae: 0.0202, val_mae: 0.0205\n",
      "Epoch [19/1000] - train_loss: 0.0200, val_loss: 0.0185, train_mae: 0.0200, val_mae: 0.0185\n",
      "Epoch [20/1000] - train_loss: 0.0192, val_loss: 0.0182, train_mae: 0.0192, val_mae: 0.0182\n",
      "Epoch [21/1000] - train_loss: 0.0190, val_loss: 0.0198, train_mae: 0.0190, val_mae: 0.0198\n",
      "Epoch [22/1000] - train_loss: 0.0188, val_loss: 0.0226, train_mae: 0.0188, val_mae: 0.0226\n",
      "Epoch [23/1000] - train_loss: 0.0184, val_loss: 0.0243, train_mae: 0.0184, val_mae: 0.0243\n",
      "Epoch [24/1000] - train_loss: 0.0184, val_loss: 0.0186, train_mae: 0.0184, val_mae: 0.0186\n",
      "Epoch [25/1000] - train_loss: 0.0181, val_loss: 0.0165, train_mae: 0.0181, val_mae: 0.0165\n",
      "Epoch [26/1000] - train_loss: 0.0180, val_loss: 0.0163, train_mae: 0.0180, val_mae: 0.0163\n",
      "Epoch [27/1000] - train_loss: 0.0176, val_loss: 0.0157, train_mae: 0.0176, val_mae: 0.0157\n",
      "Epoch [28/1000] - train_loss: 0.0176, val_loss: 0.0169, train_mae: 0.0176, val_mae: 0.0169\n",
      "Epoch [29/1000] - train_loss: 0.0172, val_loss: 0.0165, train_mae: 0.0172, val_mae: 0.0165\n",
      "Epoch [30/1000] - train_loss: 0.0171, val_loss: 0.0165, train_mae: 0.0171, val_mae: 0.0165\n",
      "Epoch [31/1000] - train_loss: 0.0168, val_loss: 0.0197, train_mae: 0.0168, val_mae: 0.0197\n",
      "Epoch [32/1000] - train_loss: 0.0163, val_loss: 0.0166, train_mae: 0.0163, val_mae: 0.0166\n",
      "Epoch [33/1000] - train_loss: 0.0163, val_loss: 0.0151, train_mae: 0.0163, val_mae: 0.0151\n",
      "Epoch [34/1000] - train_loss: 0.0162, val_loss: 0.0149, train_mae: 0.0162, val_mae: 0.0149\n",
      "Epoch [35/1000] - train_loss: 0.0156, val_loss: 0.0184, train_mae: 0.0156, val_mae: 0.0184\n",
      "Epoch [36/1000] - train_loss: 0.0157, val_loss: 0.0145, train_mae: 0.0157, val_mae: 0.0145\n",
      "Epoch [37/1000] - train_loss: 0.0154, val_loss: 0.0150, train_mae: 0.0154, val_mae: 0.0150\n",
      "Epoch [38/1000] - train_loss: 0.0152, val_loss: 0.0169, train_mae: 0.0152, val_mae: 0.0169\n",
      "Epoch [39/1000] - train_loss: 0.0150, val_loss: 0.0156, train_mae: 0.0150, val_mae: 0.0156\n",
      "Epoch [40/1000] - train_loss: 0.0152, val_loss: 0.0172, train_mae: 0.0152, val_mae: 0.0172\n",
      "Epoch [41/1000] - train_loss: 0.0147, val_loss: 0.0145, train_mae: 0.0147, val_mae: 0.0145\n",
      "Epoch [42/1000] - train_loss: 0.0149, val_loss: 0.0148, train_mae: 0.0149, val_mae: 0.0148\n",
      "Epoch [43/1000] - train_loss: 0.0146, val_loss: 0.0139, train_mae: 0.0146, val_mae: 0.0139\n",
      "Epoch [44/1000] - train_loss: 0.0143, val_loss: 0.0140, train_mae: 0.0143, val_mae: 0.0140\n",
      "Epoch [45/1000] - train_loss: 0.0142, val_loss: 0.0143, train_mae: 0.0142, val_mae: 0.0143\n",
      "Epoch [46/1000] - train_loss: 0.0143, val_loss: 0.0165, train_mae: 0.0143, val_mae: 0.0165\n",
      "Epoch [47/1000] - train_loss: 0.0139, val_loss: 0.0134, train_mae: 0.0139, val_mae: 0.0134\n",
      "Epoch [48/1000] - train_loss: 0.0138, val_loss: 0.0137, train_mae: 0.0138, val_mae: 0.0137\n",
      "Epoch [49/1000] - train_loss: 0.0136, val_loss: 0.0138, train_mae: 0.0136, val_mae: 0.0138\n",
      "Epoch [50/1000] - train_loss: 0.0136, val_loss: 0.0127, train_mae: 0.0136, val_mae: 0.0127\n",
      "Epoch [51/1000] - train_loss: 0.0137, val_loss: 0.0139, train_mae: 0.0137, val_mae: 0.0139\n",
      "Epoch [52/1000] - train_loss: 0.0135, val_loss: 0.0134, train_mae: 0.0135, val_mae: 0.0134\n",
      "Epoch [53/1000] - train_loss: 0.0133, val_loss: 0.0129, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [54/1000] - train_loss: 0.0135, val_loss: 0.0115, train_mae: 0.0135, val_mae: 0.0115\n",
      "Epoch [55/1000] - train_loss: 0.0131, val_loss: 0.0135, train_mae: 0.0131, val_mae: 0.0135\n",
      "Epoch [56/1000] - train_loss: 0.0130, val_loss: 0.0127, train_mae: 0.0130, val_mae: 0.0127\n",
      "Epoch [57/1000] - train_loss: 0.0128, val_loss: 0.0115, train_mae: 0.0128, val_mae: 0.0115\n",
      "Epoch [58/1000] - train_loss: 0.0131, val_loss: 0.0138, train_mae: 0.0131, val_mae: 0.0138\n",
      "Epoch [59/1000] - train_loss: 0.0126, val_loss: 0.0127, train_mae: 0.0126, val_mae: 0.0127\n",
      "Epoch [60/1000] - train_loss: 0.0130, val_loss: 0.0117, train_mae: 0.0130, val_mae: 0.0117\n",
      "Epoch [61/1000] - train_loss: 0.0127, val_loss: 0.0121, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [62/1000] - train_loss: 0.0124, val_loss: 0.0114, train_mae: 0.0124, val_mae: 0.0114\n",
      "Epoch [63/1000] - train_loss: 0.0125, val_loss: 0.0148, train_mae: 0.0125, val_mae: 0.0148\n",
      "Epoch [64/1000] - train_loss: 0.0126, val_loss: 0.0134, train_mae: 0.0126, val_mae: 0.0134\n",
      "Epoch [65/1000] - train_loss: 0.0122, val_loss: 0.0119, train_mae: 0.0122, val_mae: 0.0119\n",
      "Epoch [66/1000] - train_loss: 0.0123, val_loss: 0.0132, train_mae: 0.0123, val_mae: 0.0132\n",
      "Epoch [67/1000] - train_loss: 0.0119, val_loss: 0.0127, train_mae: 0.0119, val_mae: 0.0127\n",
      "Epoch [68/1000] - train_loss: 0.0122, val_loss: 0.0115, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [69/1000] - train_loss: 0.0121, val_loss: 0.0132, train_mae: 0.0121, val_mae: 0.0132\n",
      "Epoch [70/1000] - train_loss: 0.0121, val_loss: 0.0121, train_mae: 0.0121, val_mae: 0.0121\n",
      "Epoch [71/1000] - train_loss: 0.0119, val_loss: 0.0144, train_mae: 0.0119, val_mae: 0.0144\n",
      "Epoch [72/1000] - train_loss: 0.0119, val_loss: 0.0140, train_mae: 0.0119, val_mae: 0.0140\n",
      "Epoch [73/1000] - train_loss: 0.0118, val_loss: 0.0120, train_mae: 0.0118, val_mae: 0.0120\n",
      "Epoch [74/1000] - train_loss: 0.0118, val_loss: 0.0127, train_mae: 0.0118, val_mae: 0.0127\n",
      "Epoch [75/1000] - train_loss: 0.0119, val_loss: 0.0128, train_mae: 0.0119, val_mae: 0.0128\n",
      "Epoch [76/1000] - train_loss: 0.0117, val_loss: 0.0117, train_mae: 0.0117, val_mae: 0.0117\n",
      "Epoch [77/1000] - train_loss: 0.0118, val_loss: 0.0142, train_mae: 0.0118, val_mae: 0.0142\n",
      "Epoch [78/1000] - train_loss: 0.0115, val_loss: 0.0120, train_mae: 0.0115, val_mae: 0.0120\n",
      "Epoch [79/1000] - train_loss: 0.0116, val_loss: 0.0125, train_mae: 0.0116, val_mae: 0.0125\n",
      "Epoch [80/1000] - train_loss: 0.0113, val_loss: 0.0105, train_mae: 0.0113, val_mae: 0.0105\n",
      "Epoch [81/1000] - train_loss: 0.0116, val_loss: 0.0109, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [82/1000] - train_loss: 0.0113, val_loss: 0.0141, train_mae: 0.0113, val_mae: 0.0141\n",
      "Epoch [83/1000] - train_loss: 0.0114, val_loss: 0.0121, train_mae: 0.0114, val_mae: 0.0121\n",
      "Epoch [84/1000] - train_loss: 0.0111, val_loss: 0.0156, train_mae: 0.0111, val_mae: 0.0156\n",
      "Epoch [85/1000] - train_loss: 0.0111, val_loss: 0.0104, train_mae: 0.0111, val_mae: 0.0104\n",
      "Epoch [86/1000] - train_loss: 0.0113, val_loss: 0.0115, train_mae: 0.0113, val_mae: 0.0115\n",
      "Epoch [87/1000] - train_loss: 0.0112, val_loss: 0.0106, train_mae: 0.0112, val_mae: 0.0106\n",
      "Epoch [88/1000] - train_loss: 0.0112, val_loss: 0.0110, train_mae: 0.0112, val_mae: 0.0110\n",
      "Epoch [89/1000] - train_loss: 0.0110, val_loss: 0.0111, train_mae: 0.0110, val_mae: 0.0111\n",
      "Epoch [90/1000] - train_loss: 0.0111, val_loss: 0.0107, train_mae: 0.0111, val_mae: 0.0107\n",
      "Epoch [91/1000] - train_loss: 0.0111, val_loss: 0.0120, train_mae: 0.0111, val_mae: 0.0120\n",
      "Epoch [92/1000] - train_loss: 0.0110, val_loss: 0.0103, train_mae: 0.0110, val_mae: 0.0103\n",
      "Epoch [93/1000] - train_loss: 0.0109, val_loss: 0.0115, train_mae: 0.0109, val_mae: 0.0115\n",
      "Epoch [94/1000] - train_loss: 0.0110, val_loss: 0.0107, train_mae: 0.0110, val_mae: 0.0107\n",
      "Epoch [95/1000] - train_loss: 0.0108, val_loss: 0.0109, train_mae: 0.0108, val_mae: 0.0109\n",
      "Epoch [96/1000] - train_loss: 0.0110, val_loss: 0.0101, train_mae: 0.0110, val_mae: 0.0101\n",
      "Epoch [97/1000] - train_loss: 0.0107, val_loss: 0.0105, train_mae: 0.0107, val_mae: 0.0105\n",
      "Epoch [98/1000] - train_loss: 0.0105, val_loss: 0.0110, train_mae: 0.0105, val_mae: 0.0110\n",
      "Epoch [99/1000] - train_loss: 0.0107, val_loss: 0.0111, train_mae: 0.0107, val_mae: 0.0111\n",
      "Epoch [100/1000] - train_loss: 0.0106, val_loss: 0.0109, train_mae: 0.0106, val_mae: 0.0109\n",
      "Epoch [101/1000] - train_loss: 0.0108, val_loss: 0.0114, train_mae: 0.0108, val_mae: 0.0114\n",
      "Epoch [102/1000] - train_loss: 0.0105, val_loss: 0.0109, train_mae: 0.0105, val_mae: 0.0109\n",
      "Epoch [103/1000] - train_loss: 0.0107, val_loss: 0.0128, train_mae: 0.0107, val_mae: 0.0128\n",
      "Epoch [104/1000] - train_loss: 0.0106, val_loss: 0.0130, train_mae: 0.0106, val_mae: 0.0130\n",
      "Epoch [105/1000] - train_loss: 0.0105, val_loss: 0.0107, train_mae: 0.0105, val_mae: 0.0107\n",
      "Epoch [106/1000] - train_loss: 0.0104, val_loss: 0.0107, train_mae: 0.0104, val_mae: 0.0107\n",
      "Epoch [107/1000] - train_loss: 0.0105, val_loss: 0.0105, train_mae: 0.0105, val_mae: 0.0105\n",
      "Epoch [108/1000] - train_loss: 0.0103, val_loss: 0.0114, train_mae: 0.0103, val_mae: 0.0114\n",
      "Epoch [109/1000] - train_loss: 0.0104, val_loss: 0.0093, train_mae: 0.0104, val_mae: 0.0093\n",
      "Epoch [110/1000] - train_loss: 0.0105, val_loss: 0.0105, train_mae: 0.0105, val_mae: 0.0105\n",
      "Epoch [111/1000] - train_loss: 0.0103, val_loss: 0.0095, train_mae: 0.0103, val_mae: 0.0095\n",
      "Epoch [112/1000] - train_loss: 0.0105, val_loss: 0.0101, train_mae: 0.0105, val_mae: 0.0101\n",
      "Epoch [113/1000] - train_loss: 0.0105, val_loss: 0.0109, train_mae: 0.0105, val_mae: 0.0109\n",
      "Epoch [114/1000] - train_loss: 0.0102, val_loss: 0.0116, train_mae: 0.0102, val_mae: 0.0116\n",
      "Epoch [115/1000] - train_loss: 0.0103, val_loss: 0.0106, train_mae: 0.0103, val_mae: 0.0106\n",
      "Epoch [116/1000] - train_loss: 0.0102, val_loss: 0.0099, train_mae: 0.0102, val_mae: 0.0099\n",
      "Epoch [117/1000] - train_loss: 0.0102, val_loss: 0.0107, train_mae: 0.0102, val_mae: 0.0107\n",
      "Epoch [118/1000] - train_loss: 0.0101, val_loss: 0.0103, train_mae: 0.0101, val_mae: 0.0103\n",
      "Epoch [119/1000] - train_loss: 0.0102, val_loss: 0.0103, train_mae: 0.0102, val_mae: 0.0103\n",
      "Epoch [120/1000] - train_loss: 0.0103, val_loss: 0.0098, train_mae: 0.0103, val_mae: 0.0098\n",
      "Epoch [121/1000] - train_loss: 0.0101, val_loss: 0.0104, train_mae: 0.0101, val_mae: 0.0104\n",
      "Epoch [122/1000] - train_loss: 0.0100, val_loss: 0.0104, train_mae: 0.0100, val_mae: 0.0104\n",
      "Epoch [123/1000] - train_loss: 0.0099, val_loss: 0.0117, train_mae: 0.0099, val_mae: 0.0117\n",
      "Epoch [124/1000] - train_loss: 0.0101, val_loss: 0.0120, train_mae: 0.0101, val_mae: 0.0120\n",
      "Epoch [125/1000] - train_loss: 0.0099, val_loss: 0.0102, train_mae: 0.0099, val_mae: 0.0102\n",
      "Epoch [126/1000] - train_loss: 0.0100, val_loss: 0.0101, train_mae: 0.0100, val_mae: 0.0101\n",
      "Epoch [127/1000] - train_loss: 0.0098, val_loss: 0.0118, train_mae: 0.0098, val_mae: 0.0118\n",
      "Epoch [128/1000] - train_loss: 0.0099, val_loss: 0.0139, train_mae: 0.0099, val_mae: 0.0139\n",
      "Epoch [129/1000] - train_loss: 0.0099, val_loss: 0.0093, train_mae: 0.0099, val_mae: 0.0093\n",
      "Epoch [130/1000] - train_loss: 0.0097, val_loss: 0.0098, train_mae: 0.0097, val_mae: 0.0098\n",
      "Epoch [131/1000] - train_loss: 0.0099, val_loss: 0.0100, train_mae: 0.0099, val_mae: 0.0100\n",
      "Epoch [132/1000] - train_loss: 0.0098, val_loss: 0.0102, train_mae: 0.0098, val_mae: 0.0102\n",
      "Epoch [133/1000] - train_loss: 0.0098, val_loss: 0.0140, train_mae: 0.0098, val_mae: 0.0140\n",
      "Epoch [134/1000] - train_loss: 0.0098, val_loss: 0.0093, train_mae: 0.0098, val_mae: 0.0093\n",
      "Epoch [135/1000] - train_loss: 0.0098, val_loss: 0.0100, train_mae: 0.0098, val_mae: 0.0100\n",
      "Epoch [136/1000] - train_loss: 0.0096, val_loss: 0.0096, train_mae: 0.0096, val_mae: 0.0096\n",
      "Epoch [137/1000] - train_loss: 0.0100, val_loss: 0.0093, train_mae: 0.0100, val_mae: 0.0093\n",
      "Epoch [138/1000] - train_loss: 0.0096, val_loss: 0.0091, train_mae: 0.0096, val_mae: 0.0091\n",
      "Epoch [139/1000] - train_loss: 0.0100, val_loss: 0.0091, train_mae: 0.0100, val_mae: 0.0091\n",
      "Epoch [140/1000] - train_loss: 0.0097, val_loss: 0.0109, train_mae: 0.0097, val_mae: 0.0109\n",
      "Epoch [141/1000] - train_loss: 0.0096, val_loss: 0.0088, train_mae: 0.0096, val_mae: 0.0088\n",
      "Epoch [142/1000] - train_loss: 0.0097, val_loss: 0.0095, train_mae: 0.0097, val_mae: 0.0095\n",
      "Epoch [143/1000] - train_loss: 0.0094, val_loss: 0.0109, train_mae: 0.0094, val_mae: 0.0109\n",
      "Epoch [144/1000] - train_loss: 0.0097, val_loss: 0.0108, train_mae: 0.0097, val_mae: 0.0108\n",
      "Epoch [145/1000] - train_loss: 0.0093, val_loss: 0.0102, train_mae: 0.0093, val_mae: 0.0102\n",
      "Epoch [146/1000] - train_loss: 0.0095, val_loss: 0.0110, train_mae: 0.0095, val_mae: 0.0110\n",
      "Epoch [147/1000] - train_loss: 0.0096, val_loss: 0.0107, train_mae: 0.0096, val_mae: 0.0107\n",
      "Epoch [148/1000] - train_loss: 0.0095, val_loss: 0.0090, train_mae: 0.0095, val_mae: 0.0090\n",
      "Epoch [149/1000] - train_loss: 0.0094, val_loss: 0.0096, train_mae: 0.0094, val_mae: 0.0096\n",
      "Epoch [150/1000] - train_loss: 0.0095, val_loss: 0.0097, train_mae: 0.0095, val_mae: 0.0097\n",
      "Epoch [151/1000] - train_loss: 0.0095, val_loss: 0.0105, train_mae: 0.0095, val_mae: 0.0105\n",
      "Epoch [152/1000] - train_loss: 0.0094, val_loss: 0.0122, train_mae: 0.0094, val_mae: 0.0122\n",
      "Epoch [153/1000] - train_loss: 0.0095, val_loss: 0.0084, train_mae: 0.0095, val_mae: 0.0084\n",
      "Epoch [154/1000] - train_loss: 0.0096, val_loss: 0.0102, train_mae: 0.0096, val_mae: 0.0102\n",
      "Epoch [155/1000] - train_loss: 0.0093, val_loss: 0.0101, train_mae: 0.0093, val_mae: 0.0101\n",
      "Epoch [156/1000] - train_loss: 0.0093, val_loss: 0.0097, train_mae: 0.0093, val_mae: 0.0097\n",
      "Epoch [157/1000] - train_loss: 0.0093, val_loss: 0.0102, train_mae: 0.0093, val_mae: 0.0102\n",
      "Epoch [158/1000] - train_loss: 0.0096, val_loss: 0.0095, train_mae: 0.0096, val_mae: 0.0095\n",
      "Epoch [159/1000] - train_loss: 0.0094, val_loss: 0.0129, train_mae: 0.0094, val_mae: 0.0129\n",
      "Epoch [160/1000] - train_loss: 0.0094, val_loss: 0.0088, train_mae: 0.0094, val_mae: 0.0088\n",
      "Epoch [161/1000] - train_loss: 0.0094, val_loss: 0.0099, train_mae: 0.0094, val_mae: 0.0099\n",
      "Epoch [162/1000] - train_loss: 0.0093, val_loss: 0.0128, train_mae: 0.0093, val_mae: 0.0128\n",
      "Epoch [163/1000] - train_loss: 0.0092, val_loss: 0.0092, train_mae: 0.0092, val_mae: 0.0092\n",
      "Epoch [164/1000] - train_loss: 0.0091, val_loss: 0.0100, train_mae: 0.0091, val_mae: 0.0100\n",
      "Epoch [165/1000] - train_loss: 0.0090, val_loss: 0.0137, train_mae: 0.0090, val_mae: 0.0137\n",
      "Epoch [166/1000] - train_loss: 0.0093, val_loss: 0.0100, train_mae: 0.0093, val_mae: 0.0100\n",
      "Epoch [167/1000] - train_loss: 0.0092, val_loss: 0.0091, train_mae: 0.0092, val_mae: 0.0091\n",
      "Epoch [168/1000] - train_loss: 0.0093, val_loss: 0.0112, train_mae: 0.0093, val_mae: 0.0112\n",
      "Epoch [169/1000] - train_loss: 0.0090, val_loss: 0.0103, train_mae: 0.0090, val_mae: 0.0103\n",
      "Epoch [170/1000] - train_loss: 0.0092, val_loss: 0.0092, train_mae: 0.0092, val_mae: 0.0092\n",
      "Epoch [171/1000] - train_loss: 0.0091, val_loss: 0.0101, train_mae: 0.0091, val_mae: 0.0101\n",
      "Epoch [172/1000] - train_loss: 0.0090, val_loss: 0.0103, train_mae: 0.0090, val_mae: 0.0103\n",
      "Epoch [173/1000] - train_loss: 0.0091, val_loss: 0.0101, train_mae: 0.0091, val_mae: 0.0101\n",
      "Epoch [174/1000] - train_loss: 0.0091, val_loss: 0.0100, train_mae: 0.0091, val_mae: 0.0100\n",
      "Epoch [175/1000] - train_loss: 0.0093, val_loss: 0.0092, train_mae: 0.0093, val_mae: 0.0092\n",
      "Epoch [176/1000] - train_loss: 0.0090, val_loss: 0.0098, train_mae: 0.0090, val_mae: 0.0098\n",
      "Epoch [177/1000] - train_loss: 0.0091, val_loss: 0.0135, train_mae: 0.0091, val_mae: 0.0135\n",
      "Epoch [178/1000] - train_loss: 0.0089, val_loss: 0.0086, train_mae: 0.0089, val_mae: 0.0086\n",
      "Epoch [179/1000] - train_loss: 0.0090, val_loss: 0.0097, train_mae: 0.0090, val_mae: 0.0097\n",
      "Epoch [180/1000] - train_loss: 0.0090, val_loss: 0.0086, train_mae: 0.0090, val_mae: 0.0086\n",
      "Epoch [181/1000] - train_loss: 0.0091, val_loss: 0.0096, train_mae: 0.0091, val_mae: 0.0096\n",
      "Epoch [182/1000] - train_loss: 0.0090, val_loss: 0.0083, train_mae: 0.0090, val_mae: 0.0083\n",
      "Epoch [183/1000] - train_loss: 0.0089, val_loss: 0.0089, train_mae: 0.0089, val_mae: 0.0089\n",
      "Epoch [184/1000] - train_loss: 0.0089, val_loss: 0.0129, train_mae: 0.0089, val_mae: 0.0129\n",
      "Epoch [185/1000] - train_loss: 0.0090, val_loss: 0.0084, train_mae: 0.0090, val_mae: 0.0084\n",
      "Epoch [186/1000] - train_loss: 0.0089, val_loss: 0.0110, train_mae: 0.0089, val_mae: 0.0110\n",
      "Epoch [187/1000] - train_loss: 0.0087, val_loss: 0.0114, train_mae: 0.0087, val_mae: 0.0114\n",
      "Epoch [188/1000] - train_loss: 0.0088, val_loss: 0.0088, train_mae: 0.0088, val_mae: 0.0088\n",
      "Epoch [189/1000] - train_loss: 0.0090, val_loss: 0.0087, train_mae: 0.0090, val_mae: 0.0087\n",
      "Epoch [190/1000] - train_loss: 0.0090, val_loss: 0.0093, train_mae: 0.0090, val_mae: 0.0093\n",
      "Epoch [191/1000] - train_loss: 0.0088, val_loss: 0.0091, train_mae: 0.0088, val_mae: 0.0091\n",
      "Epoch [192/1000] - train_loss: 0.0089, val_loss: 0.0096, train_mae: 0.0089, val_mae: 0.0096\n",
      "Epoch [193/1000] - train_loss: 0.0087, val_loss: 0.0095, train_mae: 0.0087, val_mae: 0.0095\n",
      "Epoch [194/1000] - train_loss: 0.0088, val_loss: 0.0084, train_mae: 0.0088, val_mae: 0.0084\n",
      "Epoch [195/1000] - train_loss: 0.0089, val_loss: 0.0084, train_mae: 0.0089, val_mae: 0.0084\n",
      "Epoch [196/1000] - train_loss: 0.0088, val_loss: 0.0092, train_mae: 0.0088, val_mae: 0.0092\n",
      "Epoch [197/1000] - train_loss: 0.0088, val_loss: 0.0088, train_mae: 0.0088, val_mae: 0.0088\n",
      "Epoch [198/1000] - train_loss: 0.0087, val_loss: 0.0085, train_mae: 0.0087, val_mae: 0.0085\n",
      "Epoch [199/1000] - train_loss: 0.0087, val_loss: 0.0096, train_mae: 0.0087, val_mae: 0.0096\n",
      "Epoch [200/1000] - train_loss: 0.0087, val_loss: 0.0115, train_mae: 0.0087, val_mae: 0.0115\n",
      "Epoch [201/1000] - train_loss: 0.0089, val_loss: 0.0092, train_mae: 0.0089, val_mae: 0.0092\n",
      "Epoch [202/1000] - train_loss: 0.0088, val_loss: 0.0102, train_mae: 0.0088, val_mae: 0.0102\n",
      "Epoch [203/1000] - train_loss: 0.0086, val_loss: 0.0115, train_mae: 0.0086, val_mae: 0.0115\n",
      "Epoch [204/1000] - train_loss: 0.0086, val_loss: 0.0083, train_mae: 0.0086, val_mae: 0.0083\n",
      "Epoch [205/1000] - train_loss: 0.0088, val_loss: 0.0084, train_mae: 0.0088, val_mae: 0.0084\n",
      "Epoch [206/1000] - train_loss: 0.0086, val_loss: 0.0098, train_mae: 0.0086, val_mae: 0.0098\n",
      "Epoch [207/1000] - train_loss: 0.0085, val_loss: 0.0085, train_mae: 0.0085, val_mae: 0.0085\n",
      "Epoch [208/1000] - train_loss: 0.0088, val_loss: 0.0082, train_mae: 0.0088, val_mae: 0.0082\n",
      "Epoch [209/1000] - train_loss: 0.0086, val_loss: 0.0084, train_mae: 0.0086, val_mae: 0.0084\n",
      "Epoch [210/1000] - train_loss: 0.0086, val_loss: 0.0093, train_mae: 0.0086, val_mae: 0.0093\n",
      "Epoch [211/1000] - train_loss: 0.0084, val_loss: 0.0112, train_mae: 0.0084, val_mae: 0.0112\n",
      "Epoch [212/1000] - train_loss: 0.0086, val_loss: 0.0088, train_mae: 0.0086, val_mae: 0.0088\n",
      "Epoch [213/1000] - train_loss: 0.0086, val_loss: 0.0089, train_mae: 0.0086, val_mae: 0.0089\n",
      "Epoch [214/1000] - train_loss: 0.0086, val_loss: 0.0096, train_mae: 0.0086, val_mae: 0.0096\n",
      "Epoch [215/1000] - train_loss: 0.0084, val_loss: 0.0077, train_mae: 0.0084, val_mae: 0.0077\n",
      "Epoch [216/1000] - train_loss: 0.0086, val_loss: 0.0083, train_mae: 0.0086, val_mae: 0.0083\n",
      "Epoch [217/1000] - train_loss: 0.0083, val_loss: 0.0080, train_mae: 0.0083, val_mae: 0.0080\n",
      "Epoch [218/1000] - train_loss: 0.0083, val_loss: 0.0081, train_mae: 0.0083, val_mae: 0.0081\n",
      "Epoch [219/1000] - train_loss: 0.0086, val_loss: 0.0099, train_mae: 0.0086, val_mae: 0.0099\n",
      "Epoch [220/1000] - train_loss: 0.0084, val_loss: 0.0085, train_mae: 0.0084, val_mae: 0.0085\n",
      "Epoch [221/1000] - train_loss: 0.0083, val_loss: 0.0097, train_mae: 0.0083, val_mae: 0.0097\n",
      "Epoch [222/1000] - train_loss: 0.0083, val_loss: 0.0094, train_mae: 0.0083, val_mae: 0.0094\n",
      "Epoch [223/1000] - train_loss: 0.0085, val_loss: 0.0091, train_mae: 0.0085, val_mae: 0.0091\n",
      "Epoch [224/1000] - train_loss: 0.0084, val_loss: 0.0096, train_mae: 0.0084, val_mae: 0.0096\n",
      "Epoch [225/1000] - train_loss: 0.0082, val_loss: 0.0081, train_mae: 0.0082, val_mae: 0.0081\n",
      "Epoch [226/1000] - train_loss: 0.0084, val_loss: 0.0088, train_mae: 0.0084, val_mae: 0.0088\n",
      "Epoch [227/1000] - train_loss: 0.0084, val_loss: 0.0091, train_mae: 0.0084, val_mae: 0.0091\n",
      "Epoch [228/1000] - train_loss: 0.0082, val_loss: 0.0081, train_mae: 0.0082, val_mae: 0.0081\n",
      "Epoch [229/1000] - train_loss: 0.0084, val_loss: 0.0078, train_mae: 0.0084, val_mae: 0.0078\n",
      "Epoch [230/1000] - train_loss: 0.0083, val_loss: 0.0082, train_mae: 0.0083, val_mae: 0.0082\n",
      "Epoch [231/1000] - train_loss: 0.0082, val_loss: 0.0084, train_mae: 0.0082, val_mae: 0.0084\n",
      "Epoch [232/1000] - train_loss: 0.0082, val_loss: 0.0078, train_mae: 0.0082, val_mae: 0.0078\n",
      "Epoch [233/1000] - train_loss: 0.0081, val_loss: 0.0083, train_mae: 0.0081, val_mae: 0.0083\n",
      "Epoch [234/1000] - train_loss: 0.0083, val_loss: 0.0078, train_mae: 0.0083, val_mae: 0.0078\n",
      "Epoch [235/1000] - train_loss: 0.0080, val_loss: 0.0087, train_mae: 0.0080, val_mae: 0.0087\n",
      "Epoch [236/1000] - train_loss: 0.0084, val_loss: 0.0080, train_mae: 0.0084, val_mae: 0.0080\n",
      "Epoch [237/1000] - train_loss: 0.0079, val_loss: 0.0081, train_mae: 0.0079, val_mae: 0.0081\n",
      "Epoch [238/1000] - train_loss: 0.0081, val_loss: 0.0086, train_mae: 0.0081, val_mae: 0.0086\n",
      "Epoch [239/1000] - train_loss: 0.0081, val_loss: 0.0079, train_mae: 0.0081, val_mae: 0.0079\n",
      "Epoch [240/1000] - train_loss: 0.0080, val_loss: 0.0074, train_mae: 0.0080, val_mae: 0.0074\n",
      "Epoch [241/1000] - train_loss: 0.0081, val_loss: 0.0081, train_mae: 0.0081, val_mae: 0.0081\n",
      "Epoch [242/1000] - train_loss: 0.0082, val_loss: 0.0081, train_mae: 0.0082, val_mae: 0.0081\n",
      "Epoch [243/1000] - train_loss: 0.0081, val_loss: 0.0087, train_mae: 0.0081, val_mae: 0.0087\n",
      "Epoch [244/1000] - train_loss: 0.0080, val_loss: 0.0098, train_mae: 0.0080, val_mae: 0.0098\n",
      "Epoch [245/1000] - train_loss: 0.0081, val_loss: 0.0085, train_mae: 0.0081, val_mae: 0.0085\n",
      "Epoch [246/1000] - train_loss: 0.0079, val_loss: 0.0098, train_mae: 0.0079, val_mae: 0.0098\n",
      "Epoch [247/1000] - train_loss: 0.0081, val_loss: 0.0094, train_mae: 0.0081, val_mae: 0.0094\n",
      "Epoch [248/1000] - train_loss: 0.0081, val_loss: 0.0077, train_mae: 0.0081, val_mae: 0.0077\n",
      "Epoch [249/1000] - train_loss: 0.0080, val_loss: 0.0086, train_mae: 0.0080, val_mae: 0.0086\n",
      "Epoch [250/1000] - train_loss: 0.0079, val_loss: 0.0086, train_mae: 0.0079, val_mae: 0.0086\n",
      "Epoch [251/1000] - train_loss: 0.0080, val_loss: 0.0085, train_mae: 0.0080, val_mae: 0.0085\n",
      "Epoch [252/1000] - train_loss: 0.0079, val_loss: 0.0128, train_mae: 0.0079, val_mae: 0.0128\n",
      "Epoch [253/1000] - train_loss: 0.0080, val_loss: 0.0077, train_mae: 0.0080, val_mae: 0.0077\n",
      "Epoch [254/1000] - train_loss: 0.0080, val_loss: 0.0080, train_mae: 0.0080, val_mae: 0.0080\n",
      "Epoch [255/1000] - train_loss: 0.0079, val_loss: 0.0080, train_mae: 0.0079, val_mae: 0.0080\n",
      "Epoch [256/1000] - train_loss: 0.0078, val_loss: 0.0082, train_mae: 0.0078, val_mae: 0.0082\n",
      "Epoch [257/1000] - train_loss: 0.0077, val_loss: 0.0131, train_mae: 0.0077, val_mae: 0.0131\n",
      "Epoch [258/1000] - train_loss: 0.0079, val_loss: 0.0074, train_mae: 0.0079, val_mae: 0.0074\n",
      "Epoch [259/1000] - train_loss: 0.0078, val_loss: 0.0087, train_mae: 0.0078, val_mae: 0.0087\n",
      "Epoch [260/1000] - train_loss: 0.0079, val_loss: 0.0076, train_mae: 0.0079, val_mae: 0.0076\n",
      "Epoch [261/1000] - train_loss: 0.0077, val_loss: 0.0071, train_mae: 0.0077, val_mae: 0.0071\n",
      "Epoch [262/1000] - train_loss: 0.0079, val_loss: 0.0073, train_mae: 0.0079, val_mae: 0.0073\n",
      "Epoch [263/1000] - train_loss: 0.0077, val_loss: 0.0072, train_mae: 0.0077, val_mae: 0.0072\n",
      "Epoch [264/1000] - train_loss: 0.0079, val_loss: 0.0099, train_mae: 0.0079, val_mae: 0.0099\n",
      "Epoch [265/1000] - train_loss: 0.0077, val_loss: 0.0078, train_mae: 0.0077, val_mae: 0.0078\n",
      "Epoch [266/1000] - train_loss: 0.0077, val_loss: 0.0076, train_mae: 0.0077, val_mae: 0.0076\n",
      "Epoch [267/1000] - train_loss: 0.0077, val_loss: 0.0073, train_mae: 0.0077, val_mae: 0.0073\n",
      "Epoch [268/1000] - train_loss: 0.0078, val_loss: 0.0090, train_mae: 0.0078, val_mae: 0.0090\n",
      "Epoch [269/1000] - train_loss: 0.0077, val_loss: 0.0116, train_mae: 0.0077, val_mae: 0.0116\n",
      "Epoch [270/1000] - train_loss: 0.0077, val_loss: 0.0091, train_mae: 0.0077, val_mae: 0.0091\n",
      "Epoch [271/1000] - train_loss: 0.0077, val_loss: 0.0083, train_mae: 0.0077, val_mae: 0.0083\n",
      "Epoch [272/1000] - train_loss: 0.0078, val_loss: 0.0078, train_mae: 0.0078, val_mae: 0.0078\n",
      "Epoch [273/1000] - train_loss: 0.0075, val_loss: 0.0076, train_mae: 0.0075, val_mae: 0.0076\n",
      "Epoch [274/1000] - train_loss: 0.0078, val_loss: 0.0108, train_mae: 0.0078, val_mae: 0.0108\n",
      "Epoch [275/1000] - train_loss: 0.0076, val_loss: 0.0092, train_mae: 0.0076, val_mae: 0.0092\n",
      "Epoch [276/1000] - train_loss: 0.0076, val_loss: 0.0090, train_mae: 0.0076, val_mae: 0.0090\n",
      "Epoch [277/1000] - train_loss: 0.0077, val_loss: 0.0085, train_mae: 0.0077, val_mae: 0.0085\n",
      "Epoch [278/1000] - train_loss: 0.0076, val_loss: 0.0076, train_mae: 0.0076, val_mae: 0.0076\n",
      "Epoch [279/1000] - train_loss: 0.0078, val_loss: 0.0077, train_mae: 0.0078, val_mae: 0.0077\n",
      "Epoch [280/1000] - train_loss: 0.0075, val_loss: 0.0084, train_mae: 0.0075, val_mae: 0.0084\n",
      "Epoch [281/1000] - train_loss: 0.0078, val_loss: 0.0082, train_mae: 0.0078, val_mae: 0.0082\n",
      "Epoch [282/1000] - train_loss: 0.0076, val_loss: 0.0097, train_mae: 0.0076, val_mae: 0.0097\n",
      "Epoch [283/1000] - train_loss: 0.0076, val_loss: 0.0075, train_mae: 0.0076, val_mae: 0.0075\n",
      "Epoch [284/1000] - train_loss: 0.0076, val_loss: 0.0075, train_mae: 0.0076, val_mae: 0.0075\n",
      "Epoch [285/1000] - train_loss: 0.0076, val_loss: 0.0098, train_mae: 0.0076, val_mae: 0.0098\n",
      "Epoch [286/1000] - train_loss: 0.0076, val_loss: 0.0070, train_mae: 0.0076, val_mae: 0.0070\n",
      "Epoch [287/1000] - train_loss: 0.0075, val_loss: 0.0079, train_mae: 0.0075, val_mae: 0.0079\n",
      "Epoch [288/1000] - train_loss: 0.0075, val_loss: 0.0093, train_mae: 0.0075, val_mae: 0.0093\n",
      "Epoch [289/1000] - train_loss: 0.0076, val_loss: 0.0074, train_mae: 0.0076, val_mae: 0.0074\n",
      "Epoch [290/1000] - train_loss: 0.0075, val_loss: 0.0075, train_mae: 0.0075, val_mae: 0.0075\n",
      "Epoch [291/1000] - train_loss: 0.0075, val_loss: 0.0078, train_mae: 0.0075, val_mae: 0.0078\n",
      "Epoch [292/1000] - train_loss: 0.0075, val_loss: 0.0078, train_mae: 0.0075, val_mae: 0.0078\n",
      "Epoch [293/1000] - train_loss: 0.0074, val_loss: 0.0071, train_mae: 0.0074, val_mae: 0.0071\n",
      "Epoch [294/1000] - train_loss: 0.0074, val_loss: 0.0103, train_mae: 0.0074, val_mae: 0.0103\n",
      "Epoch [295/1000] - train_loss: 0.0075, val_loss: 0.0094, train_mae: 0.0075, val_mae: 0.0094\n",
      "Epoch [296/1000] - train_loss: 0.0074, val_loss: 0.0083, train_mae: 0.0074, val_mae: 0.0083\n",
      "Epoch [297/1000] - train_loss: 0.0074, val_loss: 0.0089, train_mae: 0.0074, val_mae: 0.0089\n",
      "Epoch [298/1000] - train_loss: 0.0074, val_loss: 0.0088, train_mae: 0.0074, val_mae: 0.0088\n",
      "Epoch [299/1000] - train_loss: 0.0075, val_loss: 0.0074, train_mae: 0.0075, val_mae: 0.0074\n",
      "Epoch [300/1000] - train_loss: 0.0074, val_loss: 0.0069, train_mae: 0.0074, val_mae: 0.0069\n",
      "Epoch [301/1000] - train_loss: 0.0074, val_loss: 0.0089, train_mae: 0.0074, val_mae: 0.0089\n",
      "Epoch [302/1000] - train_loss: 0.0074, val_loss: 0.0070, train_mae: 0.0074, val_mae: 0.0070\n",
      "Epoch [303/1000] - train_loss: 0.0073, val_loss: 0.0072, train_mae: 0.0073, val_mae: 0.0072\n",
      "Epoch [304/1000] - train_loss: 0.0074, val_loss: 0.0074, train_mae: 0.0074, val_mae: 0.0074\n",
      "Epoch [305/1000] - train_loss: 0.0075, val_loss: 0.0084, train_mae: 0.0075, val_mae: 0.0084\n",
      "Epoch [306/1000] - train_loss: 0.0074, val_loss: 0.0073, train_mae: 0.0074, val_mae: 0.0073\n",
      "Epoch [307/1000] - train_loss: 0.0072, val_loss: 0.0085, train_mae: 0.0072, val_mae: 0.0085\n",
      "Epoch [308/1000] - train_loss: 0.0073, val_loss: 0.0082, train_mae: 0.0073, val_mae: 0.0082\n",
      "Epoch [309/1000] - train_loss: 0.0074, val_loss: 0.0082, train_mae: 0.0074, val_mae: 0.0082\n",
      "Epoch [310/1000] - train_loss: 0.0073, val_loss: 0.0071, train_mae: 0.0073, val_mae: 0.0071\n",
      "Epoch [311/1000] - train_loss: 0.0072, val_loss: 0.0074, train_mae: 0.0072, val_mae: 0.0074\n",
      "Epoch [312/1000] - train_loss: 0.0072, val_loss: 0.0083, train_mae: 0.0072, val_mae: 0.0083\n",
      "Epoch [313/1000] - train_loss: 0.0075, val_loss: 0.0071, train_mae: 0.0075, val_mae: 0.0071\n",
      "Epoch [314/1000] - train_loss: 0.0072, val_loss: 0.0089, train_mae: 0.0072, val_mae: 0.0089\n",
      "Epoch [315/1000] - train_loss: 0.0073, val_loss: 0.0085, train_mae: 0.0073, val_mae: 0.0085\n",
      "Epoch [316/1000] - train_loss: 0.0072, val_loss: 0.0067, train_mae: 0.0072, val_mae: 0.0067\n",
      "Epoch [317/1000] - train_loss: 0.0072, val_loss: 0.0071, train_mae: 0.0072, val_mae: 0.0071\n",
      "Epoch [318/1000] - train_loss: 0.0072, val_loss: 0.0070, train_mae: 0.0072, val_mae: 0.0070\n",
      "Epoch [319/1000] - train_loss: 0.0071, val_loss: 0.0071, train_mae: 0.0071, val_mae: 0.0071\n",
      "Epoch [320/1000] - train_loss: 0.0072, val_loss: 0.0068, train_mae: 0.0072, val_mae: 0.0068\n",
      "Epoch [321/1000] - train_loss: 0.0072, val_loss: 0.0091, train_mae: 0.0072, val_mae: 0.0091\n",
      "Epoch [322/1000] - train_loss: 0.0073, val_loss: 0.0086, train_mae: 0.0073, val_mae: 0.0086\n",
      "Epoch [323/1000] - train_loss: 0.0072, val_loss: 0.0078, train_mae: 0.0072, val_mae: 0.0078\n",
      "Epoch [324/1000] - train_loss: 0.0073, val_loss: 0.0069, train_mae: 0.0073, val_mae: 0.0069\n",
      "Epoch [325/1000] - train_loss: 0.0073, val_loss: 0.0070, train_mae: 0.0073, val_mae: 0.0070\n",
      "Epoch [326/1000] - train_loss: 0.0072, val_loss: 0.0086, train_mae: 0.0072, val_mae: 0.0086\n",
      "Epoch [327/1000] - train_loss: 0.0072, val_loss: 0.0072, train_mae: 0.0072, val_mae: 0.0072\n",
      "Epoch [328/1000] - train_loss: 0.0070, val_loss: 0.0086, train_mae: 0.0070, val_mae: 0.0086\n",
      "Epoch [329/1000] - train_loss: 0.0072, val_loss: 0.0083, train_mae: 0.0072, val_mae: 0.0083\n",
      "Epoch [330/1000] - train_loss: 0.0072, val_loss: 0.0070, train_mae: 0.0072, val_mae: 0.0070\n",
      "Epoch [331/1000] - train_loss: 0.0071, val_loss: 0.0068, train_mae: 0.0071, val_mae: 0.0068\n",
      "Epoch [332/1000] - train_loss: 0.0070, val_loss: 0.0074, train_mae: 0.0070, val_mae: 0.0074\n",
      "Epoch [333/1000] - train_loss: 0.0071, val_loss: 0.0085, train_mae: 0.0071, val_mae: 0.0085\n",
      "Epoch [334/1000] - train_loss: 0.0071, val_loss: 0.0079, train_mae: 0.0071, val_mae: 0.0079\n",
      "Epoch [335/1000] - train_loss: 0.0070, val_loss: 0.0087, train_mae: 0.0070, val_mae: 0.0087\n",
      "Epoch [336/1000] - train_loss: 0.0071, val_loss: 0.0072, train_mae: 0.0071, val_mae: 0.0072\n",
      "Epoch [337/1000] - train_loss: 0.0071, val_loss: 0.0071, train_mae: 0.0071, val_mae: 0.0071\n",
      "Epoch [338/1000] - train_loss: 0.0071, val_loss: 0.0103, train_mae: 0.0071, val_mae: 0.0103\n",
      "Epoch [339/1000] - train_loss: 0.0070, val_loss: 0.0073, train_mae: 0.0070, val_mae: 0.0073\n",
      "Epoch [340/1000] - train_loss: 0.0071, val_loss: 0.0074, train_mae: 0.0071, val_mae: 0.0074\n",
      "Epoch [341/1000] - train_loss: 0.0072, val_loss: 0.0064, train_mae: 0.0072, val_mae: 0.0064\n",
      "Epoch [342/1000] - train_loss: 0.0070, val_loss: 0.0069, train_mae: 0.0070, val_mae: 0.0069\n",
      "Epoch [343/1000] - train_loss: 0.0070, val_loss: 0.0073, train_mae: 0.0070, val_mae: 0.0073\n",
      "Epoch [344/1000] - train_loss: 0.0069, val_loss: 0.0065, train_mae: 0.0069, val_mae: 0.0065\n",
      "Epoch [345/1000] - train_loss: 0.0070, val_loss: 0.0073, train_mae: 0.0070, val_mae: 0.0073\n",
      "Epoch [346/1000] - train_loss: 0.0070, val_loss: 0.0064, train_mae: 0.0070, val_mae: 0.0064\n",
      "Epoch [347/1000] - train_loss: 0.0068, val_loss: 0.0067, train_mae: 0.0068, val_mae: 0.0067\n",
      "Epoch [348/1000] - train_loss: 0.0070, val_loss: 0.0066, train_mae: 0.0070, val_mae: 0.0066\n",
      "Epoch [349/1000] - train_loss: 0.0070, val_loss: 0.0109, train_mae: 0.0070, val_mae: 0.0109\n",
      "Epoch [350/1000] - train_loss: 0.0069, val_loss: 0.0078, train_mae: 0.0069, val_mae: 0.0078\n",
      "Epoch [351/1000] - train_loss: 0.0069, val_loss: 0.0078, train_mae: 0.0069, val_mae: 0.0078\n",
      "Epoch [352/1000] - train_loss: 0.0069, val_loss: 0.0078, train_mae: 0.0069, val_mae: 0.0078\n",
      "Epoch [353/1000] - train_loss: 0.0070, val_loss: 0.0088, train_mae: 0.0070, val_mae: 0.0088\n",
      "Epoch [354/1000] - train_loss: 0.0068, val_loss: 0.0065, train_mae: 0.0068, val_mae: 0.0065\n",
      "Epoch [355/1000] - train_loss: 0.0069, val_loss: 0.0071, train_mae: 0.0069, val_mae: 0.0071\n",
      "Epoch [356/1000] - train_loss: 0.0069, val_loss: 0.0077, train_mae: 0.0069, val_mae: 0.0077\n",
      "Epoch [357/1000] - train_loss: 0.0069, val_loss: 0.0068, train_mae: 0.0069, val_mae: 0.0068\n",
      "Epoch [358/1000] - train_loss: 0.0068, val_loss: 0.0068, train_mae: 0.0068, val_mae: 0.0068\n",
      "Epoch [359/1000] - train_loss: 0.0068, val_loss: 0.0065, train_mae: 0.0068, val_mae: 0.0065\n",
      "Epoch [360/1000] - train_loss: 0.0069, val_loss: 0.0091, train_mae: 0.0069, val_mae: 0.0091\n",
      "Epoch [361/1000] - train_loss: 0.0068, val_loss: 0.0071, train_mae: 0.0068, val_mae: 0.0071\n",
      "Epoch [362/1000] - train_loss: 0.0069, val_loss: 0.0063, train_mae: 0.0069, val_mae: 0.0063\n",
      "Epoch [363/1000] - train_loss: 0.0068, val_loss: 0.0060, train_mae: 0.0068, val_mae: 0.0060\n",
      "Epoch [364/1000] - train_loss: 0.0068, val_loss: 0.0069, train_mae: 0.0068, val_mae: 0.0069\n",
      "Epoch [365/1000] - train_loss: 0.0067, val_loss: 0.0072, train_mae: 0.0067, val_mae: 0.0072\n",
      "Epoch [366/1000] - train_loss: 0.0068, val_loss: 0.0065, train_mae: 0.0068, val_mae: 0.0065\n",
      "Epoch [367/1000] - train_loss: 0.0068, val_loss: 0.0068, train_mae: 0.0068, val_mae: 0.0068\n",
      "Epoch [368/1000] - train_loss: 0.0068, val_loss: 0.0078, train_mae: 0.0068, val_mae: 0.0078\n",
      "Epoch [369/1000] - train_loss: 0.0068, val_loss: 0.0096, train_mae: 0.0068, val_mae: 0.0096\n",
      "Epoch [370/1000] - train_loss: 0.0068, val_loss: 0.0087, train_mae: 0.0068, val_mae: 0.0087\n",
      "Epoch [371/1000] - train_loss: 0.0068, val_loss: 0.0072, train_mae: 0.0068, val_mae: 0.0072\n",
      "Epoch [372/1000] - train_loss: 0.0067, val_loss: 0.0081, train_mae: 0.0067, val_mae: 0.0081\n",
      "Epoch [373/1000] - train_loss: 0.0068, val_loss: 0.0078, train_mae: 0.0068, val_mae: 0.0078\n",
      "Epoch [374/1000] - train_loss: 0.0068, val_loss: 0.0067, train_mae: 0.0068, val_mae: 0.0067\n",
      "Epoch [375/1000] - train_loss: 0.0067, val_loss: 0.0063, train_mae: 0.0067, val_mae: 0.0063\n",
      "Epoch [376/1000] - train_loss: 0.0067, val_loss: 0.0063, train_mae: 0.0067, val_mae: 0.0063\n",
      "Epoch [377/1000] - train_loss: 0.0068, val_loss: 0.0072, train_mae: 0.0068, val_mae: 0.0072\n",
      "Epoch [378/1000] - train_loss: 0.0068, val_loss: 0.0068, train_mae: 0.0068, val_mae: 0.0068\n",
      "Epoch [379/1000] - train_loss: 0.0067, val_loss: 0.0078, train_mae: 0.0067, val_mae: 0.0078\n",
      "Epoch [380/1000] - train_loss: 0.0068, val_loss: 0.0072, train_mae: 0.0068, val_mae: 0.0072\n",
      "Epoch [381/1000] - train_loss: 0.0067, val_loss: 0.0068, train_mae: 0.0067, val_mae: 0.0068\n",
      "Epoch [382/1000] - train_loss: 0.0069, val_loss: 0.0087, train_mae: 0.0069, val_mae: 0.0087\n",
      "Epoch [383/1000] - train_loss: 0.0068, val_loss: 0.0070, train_mae: 0.0068, val_mae: 0.0070\n",
      "Epoch [384/1000] - train_loss: 0.0067, val_loss: 0.0060, train_mae: 0.0067, val_mae: 0.0060\n",
      "Epoch [385/1000] - train_loss: 0.0068, val_loss: 0.0118, train_mae: 0.0068, val_mae: 0.0118\n",
      "Epoch [386/1000] - train_loss: 0.0068, val_loss: 0.0077, train_mae: 0.0068, val_mae: 0.0077\n",
      "Epoch [387/1000] - train_loss: 0.0067, val_loss: 0.0074, train_mae: 0.0067, val_mae: 0.0074\n",
      "Epoch [388/1000] - train_loss: 0.0067, val_loss: 0.0064, train_mae: 0.0067, val_mae: 0.0064\n",
      "Epoch [389/1000] - train_loss: 0.0066, val_loss: 0.0071, train_mae: 0.0066, val_mae: 0.0071\n",
      "Epoch [390/1000] - train_loss: 0.0067, val_loss: 0.0073, train_mae: 0.0067, val_mae: 0.0073\n",
      "Epoch [391/1000] - train_loss: 0.0068, val_loss: 0.0071, train_mae: 0.0068, val_mae: 0.0071\n",
      "Epoch [392/1000] - train_loss: 0.0067, val_loss: 0.0076, train_mae: 0.0067, val_mae: 0.0076\n",
      "Epoch [393/1000] - train_loss: 0.0066, val_loss: 0.0070, train_mae: 0.0066, val_mae: 0.0070\n",
      "Epoch [394/1000] - train_loss: 0.0065, val_loss: 0.0064, train_mae: 0.0065, val_mae: 0.0064\n",
      "Epoch [395/1000] - train_loss: 0.0067, val_loss: 0.0072, train_mae: 0.0067, val_mae: 0.0072\n",
      "Epoch [396/1000] - train_loss: 0.0067, val_loss: 0.0065, train_mae: 0.0067, val_mae: 0.0065\n",
      "Epoch [397/1000] - train_loss: 0.0067, val_loss: 0.0089, train_mae: 0.0067, val_mae: 0.0089\n",
      "Epoch [398/1000] - train_loss: 0.0066, val_loss: 0.0063, train_mae: 0.0066, val_mae: 0.0063\n",
      "Epoch [399/1000] - train_loss: 0.0067, val_loss: 0.0068, train_mae: 0.0067, val_mae: 0.0068\n",
      "Epoch [400/1000] - train_loss: 0.0066, val_loss: 0.0066, train_mae: 0.0066, val_mae: 0.0066\n",
      "Epoch [401/1000] - train_loss: 0.0066, val_loss: 0.0067, train_mae: 0.0066, val_mae: 0.0067\n",
      "Epoch [402/1000] - train_loss: 0.0066, val_loss: 0.0069, train_mae: 0.0066, val_mae: 0.0069\n",
      "Epoch [403/1000] - train_loss: 0.0067, val_loss: 0.0068, train_mae: 0.0067, val_mae: 0.0068\n",
      "Epoch [404/1000] - train_loss: 0.0066, val_loss: 0.0073, train_mae: 0.0066, val_mae: 0.0073\n",
      "Epoch [405/1000] - train_loss: 0.0065, val_loss: 0.0069, train_mae: 0.0065, val_mae: 0.0069\n",
      "Epoch [406/1000] - train_loss: 0.0067, val_loss: 0.0071, train_mae: 0.0067, val_mae: 0.0071\n",
      "Epoch [407/1000] - train_loss: 0.0065, val_loss: 0.0065, train_mae: 0.0065, val_mae: 0.0065\n",
      "Epoch [408/1000] - train_loss: 0.0067, val_loss: 0.0067, train_mae: 0.0067, val_mae: 0.0067\n",
      "Epoch [409/1000] - train_loss: 0.0067, val_loss: 0.0069, train_mae: 0.0067, val_mae: 0.0069\n",
      "Epoch [410/1000] - train_loss: 0.0064, val_loss: 0.0065, train_mae: 0.0064, val_mae: 0.0065\n",
      "Epoch [411/1000] - train_loss: 0.0065, val_loss: 0.0060, train_mae: 0.0065, val_mae: 0.0060\n",
      "Epoch [412/1000] - train_loss: 0.0067, val_loss: 0.0063, train_mae: 0.0067, val_mae: 0.0063\n",
      "Epoch [413/1000] - train_loss: 0.0066, val_loss: 0.0068, train_mae: 0.0066, val_mae: 0.0068\n",
      "Epoch [414/1000] - train_loss: 0.0065, val_loss: 0.0070, train_mae: 0.0065, val_mae: 0.0070\n",
      "Epoch [415/1000] - train_loss: 0.0065, val_loss: 0.0068, train_mae: 0.0065, val_mae: 0.0068\n",
      "Epoch [416/1000] - train_loss: 0.0065, val_loss: 0.0065, train_mae: 0.0065, val_mae: 0.0065\n",
      "Epoch [417/1000] - train_loss: 0.0066, val_loss: 0.0063, train_mae: 0.0066, val_mae: 0.0063\n",
      "Epoch [418/1000] - train_loss: 0.0065, val_loss: 0.0066, train_mae: 0.0065, val_mae: 0.0066\n",
      "Epoch [419/1000] - train_loss: 0.0065, val_loss: 0.0074, train_mae: 0.0065, val_mae: 0.0074\n",
      "Epoch [420/1000] - train_loss: 0.0063, val_loss: 0.0070, train_mae: 0.0063, val_mae: 0.0070\n",
      "Epoch [421/1000] - train_loss: 0.0064, val_loss: 0.0073, train_mae: 0.0064, val_mae: 0.0073\n",
      "Epoch [422/1000] - train_loss: 0.0065, val_loss: 0.0058, train_mae: 0.0065, val_mae: 0.0058\n",
      "Epoch [423/1000] - train_loss: 0.0064, val_loss: 0.0068, train_mae: 0.0064, val_mae: 0.0068\n",
      "Epoch [424/1000] - train_loss: 0.0064, val_loss: 0.0110, train_mae: 0.0064, val_mae: 0.0110\n",
      "Epoch [425/1000] - train_loss: 0.0065, val_loss: 0.0059, train_mae: 0.0065, val_mae: 0.0059\n",
      "Epoch [426/1000] - train_loss: 0.0065, val_loss: 0.0070, train_mae: 0.0065, val_mae: 0.0070\n",
      "Epoch [427/1000] - train_loss: 0.0064, val_loss: 0.0061, train_mae: 0.0064, val_mae: 0.0061\n",
      "Epoch [428/1000] - train_loss: 0.0064, val_loss: 0.0068, train_mae: 0.0064, val_mae: 0.0068\n",
      "Epoch [429/1000] - train_loss: 0.0064, val_loss: 0.0058, train_mae: 0.0064, val_mae: 0.0058\n",
      "Epoch [430/1000] - train_loss: 0.0065, val_loss: 0.0063, train_mae: 0.0065, val_mae: 0.0063\n",
      "Epoch [431/1000] - train_loss: 0.0063, val_loss: 0.0062, train_mae: 0.0063, val_mae: 0.0062\n",
      "Epoch [432/1000] - train_loss: 0.0063, val_loss: 0.0064, train_mae: 0.0063, val_mae: 0.0064\n",
      "Epoch [433/1000] - train_loss: 0.0064, val_loss: 0.0069, train_mae: 0.0064, val_mae: 0.0069\n",
      "Epoch [434/1000] - train_loss: 0.0064, val_loss: 0.0058, train_mae: 0.0064, val_mae: 0.0058\n",
      "Epoch [435/1000] - train_loss: 0.0064, val_loss: 0.0063, train_mae: 0.0064, val_mae: 0.0063\n",
      "Epoch [436/1000] - train_loss: 0.0064, val_loss: 0.0059, train_mae: 0.0064, val_mae: 0.0059\n",
      "Epoch [437/1000] - train_loss: 0.0064, val_loss: 0.0062, train_mae: 0.0064, val_mae: 0.0062\n",
      "Epoch [438/1000] - train_loss: 0.0063, val_loss: 0.0063, train_mae: 0.0063, val_mae: 0.0063\n",
      "Epoch [439/1000] - train_loss: 0.0065, val_loss: 0.0067, train_mae: 0.0065, val_mae: 0.0067\n",
      "Epoch [440/1000] - train_loss: 0.0063, val_loss: 0.0060, train_mae: 0.0063, val_mae: 0.0060\n",
      "Epoch [441/1000] - train_loss: 0.0064, val_loss: 0.0067, train_mae: 0.0064, val_mae: 0.0067\n",
      "Epoch [442/1000] - train_loss: 0.0063, val_loss: 0.0066, train_mae: 0.0063, val_mae: 0.0066\n",
      "Epoch [443/1000] - train_loss: 0.0064, val_loss: 0.0071, train_mae: 0.0064, val_mae: 0.0071\n",
      "Epoch [444/1000] - train_loss: 0.0062, val_loss: 0.0060, train_mae: 0.0062, val_mae: 0.0060\n",
      "Epoch [445/1000] - train_loss: 0.0063, val_loss: 0.0059, train_mae: 0.0063, val_mae: 0.0059\n",
      "Epoch [446/1000] - train_loss: 0.0063, val_loss: 0.0055, train_mae: 0.0063, val_mae: 0.0055\n",
      "Epoch [447/1000] - train_loss: 0.0064, val_loss: 0.0067, train_mae: 0.0064, val_mae: 0.0067\n",
      "Epoch [448/1000] - train_loss: 0.0062, val_loss: 0.0058, train_mae: 0.0062, val_mae: 0.0058\n",
      "Epoch [449/1000] - train_loss: 0.0063, val_loss: 0.0061, train_mae: 0.0063, val_mae: 0.0061\n",
      "Epoch [450/1000] - train_loss: 0.0063, val_loss: 0.0089, train_mae: 0.0063, val_mae: 0.0089\n",
      "Epoch [451/1000] - train_loss: 0.0062, val_loss: 0.0060, train_mae: 0.0062, val_mae: 0.0060\n",
      "Epoch [452/1000] - train_loss: 0.0062, val_loss: 0.0057, train_mae: 0.0062, val_mae: 0.0057\n",
      "Epoch [453/1000] - train_loss: 0.0062, val_loss: 0.0059, train_mae: 0.0062, val_mae: 0.0059\n",
      "Epoch [454/1000] - train_loss: 0.0063, val_loss: 0.0066, train_mae: 0.0063, val_mae: 0.0066\n",
      "Epoch [455/1000] - train_loss: 0.0062, val_loss: 0.0064, train_mae: 0.0062, val_mae: 0.0064\n",
      "Epoch [456/1000] - train_loss: 0.0063, val_loss: 0.0067, train_mae: 0.0063, val_mae: 0.0067\n",
      "Epoch [457/1000] - train_loss: 0.0062, val_loss: 0.0068, train_mae: 0.0062, val_mae: 0.0068\n",
      "Epoch [458/1000] - train_loss: 0.0064, val_loss: 0.0067, train_mae: 0.0064, val_mae: 0.0067\n",
      "Epoch [459/1000] - train_loss: 0.0063, val_loss: 0.0058, train_mae: 0.0063, val_mae: 0.0058\n",
      "Epoch [460/1000] - train_loss: 0.0061, val_loss: 0.0057, train_mae: 0.0061, val_mae: 0.0057\n",
      "Epoch [461/1000] - train_loss: 0.0062, val_loss: 0.0063, train_mae: 0.0062, val_mae: 0.0063\n",
      "Epoch [462/1000] - train_loss: 0.0063, val_loss: 0.0057, train_mae: 0.0063, val_mae: 0.0057\n",
      "Epoch [463/1000] - train_loss: 0.0062, val_loss: 0.0073, train_mae: 0.0062, val_mae: 0.0073\n",
      "Epoch [464/1000] - train_loss: 0.0063, val_loss: 0.0071, train_mae: 0.0063, val_mae: 0.0071\n",
      "Epoch [465/1000] - train_loss: 0.0062, val_loss: 0.0059, train_mae: 0.0062, val_mae: 0.0059\n",
      "Epoch [466/1000] - train_loss: 0.0062, val_loss: 0.0054, train_mae: 0.0062, val_mae: 0.0054\n",
      "Epoch [467/1000] - train_loss: 0.0061, val_loss: 0.0065, train_mae: 0.0061, val_mae: 0.0065\n",
      "Epoch [468/1000] - train_loss: 0.0064, val_loss: 0.0060, train_mae: 0.0064, val_mae: 0.0060\n",
      "Epoch [469/1000] - train_loss: 0.0062, val_loss: 0.0059, train_mae: 0.0062, val_mae: 0.0059\n",
      "Epoch [470/1000] - train_loss: 0.0062, val_loss: 0.0070, train_mae: 0.0062, val_mae: 0.0070\n",
      "Epoch [471/1000] - train_loss: 0.0062, val_loss: 0.0065, train_mae: 0.0062, val_mae: 0.0065\n",
      "Epoch [472/1000] - train_loss: 0.0061, val_loss: 0.0065, train_mae: 0.0061, val_mae: 0.0065\n",
      "Epoch [473/1000] - train_loss: 0.0062, val_loss: 0.0056, train_mae: 0.0062, val_mae: 0.0056\n",
      "Epoch [474/1000] - train_loss: 0.0061, val_loss: 0.0059, train_mae: 0.0061, val_mae: 0.0059\n",
      "Epoch [475/1000] - train_loss: 0.0063, val_loss: 0.0066, train_mae: 0.0063, val_mae: 0.0066\n",
      "Epoch [476/1000] - train_loss: 0.0061, val_loss: 0.0056, train_mae: 0.0061, val_mae: 0.0056\n",
      "Epoch [477/1000] - train_loss: 0.0061, val_loss: 0.0095, train_mae: 0.0061, val_mae: 0.0095\n",
      "Epoch [478/1000] - train_loss: 0.0062, val_loss: 0.0064, train_mae: 0.0062, val_mae: 0.0064\n",
      "Epoch [479/1000] - train_loss: 0.0062, val_loss: 0.0064, train_mae: 0.0062, val_mae: 0.0064\n",
      "Epoch [480/1000] - train_loss: 0.0062, val_loss: 0.0052, train_mae: 0.0062, val_mae: 0.0052\n",
      "Epoch [481/1000] - train_loss: 0.0062, val_loss: 0.0059, train_mae: 0.0062, val_mae: 0.0059\n",
      "Epoch [482/1000] - train_loss: 0.0060, val_loss: 0.0062, train_mae: 0.0060, val_mae: 0.0062\n",
      "Epoch [483/1000] - train_loss: 0.0062, val_loss: 0.0067, train_mae: 0.0062, val_mae: 0.0067\n",
      "Epoch [484/1000] - train_loss: 0.0060, val_loss: 0.0055, train_mae: 0.0060, val_mae: 0.0055\n",
      "Epoch [485/1000] - train_loss: 0.0061, val_loss: 0.0076, train_mae: 0.0061, val_mae: 0.0076\n",
      "Epoch [486/1000] - train_loss: 0.0060, val_loss: 0.0068, train_mae: 0.0060, val_mae: 0.0068\n",
      "Epoch [487/1000] - train_loss: 0.0060, val_loss: 0.0059, train_mae: 0.0060, val_mae: 0.0059\n",
      "Epoch [488/1000] - train_loss: 0.0062, val_loss: 0.0083, train_mae: 0.0062, val_mae: 0.0083\n",
      "Epoch [489/1000] - train_loss: 0.0060, val_loss: 0.0068, train_mae: 0.0060, val_mae: 0.0068\n",
      "Epoch [490/1000] - train_loss: 0.0061, val_loss: 0.0066, train_mae: 0.0061, val_mae: 0.0066\n",
      "Epoch [491/1000] - train_loss: 0.0060, val_loss: 0.0068, train_mae: 0.0060, val_mae: 0.0068\n",
      "Epoch [492/1000] - train_loss: 0.0061, val_loss: 0.0071, train_mae: 0.0061, val_mae: 0.0071\n",
      "Epoch [493/1000] - train_loss: 0.0061, val_loss: 0.0055, train_mae: 0.0061, val_mae: 0.0055\n",
      "Epoch [494/1000] - train_loss: 0.0060, val_loss: 0.0058, train_mae: 0.0060, val_mae: 0.0058\n",
      "Epoch [495/1000] - train_loss: 0.0060, val_loss: 0.0067, train_mae: 0.0060, val_mae: 0.0067\n",
      "Epoch [496/1000] - train_loss: 0.0061, val_loss: 0.0065, train_mae: 0.0061, val_mae: 0.0065\n",
      "Epoch [497/1000] - train_loss: 0.0061, val_loss: 0.0064, train_mae: 0.0061, val_mae: 0.0064\n",
      "Epoch [498/1000] - train_loss: 0.0061, val_loss: 0.0100, train_mae: 0.0061, val_mae: 0.0100\n",
      "Epoch [499/1000] - train_loss: 0.0060, val_loss: 0.0074, train_mae: 0.0060, val_mae: 0.0074\n",
      "Epoch [500/1000] - train_loss: 0.0061, val_loss: 0.0059, train_mae: 0.0061, val_mae: 0.0059\n",
      "Epoch [501/1000] - train_loss: 0.0060, val_loss: 0.0061, train_mae: 0.0060, val_mae: 0.0061\n",
      "Epoch [502/1000] - train_loss: 0.0060, val_loss: 0.0071, train_mae: 0.0060, val_mae: 0.0071\n",
      "Epoch [503/1000] - train_loss: 0.0061, val_loss: 0.0061, train_mae: 0.0061, val_mae: 0.0061\n",
      "Epoch [504/1000] - train_loss: 0.0060, val_loss: 0.0062, train_mae: 0.0060, val_mae: 0.0062\n",
      "Epoch [505/1000] - train_loss: 0.0061, val_loss: 0.0056, train_mae: 0.0061, val_mae: 0.0056\n",
      "Epoch [506/1000] - train_loss: 0.0059, val_loss: 0.0073, train_mae: 0.0059, val_mae: 0.0073\n",
      "Epoch [507/1000] - train_loss: 0.0060, val_loss: 0.0060, train_mae: 0.0060, val_mae: 0.0060\n",
      "Epoch [508/1000] - train_loss: 0.0060, val_loss: 0.0053, train_mae: 0.0060, val_mae: 0.0053\n",
      "Epoch [509/1000] - train_loss: 0.0060, val_loss: 0.0060, train_mae: 0.0060, val_mae: 0.0060\n",
      "Epoch [510/1000] - train_loss: 0.0060, val_loss: 0.0061, train_mae: 0.0060, val_mae: 0.0061\n",
      "Epoch [511/1000] - train_loss: 0.0060, val_loss: 0.0060, train_mae: 0.0060, val_mae: 0.0060\n",
      "Epoch [512/1000] - train_loss: 0.0060, val_loss: 0.0056, train_mae: 0.0060, val_mae: 0.0056\n",
      "Epoch [513/1000] - train_loss: 0.0060, val_loss: 0.0063, train_mae: 0.0060, val_mae: 0.0063\n",
      "Epoch [514/1000] - train_loss: 0.0059, val_loss: 0.0060, train_mae: 0.0059, val_mae: 0.0060\n",
      "Epoch [515/1000] - train_loss: 0.0059, val_loss: 0.0075, train_mae: 0.0059, val_mae: 0.0075\n",
      "Epoch [516/1000] - train_loss: 0.0060, val_loss: 0.0075, train_mae: 0.0060, val_mae: 0.0075\n",
      "Epoch [517/1000] - train_loss: 0.0060, val_loss: 0.0063, train_mae: 0.0060, val_mae: 0.0063\n",
      "Epoch [518/1000] - train_loss: 0.0060, val_loss: 0.0064, train_mae: 0.0060, val_mae: 0.0064\n",
      "Epoch [519/1000] - train_loss: 0.0059, val_loss: 0.0066, train_mae: 0.0059, val_mae: 0.0066\n",
      "Epoch [520/1000] - train_loss: 0.0060, val_loss: 0.0057, train_mae: 0.0060, val_mae: 0.0057\n",
      "Epoch [521/1000] - train_loss: 0.0060, val_loss: 0.0057, train_mae: 0.0060, val_mae: 0.0057\n",
      "Epoch [522/1000] - train_loss: 0.0059, val_loss: 0.0063, train_mae: 0.0059, val_mae: 0.0063\n",
      "Epoch [523/1000] - train_loss: 0.0061, val_loss: 0.0090, train_mae: 0.0061, val_mae: 0.0090\n",
      "Epoch [524/1000] - train_loss: 0.0060, val_loss: 0.0060, train_mae: 0.0060, val_mae: 0.0060\n",
      "Epoch [525/1000] - train_loss: 0.0059, val_loss: 0.0061, train_mae: 0.0059, val_mae: 0.0061\n",
      "Epoch [526/1000] - train_loss: 0.0060, val_loss: 0.0064, train_mae: 0.0060, val_mae: 0.0064\n",
      "Epoch [527/1000] - train_loss: 0.0059, val_loss: 0.0062, train_mae: 0.0059, val_mae: 0.0062\n",
      "Epoch [528/1000] - train_loss: 0.0058, val_loss: 0.0056, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [529/1000] - train_loss: 0.0059, val_loss: 0.0062, train_mae: 0.0059, val_mae: 0.0062\n",
      "Epoch [530/1000] - train_loss: 0.0060, val_loss: 0.0062, train_mae: 0.0060, val_mae: 0.0062\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "train_losses6x50mae, val_losses6x50mae, train_maes6x50mae, val_maes6x50mae, best_state6x50mae = train_loop(net6x50mae, train_dataloader, val_dataloader, patience=50, num_epochs=1000, lossfun='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1x30 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net2x30 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), \n",
    "                              torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net3x30 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), \n",
    "                              torch.nn.ReLU(), torch.nn.Linear(30, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net6x50 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 1))\n",
    "net_large = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 1000), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(1000, 500), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(500, 250), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(250, 125), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(125, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 1))\n",
    "\n",
    "net1x30sf = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net2x30sf = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), \n",
    "                              torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net3x30sf = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), \n",
    "                              torch.nn.ReLU(), torch.nn.Linear(30, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net6x50sf = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 1))\n",
    "net_largesf = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 1000), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(1000, 500), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(500, 250), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(250, 125), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(125, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - train_loss: 0.0049, val_loss: 0.0009, train_mae: 0.0471, val_mae: 0.0238\n",
      "Epoch [2/1000] - train_loss: 0.0008, val_loss: 0.0004, train_mae: 0.0223, val_mae: 0.0158\n",
      "Epoch [3/1000] - train_loss: 0.0006, val_loss: 0.0003, train_mae: 0.0180, val_mae: 0.0120\n",
      "Epoch [4/1000] - train_loss: 0.0004, val_loss: 0.0002, train_mae: 0.0148, val_mae: 0.0100\n",
      "Epoch [5/1000] - train_loss: 0.0003, val_loss: 0.0001, train_mae: 0.0135, val_mae: 0.0088\n",
      "Epoch [6/1000] - train_loss: 0.0003, val_loss: 0.0001, train_mae: 0.0118, val_mae: 0.0081\n",
      "Epoch [7/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0115, val_mae: 0.0076\n",
      "Epoch [8/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0100, val_mae: 0.0071\n",
      "Epoch [9/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0098, val_mae: 0.0068\n",
      "Epoch [10/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0066\n",
      "Epoch [11/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0063\n",
      "Epoch [12/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0061\n",
      "Epoch [13/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0059\n",
      "Epoch [14/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0058\n",
      "Epoch [15/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0057\n",
      "Epoch [16/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0057\n",
      "Epoch [17/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0055\n",
      "Epoch [18/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0054\n",
      "Epoch [19/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0070, val_mae: 0.0053\n",
      "Epoch [20/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0069, val_mae: 0.0052\n",
      "Epoch [21/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0066, val_mae: 0.0051\n",
      "Epoch [22/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0066, val_mae: 0.0050\n",
      "Epoch [23/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0064, val_mae: 0.0049\n",
      "Epoch [24/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0066, val_mae: 0.0049\n",
      "Epoch [25/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0061, val_mae: 0.0049\n",
      "Epoch [26/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0062, val_mae: 0.0049\n",
      "Epoch [27/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0061, val_mae: 0.0049\n",
      "Epoch [28/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0059, val_mae: 0.0049\n",
      "Epoch [29/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0058, val_mae: 0.0049\n",
      "Epoch [30/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0049\n",
      "Epoch [31/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0049\n",
      "Epoch [32/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0050\n",
      "Epoch [33/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0050\n",
      "Epoch [34/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0053, val_mae: 0.0050\n",
      "Epoch [35/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0054, val_mae: 0.0050\n",
      "Epoch [36/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0054, val_mae: 0.0049\n",
      "Epoch [37/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0055, val_mae: 0.0048\n",
      "Epoch [38/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0053, val_mae: 0.0047\n",
      "Epoch [39/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0054, val_mae: 0.0046\n",
      "Epoch [40/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0050, val_mae: 0.0045\n",
      "Epoch [41/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0050, val_mae: 0.0044\n",
      "Epoch [42/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0051, val_mae: 0.0044\n",
      "Epoch [43/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0044\n",
      "Epoch [44/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0043\n",
      "Epoch [45/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0042\n",
      "Epoch [46/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0042\n",
      "Epoch [47/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0041\n",
      "Epoch [48/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0047, val_mae: 0.0041\n",
      "Epoch [49/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0040\n",
      "Epoch [50/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0040\n",
      "Epoch [51/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0040\n",
      "Epoch [52/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0040\n",
      "Epoch [53/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0040\n",
      "Epoch [54/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0041\n",
      "Epoch [55/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0041\n",
      "Epoch [56/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0042\n",
      "Epoch [57/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0042\n",
      "Epoch [58/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0043\n",
      "Epoch [59/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0044\n",
      "Epoch [60/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0044\n",
      "Epoch [61/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0045\n",
      "Epoch [62/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0046\n",
      "Epoch [63/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0046\n",
      "Epoch [64/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0047\n",
      "Epoch [65/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0048\n",
      "Epoch [66/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0048\n",
      "Epoch [67/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0049\n",
      "Epoch [68/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0050\n",
      "Epoch [69/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0050\n",
      "Epoch [70/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0051\n",
      "Epoch [71/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0053\n",
      "Epoch [72/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0040, val_mae: 0.0054\n",
      "Epoch [73/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0040, val_mae: 0.0056\n",
      "Epoch [74/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0059\n",
      "Epoch [75/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0040, val_mae: 0.0061\n",
      "Epoch [76/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0041, val_mae: 0.0064\n",
      "Epoch [77/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0066\n",
      "Epoch [78/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0068\n",
      "Epoch [79/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0069\n",
      "Epoch [80/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0069\n",
      "Epoch [81/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0040, val_mae: 0.0069\n",
      "Epoch [82/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0036, val_mae: 0.0068\n",
      "Epoch [83/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0067\n",
      "Epoch [84/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0066\n",
      "Epoch [85/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0064\n",
      "Epoch [86/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0062\n",
      "Epoch [87/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0060\n",
      "Epoch [88/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0037, val_mae: 0.0058\n",
      "Epoch [89/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0055\n",
      "Epoch [90/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0053\n",
      "Epoch [91/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0051\n",
      "Epoch [92/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0049\n",
      "Epoch [93/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0048\n",
      "Epoch [94/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0046\n",
      "Epoch [95/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0045\n",
      "Epoch [96/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0044\n",
      "Epoch [97/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0043\n",
      "Epoch [98/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0043\n",
      "Epoch [99/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0042\n",
      "Epoch [100/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0041\n",
      "Epoch [101/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0041\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n",
      "Epoch [1/1000] - train_loss: 0.0227, val_loss: 0.0061, train_mae: 0.1084, val_mae: 0.0611\n",
      "Epoch [2/1000] - train_loss: 0.0053, val_loss: 0.0045, train_mae: 0.0580, val_mae: 0.0532\n",
      "Epoch [3/1000] - train_loss: 0.0043, val_loss: 0.0039, train_mae: 0.0522, val_mae: 0.0490\n",
      "Epoch [4/1000] - train_loss: 0.0036, val_loss: 0.0032, train_mae: 0.0474, val_mae: 0.0445\n",
      "Epoch [5/1000] - train_loss: 0.0032, val_loss: 0.0030, train_mae: 0.0445, val_mae: 0.0428\n",
      "Epoch [6/1000] - train_loss: 0.0029, val_loss: 0.0029, train_mae: 0.0428, val_mae: 0.0419\n",
      "Epoch [7/1000] - train_loss: 0.0028, val_loss: 0.0027, train_mae: 0.0417, val_mae: 0.0408\n",
      "Epoch [8/1000] - train_loss: 0.0027, val_loss: 0.0026, train_mae: 0.0406, val_mae: 0.0398\n",
      "Epoch [9/1000] - train_loss: 0.0026, val_loss: 0.0026, train_mae: 0.0401, val_mae: 0.0396\n",
      "Epoch [10/1000] - train_loss: 0.0025, val_loss: 0.0028, train_mae: 0.0397, val_mae: 0.0414\n",
      "Epoch [11/1000] - train_loss: 0.0025, val_loss: 0.0024, train_mae: 0.0391, val_mae: 0.0380\n",
      "Epoch [12/1000] - train_loss: 0.0024, val_loss: 0.0025, train_mae: 0.0385, val_mae: 0.0386\n",
      "Epoch [13/1000] - train_loss: 0.0024, val_loss: 0.0024, train_mae: 0.0383, val_mae: 0.0385\n",
      "Epoch [14/1000] - train_loss: 0.0023, val_loss: 0.0024, train_mae: 0.0379, val_mae: 0.0385\n",
      "Epoch [15/1000] - train_loss: 0.0023, val_loss: 0.0023, train_mae: 0.0376, val_mae: 0.0368\n",
      "Epoch [16/1000] - train_loss: 0.0023, val_loss: 0.0027, train_mae: 0.0374, val_mae: 0.0414\n",
      "Epoch [17/1000] - train_loss: 0.0022, val_loss: 0.0022, train_mae: 0.0369, val_mae: 0.0361\n",
      "Epoch [18/1000] - train_loss: 0.0022, val_loss: 0.0023, train_mae: 0.0365, val_mae: 0.0378\n",
      "Epoch [19/1000] - train_loss: 0.0022, val_loss: 0.0022, train_mae: 0.0366, val_mae: 0.0361\n",
      "Epoch [20/1000] - train_loss: 0.0021, val_loss: 0.0023, train_mae: 0.0361, val_mae: 0.0377\n",
      "Epoch [21/1000] - train_loss: 0.0021, val_loss: 0.0021, train_mae: 0.0359, val_mae: 0.0358\n",
      "Epoch [22/1000] - train_loss: 0.0021, val_loss: 0.0021, train_mae: 0.0357, val_mae: 0.0363\n",
      "Epoch [23/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0355, val_mae: 0.0351\n",
      "Epoch [24/1000] - train_loss: 0.0020, val_loss: 0.0022, train_mae: 0.0353, val_mae: 0.0371\n",
      "Epoch [25/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0351, val_mae: 0.0346\n",
      "Epoch [26/1000] - train_loss: 0.0020, val_loss: 0.0019, train_mae: 0.0349, val_mae: 0.0341\n",
      "Epoch [27/1000] - train_loss: 0.0020, val_loss: 0.0020, train_mae: 0.0347, val_mae: 0.0355\n",
      "Epoch [28/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0344, val_mae: 0.0340\n",
      "Epoch [29/1000] - train_loss: 0.0019, val_loss: 0.0020, train_mae: 0.0344, val_mae: 0.0343\n",
      "Epoch [30/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0343, val_mae: 0.0338\n",
      "Epoch [31/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0341, val_mae: 0.0338\n",
      "Epoch [32/1000] - train_loss: 0.0019, val_loss: 0.0022, train_mae: 0.0340, val_mae: 0.0370\n",
      "Epoch [33/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0340, val_mae: 0.0335\n",
      "Epoch [34/1000] - train_loss: 0.0019, val_loss: 0.0019, train_mae: 0.0339, val_mae: 0.0336\n",
      "Epoch [35/1000] - train_loss: 0.0019, val_loss: 0.0018, train_mae: 0.0340, val_mae: 0.0334\n",
      "Epoch [36/1000] - train_loss: 0.0019, val_loss: 0.0018, train_mae: 0.0338, val_mae: 0.0337\n",
      "Epoch [37/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0335, val_mae: 0.0332\n",
      "Epoch [38/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0336, val_mae: 0.0335\n",
      "Epoch [39/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0336, val_mae: 0.0333\n",
      "Epoch [40/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0335, val_mae: 0.0335\n",
      "Epoch [41/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0334, val_mae: 0.0332\n",
      "Epoch [42/1000] - train_loss: 0.0018, val_loss: 0.0020, train_mae: 0.0334, val_mae: 0.0354\n",
      "Epoch [43/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0334, val_mae: 0.0338\n",
      "Epoch [44/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0332, val_mae: 0.0330\n",
      "Epoch [45/1000] - train_loss: 0.0018, val_loss: 0.0021, train_mae: 0.0334, val_mae: 0.0365\n",
      "Epoch [46/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0333, val_mae: 0.0349\n",
      "Epoch [47/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0333, val_mae: 0.0334\n",
      "Epoch [48/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0332, val_mae: 0.0348\n",
      "Epoch [49/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0332, val_mae: 0.0334\n",
      "Epoch [50/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0331, val_mae: 0.0352\n",
      "Epoch [51/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0333, val_mae: 0.0340\n",
      "Epoch [52/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0333, val_mae: 0.0326\n",
      "Epoch [53/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0332, val_mae: 0.0332\n",
      "Epoch [54/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0331, val_mae: 0.0337\n",
      "Epoch [55/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0330, val_mae: 0.0342\n",
      "Epoch [56/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0330, val_mae: 0.0329\n",
      "Epoch [57/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0331, val_mae: 0.0326\n",
      "Epoch [58/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0332, val_mae: 0.0326\n",
      "Epoch [59/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0329, val_mae: 0.0327\n",
      "Epoch [60/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0331, val_mae: 0.0328\n",
      "Epoch [61/1000] - train_loss: 0.0018, val_loss: 0.0020, train_mae: 0.0330, val_mae: 0.0339\n",
      "Epoch [62/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0330, val_mae: 0.0329\n",
      "Epoch [63/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0330, val_mae: 0.0328\n",
      "Epoch [64/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0330, val_mae: 0.0350\n",
      "Epoch [65/1000] - train_loss: 0.0018, val_loss: 0.0020, train_mae: 0.0329, val_mae: 0.0362\n",
      "Epoch [66/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0330\n",
      "Epoch [67/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0330, val_mae: 0.0345\n",
      "Epoch [68/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0329, val_mae: 0.0353\n",
      "Epoch [69/1000] - train_loss: 0.0018, val_loss: 0.0017, train_mae: 0.0329, val_mae: 0.0325\n",
      "Epoch [70/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0335\n",
      "Epoch [71/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0332\n",
      "Epoch [72/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0330, val_mae: 0.0349\n",
      "Epoch [73/1000] - train_loss: 0.0017, val_loss: 0.0020, train_mae: 0.0328, val_mae: 0.0362\n",
      "Epoch [74/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0326\n",
      "Epoch [75/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0330\n",
      "Epoch [76/1000] - train_loss: 0.0018, val_loss: 0.0019, train_mae: 0.0329, val_mae: 0.0337\n",
      "Epoch [77/1000] - train_loss: 0.0018, val_loss: 0.0017, train_mae: 0.0328, val_mae: 0.0328\n",
      "Epoch [78/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0329, val_mae: 0.0331\n",
      "Epoch [79/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0326, val_mae: 0.0337\n",
      "Epoch [80/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0328, val_mae: 0.0336\n",
      "Epoch [81/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0323\n",
      "Epoch [82/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0326, val_mae: 0.0331\n",
      "Epoch [83/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0323\n",
      "Epoch [84/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0327, val_mae: 0.0329\n",
      "Epoch [85/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0321\n",
      "Epoch [86/1000] - train_loss: 0.0017, val_loss: 0.0021, train_mae: 0.0326, val_mae: 0.0370\n",
      "Epoch [87/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0326, val_mae: 0.0323\n",
      "Epoch [88/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0321\n",
      "Epoch [89/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0329\n",
      "Epoch [90/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0325, val_mae: 0.0324\n",
      "Epoch [91/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0326\n",
      "Epoch [92/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0329\n",
      "Epoch [93/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0323, val_mae: 0.0324\n",
      "Epoch [94/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0320\n",
      "Epoch [95/1000] - train_loss: 0.0017, val_loss: 0.0020, train_mae: 0.0321, val_mae: 0.0361\n",
      "Epoch [96/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0323, val_mae: 0.0320\n",
      "Epoch [97/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0322, val_mae: 0.0325\n",
      "Epoch [98/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0320, val_mae: 0.0333\n",
      "Epoch [99/1000] - train_loss: 0.0017, val_loss: 0.0021, train_mae: 0.0322, val_mae: 0.0372\n",
      "Epoch [100/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0323\n",
      "Epoch [101/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0325\n",
      "Epoch [102/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0319\n",
      "Epoch [103/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0322, val_mae: 0.0322\n",
      "Epoch [104/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0322, val_mae: 0.0345\n",
      "Epoch [105/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0322, val_mae: 0.0325\n",
      "Epoch [106/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0321, val_mae: 0.0338\n",
      "Epoch [107/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0323\n",
      "Epoch [108/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0325\n",
      "Epoch [109/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0322\n",
      "Epoch [110/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0319, val_mae: 0.0323\n",
      "Epoch [111/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0335\n",
      "Epoch [112/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0321, val_mae: 0.0322\n",
      "Epoch [113/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0319\n",
      "Epoch [114/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0324\n",
      "Epoch [115/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0316\n",
      "Epoch [116/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0317\n",
      "Epoch [117/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0324\n",
      "Epoch [118/1000] - train_loss: 0.0017, val_loss: 0.0024, train_mae: 0.0321, val_mae: 0.0378\n",
      "Epoch [119/1000] - train_loss: 0.0017, val_loss: 0.0018, train_mae: 0.0320, val_mae: 0.0346\n",
      "Epoch [120/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0322\n",
      "Epoch [121/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0320, val_mae: 0.0353\n",
      "Epoch [122/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0320, val_mae: 0.0314\n",
      "Epoch [123/1000] - train_loss: 0.0016, val_loss: 0.0020, train_mae: 0.0319, val_mae: 0.0359\n",
      "Epoch [124/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0321\n",
      "Epoch [125/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0317\n",
      "Epoch [126/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0318\n",
      "Epoch [127/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0321\n",
      "Epoch [128/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0319, val_mae: 0.0357\n",
      "Epoch [129/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0318\n",
      "Epoch [130/1000] - train_loss: 0.0017, val_loss: 0.0016, train_mae: 0.0320, val_mae: 0.0314\n",
      "Epoch [131/1000] - train_loss: 0.0017, val_loss: 0.0020, train_mae: 0.0319, val_mae: 0.0362\n",
      "Epoch [132/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0326\n",
      "Epoch [133/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0319\n",
      "Epoch [134/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0328\n",
      "Epoch [135/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0315\n",
      "Epoch [136/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0318, val_mae: 0.0322\n",
      "Epoch [137/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0319, val_mae: 0.0319\n",
      "Epoch [138/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0319\n",
      "Epoch [139/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0319, val_mae: 0.0325\n",
      "Epoch [140/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0320\n",
      "Epoch [141/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0316\n",
      "Epoch [142/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0323\n",
      "Epoch [143/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0318\n",
      "Epoch [144/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0332\n",
      "Epoch [145/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0320, val_mae: 0.0325\n",
      "Epoch [146/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0314\n",
      "Epoch [147/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0318, val_mae: 0.0339\n",
      "Epoch [148/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0314\n",
      "Epoch [149/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0314\n",
      "Epoch [150/1000] - train_loss: 0.0016, val_loss: 0.0020, train_mae: 0.0316, val_mae: 0.0361\n",
      "Epoch [151/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0322\n",
      "Epoch [152/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0329\n",
      "Epoch [153/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0314\n",
      "Epoch [154/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0321\n",
      "Epoch [155/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0319\n",
      "Epoch [156/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0319\n",
      "Epoch [157/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0317, val_mae: 0.0347\n",
      "Epoch [158/1000] - train_loss: 0.0016, val_loss: 0.0020, train_mae: 0.0317, val_mae: 0.0362\n",
      "Epoch [159/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0327\n",
      "Epoch [160/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0324\n",
      "Epoch [161/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0321\n",
      "Epoch [162/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0341\n",
      "Epoch [163/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0326\n",
      "Epoch [164/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0316\n",
      "Epoch [165/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0321\n",
      "Epoch [166/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0323\n",
      "Epoch [167/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0339\n",
      "Epoch [168/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0318, val_mae: 0.0326\n",
      "Epoch [169/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0317, val_mae: 0.0331\n",
      "Epoch [170/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0320\n",
      "Epoch [171/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0316\n",
      "Epoch [172/1000] - train_loss: 0.0017, val_loss: 0.0019, train_mae: 0.0319, val_mae: 0.0350\n",
      "Epoch [173/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0316\n",
      "Epoch [174/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0317\n",
      "Epoch [175/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0319\n",
      "Epoch [176/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0321\n",
      "Epoch [177/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0316\n",
      "Epoch [178/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0312\n",
      "Epoch [179/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0317, val_mae: 0.0325\n",
      "Epoch [180/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0317\n",
      "Epoch [181/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0316, val_mae: 0.0349\n",
      "Epoch [182/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0318, val_mae: 0.0314\n",
      "Epoch [183/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0319, val_mae: 0.0313\n",
      "Epoch [184/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0316\n",
      "Epoch [185/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0329\n",
      "Epoch [186/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0322\n",
      "Epoch [187/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0317, val_mae: 0.0341\n",
      "Epoch [188/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0333\n",
      "Epoch [189/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0321\n",
      "Epoch [190/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0319\n",
      "Epoch [191/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0313\n",
      "Epoch [192/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0316\n",
      "Epoch [193/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0315\n",
      "Epoch [194/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0320\n",
      "Epoch [195/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0315\n",
      "Epoch [196/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0314\n",
      "Epoch [197/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0324\n",
      "Epoch [198/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0312\n",
      "Epoch [199/1000] - train_loss: 0.0016, val_loss: 0.0021, train_mae: 0.0316, val_mae: 0.0374\n",
      "Epoch [200/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0321\n",
      "Epoch [201/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0315, val_mae: 0.0329\n",
      "Epoch [202/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0319\n",
      "Epoch [203/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0327\n",
      "Epoch [204/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0318\n",
      "Epoch [205/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0315, val_mae: 0.0331\n",
      "Epoch [206/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0317\n",
      "Epoch [207/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0317\n",
      "Epoch [208/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0315\n",
      "Epoch [209/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0321\n",
      "Epoch [210/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0318\n",
      "Epoch [211/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0312\n",
      "Epoch [212/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0320\n",
      "Epoch [213/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0312\n",
      "Epoch [214/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0321\n",
      "Epoch [215/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0315\n",
      "Epoch [216/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0318\n",
      "Epoch [217/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0315, val_mae: 0.0312\n",
      "Epoch [218/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0312\n",
      "Epoch [219/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0324\n",
      "Epoch [220/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0320\n",
      "Epoch [221/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0317, val_mae: 0.0357\n",
      "Epoch [222/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0317, val_mae: 0.0315\n",
      "Epoch [223/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0317, val_mae: 0.0314\n",
      "Epoch [224/1000] - train_loss: 0.0016, val_loss: 0.0019, train_mae: 0.0315, val_mae: 0.0333\n",
      "Epoch [225/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0315\n",
      "Epoch [226/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0326\n",
      "Epoch [227/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0311\n",
      "Epoch [228/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0316, val_mae: 0.0344\n",
      "Epoch [229/1000] - train_loss: 0.0016, val_loss: 0.0017, train_mae: 0.0316, val_mae: 0.0316\n",
      "Epoch [230/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0312\n",
      "Epoch [231/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0316, val_mae: 0.0314\n",
      "Epoch [232/1000] - train_loss: 0.0016, val_loss: 0.0018, train_mae: 0.0315, val_mae: 0.0333\n",
      "Epoch [233/1000] - train_loss: 0.0016, val_loss: 0.0020, train_mae: 0.0316, val_mae: 0.0360\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n",
      "Epoch [1/1000] - train_loss: 0.0150, val_loss: 0.0057, train_mae: 0.0885, val_mae: 0.0595\n",
      "Epoch [2/1000] - train_loss: 0.0047, val_loss: 0.0039, train_mae: 0.0539, val_mae: 0.0492\n",
      "Epoch [3/1000] - train_loss: 0.0035, val_loss: 0.0031, train_mae: 0.0461, val_mae: 0.0440\n",
      "Epoch [4/1000] - train_loss: 0.0029, val_loss: 0.0027, train_mae: 0.0422, val_mae: 0.0413\n",
      "Epoch [5/1000] - train_loss: 0.0026, val_loss: 0.0025, train_mae: 0.0403, val_mae: 0.0396\n",
      "Epoch [6/1000] - train_loss: 0.0024, val_loss: 0.0024, train_mae: 0.0388, val_mae: 0.0384\n",
      "Epoch [7/1000] - train_loss: 0.0023, val_loss: 0.0022, train_mae: 0.0376, val_mae: 0.0374\n",
      "Epoch [8/1000] - train_loss: 0.0022, val_loss: 0.0021, train_mae: 0.0367, val_mae: 0.0365\n",
      "Epoch [9/1000] - train_loss: 0.0021, val_loss: 0.0020, train_mae: 0.0357, val_mae: 0.0355\n",
      "Epoch [10/1000] - train_loss: 0.0020, val_loss: 0.0019, train_mae: 0.0348, val_mae: 0.0346\n",
      "Epoch [11/1000] - train_loss: 0.0019, val_loss: 0.0018, train_mae: 0.0340, val_mae: 0.0337\n",
      "Epoch [12/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0329, val_mae: 0.0328\n",
      "Epoch [13/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0321, val_mae: 0.0319\n",
      "Epoch [14/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0312, val_mae: 0.0311\n",
      "Epoch [15/1000] - train_loss: 0.0015, val_loss: 0.0015, train_mae: 0.0306, val_mae: 0.0303\n",
      "Epoch [16/1000] - train_loss: 0.0015, val_loss: 0.0015, train_mae: 0.0301, val_mae: 0.0297\n",
      "Epoch [17/1000] - train_loss: 0.0014, val_loss: 0.0014, train_mae: 0.0297, val_mae: 0.0292\n",
      "Epoch [18/1000] - train_loss: 0.0014, val_loss: 0.0014, train_mae: 0.0293, val_mae: 0.0288\n",
      "Epoch [19/1000] - train_loss: 0.0014, val_loss: 0.0013, train_mae: 0.0288, val_mae: 0.0284\n",
      "Epoch [20/1000] - train_loss: 0.0013, val_loss: 0.0013, train_mae: 0.0285, val_mae: 0.0280\n",
      "Epoch [21/1000] - train_loss: 0.0013, val_loss: 0.0013, train_mae: 0.0282, val_mae: 0.0277\n",
      "Epoch [22/1000] - train_loss: 0.0013, val_loss: 0.0012, train_mae: 0.0279, val_mae: 0.0273\n",
      "Epoch [23/1000] - train_loss: 0.0013, val_loss: 0.0012, train_mae: 0.0277, val_mae: 0.0271\n",
      "Epoch [24/1000] - train_loss: 0.0012, val_loss: 0.0012, train_mae: 0.0273, val_mae: 0.0268\n",
      "Epoch [25/1000] - train_loss: 0.0012, val_loss: 0.0012, train_mae: 0.0272, val_mae: 0.0266\n",
      "Epoch [26/1000] - train_loss: 0.0012, val_loss: 0.0011, train_mae: 0.0268, val_mae: 0.0264\n",
      "Epoch [27/1000] - train_loss: 0.0012, val_loss: 0.0011, train_mae: 0.0266, val_mae: 0.0262\n",
      "Epoch [28/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0264, val_mae: 0.0260\n",
      "Epoch [29/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0262, val_mae: 0.0258\n",
      "Epoch [30/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0259, val_mae: 0.0256\n",
      "Epoch [31/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0258, val_mae: 0.0254\n",
      "Epoch [32/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0256, val_mae: 0.0253\n",
      "Epoch [33/1000] - train_loss: 0.0011, val_loss: 0.0010, train_mae: 0.0253, val_mae: 0.0251\n",
      "Epoch [34/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0252, val_mae: 0.0250\n",
      "Epoch [35/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0250, val_mae: 0.0248\n",
      "Epoch [36/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0248, val_mae: 0.0247\n",
      "Epoch [37/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0247, val_mae: 0.0245\n",
      "Epoch [38/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0245, val_mae: 0.0244\n",
      "Epoch [39/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0244, val_mae: 0.0243\n",
      "Epoch [40/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0244, val_mae: 0.0242\n",
      "Epoch [41/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0243, val_mae: 0.0240\n",
      "Epoch [42/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0242, val_mae: 0.0240\n",
      "Epoch [43/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0239, val_mae: 0.0239\n",
      "Epoch [44/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0240, val_mae: 0.0238\n",
      "Epoch [45/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0238, val_mae: 0.0237\n",
      "Epoch [46/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0237, val_mae: 0.0237\n",
      "Epoch [47/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0237, val_mae: 0.0236\n",
      "Epoch [48/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0236, val_mae: 0.0235\n",
      "Epoch [49/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0235, val_mae: 0.0235\n",
      "Epoch [50/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0235, val_mae: 0.0234\n",
      "Epoch [51/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0235, val_mae: 0.0234\n",
      "Epoch [52/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0233, val_mae: 0.0233\n",
      "Epoch [53/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0233, val_mae: 0.0233\n",
      "Epoch [54/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0232, val_mae: 0.0232\n",
      "Epoch [55/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0231, val_mae: 0.0232\n",
      "Epoch [56/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0231, val_mae: 0.0231\n",
      "Epoch [57/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0230, val_mae: 0.0230\n",
      "Epoch [58/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0229, val_mae: 0.0230\n",
      "Epoch [59/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0229, val_mae: 0.0229\n",
      "Epoch [60/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0228, val_mae: 0.0228\n",
      "Epoch [61/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0228, val_mae: 0.0228\n",
      "Epoch [62/1000] - train_loss: 0.0008, val_loss: 0.0009, train_mae: 0.0227, val_mae: 0.0227\n",
      "Epoch [63/1000] - train_loss: 0.0008, val_loss: 0.0009, train_mae: 0.0227, val_mae: 0.0226\n",
      "Epoch [64/1000] - train_loss: 0.0008, val_loss: 0.0009, train_mae: 0.0225, val_mae: 0.0226\n",
      "Epoch [65/1000] - train_loss: 0.0008, val_loss: 0.0009, train_mae: 0.0225, val_mae: 0.0225\n",
      "Epoch [66/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0223, val_mae: 0.0224\n",
      "Epoch [67/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0224, val_mae: 0.0224\n",
      "Epoch [68/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0223, val_mae: 0.0223\n",
      "Epoch [69/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0222, val_mae: 0.0223\n",
      "Epoch [70/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0221, val_mae: 0.0222\n",
      "Epoch [71/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0220, val_mae: 0.0221\n",
      "Epoch [72/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0220, val_mae: 0.0221\n",
      "Epoch [73/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0220, val_mae: 0.0220\n",
      "Epoch [74/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0219, val_mae: 0.0220\n",
      "Epoch [75/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0219, val_mae: 0.0219\n",
      "Epoch [76/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0218, val_mae: 0.0219\n",
      "Epoch [77/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0217, val_mae: 0.0218\n",
      "Epoch [78/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0216, val_mae: 0.0217\n",
      "Epoch [79/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0217, val_mae: 0.0217\n",
      "Epoch [80/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0215, val_mae: 0.0216\n",
      "Epoch [81/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0216, val_mae: 0.0216\n",
      "Epoch [82/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0214, val_mae: 0.0215\n",
      "Epoch [83/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0215, val_mae: 0.0214\n",
      "Epoch [84/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0214, val_mae: 0.0214\n",
      "Epoch [85/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0212, val_mae: 0.0213\n",
      "Epoch [86/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0212, val_mae: 0.0212\n",
      "Epoch [87/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0211, val_mae: 0.0212\n",
      "Epoch [88/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0211, val_mae: 0.0211\n",
      "Epoch [89/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0210, val_mae: 0.0210\n",
      "Epoch [90/1000] - train_loss: 0.0007, val_loss: 0.0008, train_mae: 0.0209, val_mae: 0.0210\n",
      "Epoch [91/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0208, val_mae: 0.0209\n",
      "Epoch [92/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0208, val_mae: 0.0209\n",
      "Epoch [93/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0207, val_mae: 0.0208\n",
      "Epoch [94/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0207, val_mae: 0.0207\n",
      "Epoch [95/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0206, val_mae: 0.0207\n",
      "Epoch [96/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0206, val_mae: 0.0206\n",
      "Epoch [97/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0205, val_mae: 0.0206\n",
      "Epoch [98/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0204, val_mae: 0.0205\n",
      "Epoch [99/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0204, val_mae: 0.0204\n",
      "Epoch [100/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0202, val_mae: 0.0204\n",
      "Epoch [101/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0202, val_mae: 0.0203\n",
      "Epoch [102/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0201, val_mae: 0.0203\n",
      "Epoch [103/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0200, val_mae: 0.0202\n",
      "Epoch [104/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0200, val_mae: 0.0202\n",
      "Epoch [105/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0199, val_mae: 0.0201\n",
      "Epoch [106/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0199, val_mae: 0.0200\n",
      "Epoch [107/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0198, val_mae: 0.0200\n",
      "Epoch [108/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0198, val_mae: 0.0199\n",
      "Epoch [109/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0196, val_mae: 0.0199\n",
      "Epoch [110/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0197, val_mae: 0.0198\n",
      "Epoch [111/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0196, val_mae: 0.0198\n",
      "Epoch [112/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0196, val_mae: 0.0197\n",
      "Epoch [113/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0194, val_mae: 0.0196\n",
      "Epoch [114/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0195, val_mae: 0.0196\n",
      "Epoch [115/1000] - train_loss: 0.0006, val_loss: 0.0007, train_mae: 0.0194, val_mae: 0.0195\n",
      "Epoch [116/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0193, val_mae: 0.0194\n",
      "Epoch [117/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0193, val_mae: 0.0194\n",
      "Epoch [118/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0192, val_mae: 0.0193\n",
      "Epoch [119/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0191, val_mae: 0.0192\n",
      "Epoch [120/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0191, val_mae: 0.0192\n",
      "Epoch [121/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0191, val_mae: 0.0191\n",
      "Epoch [122/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0190, val_mae: 0.0190\n",
      "Epoch [123/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0189, val_mae: 0.0190\n",
      "Epoch [124/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0189, val_mae: 0.0189\n",
      "Epoch [125/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0187, val_mae: 0.0189\n",
      "Epoch [126/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0188, val_mae: 0.0188\n",
      "Epoch [127/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0187, val_mae: 0.0188\n",
      "Epoch [128/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0186, val_mae: 0.0187\n",
      "Epoch [129/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0185, val_mae: 0.0187\n",
      "Epoch [130/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0184, val_mae: 0.0186\n",
      "Epoch [131/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0184, val_mae: 0.0186\n",
      "Epoch [132/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0183, val_mae: 0.0185\n",
      "Epoch [133/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0182, val_mae: 0.0185\n",
      "Epoch [134/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0181, val_mae: 0.0185\n",
      "Epoch [135/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0181, val_mae: 0.0184\n",
      "Epoch [136/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0180, val_mae: 0.0184\n",
      "Epoch [137/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0178, val_mae: 0.0184\n",
      "Epoch [138/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0178, val_mae: 0.0183\n",
      "Epoch [139/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0177, val_mae: 0.0183\n",
      "Epoch [140/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0177, val_mae: 0.0183\n",
      "Epoch [141/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0175, val_mae: 0.0182\n",
      "Epoch [142/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0175, val_mae: 0.0181\n",
      "Epoch [143/1000] - train_loss: 0.0005, val_loss: 0.0006, train_mae: 0.0176, val_mae: 0.0181\n",
      "Epoch [144/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0174, val_mae: 0.0180\n",
      "Epoch [145/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0173, val_mae: 0.0179\n",
      "Epoch [146/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0173, val_mae: 0.0179\n",
      "Epoch [147/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0172, val_mae: 0.0178\n",
      "Epoch [148/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0177\n",
      "Epoch [149/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0172, val_mae: 0.0176\n",
      "Epoch [150/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0176\n",
      "Epoch [151/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0175\n",
      "Epoch [152/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0170, val_mae: 0.0174\n",
      "Epoch [153/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0170, val_mae: 0.0173\n",
      "Epoch [154/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0169, val_mae: 0.0173\n",
      "Epoch [155/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0168, val_mae: 0.0172\n",
      "Epoch [156/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0169, val_mae: 0.0171\n",
      "Epoch [157/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0168, val_mae: 0.0170\n",
      "Epoch [158/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0168, val_mae: 0.0170\n",
      "Epoch [159/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0167, val_mae: 0.0169\n",
      "Epoch [160/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0166, val_mae: 0.0168\n",
      "Epoch [161/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0167, val_mae: 0.0168\n",
      "Epoch [162/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0166, val_mae: 0.0167\n",
      "Epoch [163/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0166, val_mae: 0.0167\n",
      "Epoch [164/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0166, val_mae: 0.0166\n",
      "Epoch [165/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0164, val_mae: 0.0166\n",
      "Epoch [166/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0165, val_mae: 0.0165\n",
      "Epoch [167/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0165, val_mae: 0.0165\n",
      "Epoch [168/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0164, val_mae: 0.0164\n",
      "Epoch [169/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0164, val_mae: 0.0164\n",
      "Epoch [170/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0164\n",
      "Epoch [171/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0163\n",
      "Epoch [172/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0163\n",
      "Epoch [173/1000] - train_loss: 0.0004, val_loss: 0.0005, train_mae: 0.0163, val_mae: 0.0163\n",
      "Epoch [174/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0162\n",
      "Epoch [175/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0162\n",
      "Epoch [176/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0162\n",
      "Epoch [177/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0161\n",
      "Epoch [178/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0161\n",
      "Epoch [179/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0161\n",
      "Epoch [180/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0160\n",
      "Epoch [181/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0160\n",
      "Epoch [182/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0160\n",
      "Epoch [183/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0159\n",
      "Epoch [184/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0159\n",
      "Epoch [185/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0159\n",
      "Epoch [186/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0158\n",
      "Epoch [187/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0158\n",
      "Epoch [188/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0158\n",
      "Epoch [189/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0157\n",
      "Epoch [190/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0157\n",
      "Epoch [191/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0157\n",
      "Epoch [192/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0157\n",
      "Epoch [193/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0156\n",
      "Epoch [194/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0156\n",
      "Epoch [195/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0156\n",
      "Epoch [196/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0155\n",
      "Epoch [197/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0155\n",
      "Epoch [198/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0155\n",
      "Epoch [199/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0155\n",
      "Epoch [200/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0154\n",
      "Epoch [201/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0154\n",
      "Epoch [202/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0154\n",
      "Epoch [203/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0153\n",
      "Epoch [204/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0153\n",
      "Epoch [205/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0153\n",
      "Epoch [206/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0153\n",
      "Epoch [207/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0152\n",
      "Epoch [208/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0152\n",
      "Epoch [209/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0152\n",
      "Epoch [210/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0152\n",
      "Epoch [211/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0151\n",
      "Epoch [212/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0151\n",
      "Epoch [213/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0151\n",
      "Epoch [214/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0151\n",
      "Epoch [215/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0150\n",
      "Epoch [216/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0150\n",
      "Epoch [217/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0150\n",
      "Epoch [218/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0150, val_mae: 0.0150\n",
      "Epoch [219/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0149\n",
      "Epoch [220/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0149\n",
      "Epoch [221/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0149\n",
      "Epoch [222/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0149\n",
      "Epoch [223/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0149, val_mae: 0.0149\n",
      "Epoch [224/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0148\n",
      "Epoch [225/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0148\n",
      "Epoch [226/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0148\n",
      "Epoch [227/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0148\n",
      "Epoch [228/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0148\n",
      "Epoch [229/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0148, val_mae: 0.0147\n",
      "Epoch [230/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0147\n",
      "Epoch [231/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0147\n",
      "Epoch [232/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0147\n",
      "Epoch [233/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0146\n",
      "Epoch [234/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0146\n",
      "Epoch [235/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0146\n",
      "Epoch [236/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0146\n",
      "Epoch [237/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0146\n",
      "Epoch [238/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0147, val_mae: 0.0145\n",
      "Epoch [239/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0145\n",
      "Epoch [240/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0145\n",
      "Epoch [241/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0145\n",
      "Epoch [242/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0145\n",
      "Epoch [243/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0145\n",
      "Epoch [244/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0144\n",
      "Epoch [245/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0144\n",
      "Epoch [246/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0144\n",
      "Epoch [247/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0144\n",
      "Epoch [248/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0146, val_mae: 0.0144\n",
      "Epoch [249/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0143\n",
      "Epoch [250/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0143\n",
      "Epoch [251/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0143\n",
      "Epoch [252/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0143\n",
      "Epoch [253/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0143\n",
      "Epoch [254/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0145, val_mae: 0.0143\n",
      "Epoch [255/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0144, val_mae: 0.0142\n",
      "Epoch [256/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0142\n",
      "Epoch [257/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0142\n",
      "Epoch [258/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0142\n",
      "Epoch [259/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0142\n",
      "Epoch [260/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0142\n",
      "Epoch [261/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0141\n",
      "Epoch [262/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0141\n",
      "Epoch [263/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0141\n",
      "Epoch [264/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0141\n",
      "Epoch [265/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0141\n",
      "Epoch [266/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0141\n",
      "Epoch [267/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0141\n",
      "Epoch [268/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0140\n",
      "Epoch [269/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0140\n",
      "Epoch [270/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0140\n",
      "Epoch [271/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0140\n",
      "Epoch [272/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0140\n",
      "Epoch [273/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0140\n",
      "Epoch [274/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0140\n",
      "Epoch [275/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0140\n",
      "Epoch [276/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0139\n",
      "Epoch [277/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0139\n",
      "Epoch [278/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0139\n",
      "Epoch [279/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0139\n",
      "Epoch [280/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0139\n",
      "Epoch [281/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0139\n",
      "Epoch [282/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0139\n",
      "Epoch [283/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0139\n",
      "Epoch [284/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0139\n",
      "Epoch [285/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [286/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [287/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0138\n",
      "Epoch [288/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [289/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [290/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [291/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0138\n",
      "Epoch [292/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [293/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [294/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0138\n",
      "Epoch [295/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0138\n",
      "Epoch [296/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0138\n",
      "Epoch [297/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [298/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0137\n",
      "Epoch [299/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [300/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0137\n",
      "Epoch [301/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [302/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [303/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [304/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [305/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [306/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0137\n",
      "Epoch [307/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0137\n",
      "Epoch [308/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0136\n",
      "Epoch [309/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0136\n",
      "Epoch [310/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0136\n",
      "Epoch [311/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0136\n",
      "Epoch [312/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0136\n",
      "Epoch [313/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0136\n",
      "Epoch [314/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0136\n",
      "Epoch [315/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0136\n",
      "Epoch [316/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0136\n",
      "Epoch [317/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0136\n",
      "Epoch [318/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0136\n",
      "Epoch [319/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0135\n",
      "Epoch [320/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0135\n",
      "Epoch [321/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0135\n",
      "Epoch [322/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0135\n",
      "Epoch [323/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0135\n",
      "Epoch [324/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0135\n",
      "Epoch [325/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0135\n",
      "Epoch [326/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0135\n",
      "Epoch [327/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0135\n",
      "Epoch [328/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0135\n",
      "Epoch [329/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0135\n",
      "Epoch [330/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0135\n",
      "Epoch [331/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0135\n",
      "Epoch [332/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0135\n",
      "Epoch [333/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0134\n",
      "Epoch [334/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [335/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [336/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [337/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [338/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [339/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [340/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [341/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0134\n",
      "Epoch [342/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0134\n",
      "Epoch [343/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [344/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0134\n",
      "Epoch [345/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0134\n",
      "Epoch [346/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0134\n",
      "Epoch [347/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0133\n",
      "Epoch [348/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0133\n",
      "Epoch [349/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0133\n",
      "Epoch [350/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [351/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [352/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [353/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [354/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [355/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [356/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [357/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [358/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0133\n",
      "Epoch [359/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [360/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0133\n",
      "Epoch [361/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0133\n",
      "Epoch [362/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0132\n",
      "Epoch [363/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0132\n",
      "Epoch [364/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [365/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [366/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0132\n",
      "Epoch [367/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0132\n",
      "Epoch [368/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0132\n",
      "Epoch [369/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [370/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0132\n",
      "Epoch [371/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [372/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0132\n",
      "Epoch [373/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0132\n",
      "Epoch [374/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [375/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0132\n",
      "Epoch [376/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [377/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [378/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [379/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [380/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0132\n",
      "Epoch [381/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0131\n",
      "Epoch [382/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0131\n",
      "Epoch [383/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0131\n",
      "Epoch [384/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0131\n",
      "Epoch [385/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0131\n",
      "Epoch [386/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0131\n",
      "Epoch [387/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0131\n",
      "Epoch [388/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0131\n",
      "Epoch [389/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0131\n",
      "Epoch [390/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0131\n",
      "Epoch [391/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0131\n",
      "Epoch [392/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0131\n",
      "Epoch [393/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0131\n",
      "Epoch [394/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0131\n",
      "Epoch [395/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0131\n",
      "Epoch [396/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [397/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [398/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0130\n",
      "Epoch [399/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [400/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [401/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [402/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [403/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [404/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [405/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [406/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [407/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [408/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [409/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0130\n",
      "Epoch [410/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [411/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [412/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [413/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0129\n",
      "Epoch [414/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [415/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [416/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [417/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0129\n",
      "Epoch [418/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [419/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [420/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [421/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [422/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [423/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [424/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [425/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [426/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [427/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [428/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [429/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [430/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [431/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [432/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [433/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [434/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [435/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [436/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [437/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [438/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0129\n",
      "Epoch [439/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [440/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0128\n",
      "Epoch [441/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0128\n",
      "Epoch [442/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [443/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [444/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0128\n",
      "Epoch [445/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [446/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [447/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0128\n",
      "Epoch [448/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [449/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [450/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [451/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [452/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [453/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [454/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [455/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [456/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [457/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [458/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [459/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [460/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [461/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [462/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [463/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [464/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [465/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [466/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [467/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [468/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [469/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [470/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [471/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [472/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [473/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [474/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [475/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [476/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [477/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [478/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [479/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [480/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [481/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [482/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [483/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [484/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0128\n",
      "Epoch [485/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [486/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [487/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [488/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [489/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [490/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [491/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [492/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [493/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [494/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [495/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [496/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [497/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [498/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [499/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [500/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [501/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0128\n",
      "Epoch [502/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [503/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [504/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0127\n",
      "Epoch [505/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [506/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [507/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0127\n",
      "Epoch [508/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [509/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [510/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [511/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [512/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [513/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [514/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [515/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [516/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [517/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [518/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [519/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [520/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [521/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [522/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [523/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [524/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [525/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0126\n",
      "Epoch [526/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [527/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [528/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0126\n",
      "Epoch [529/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [530/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0126\n",
      "Epoch [531/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [532/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [533/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [534/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [535/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [536/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [537/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [538/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [539/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [540/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [541/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [542/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [543/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [544/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [545/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [546/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [547/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [548/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [549/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [550/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [551/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [552/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0124\n",
      "Epoch [553/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [554/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0124\n",
      "Epoch [555/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [556/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [557/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [558/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [559/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [560/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [561/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [562/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [563/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [564/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [565/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [566/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [567/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0125\n",
      "Epoch [568/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [569/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [570/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0125\n",
      "Epoch [571/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [572/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [573/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [574/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [575/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [576/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [577/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0125\n",
      "Epoch [578/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [579/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [580/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [581/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0124\n",
      "Epoch [582/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [583/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [584/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [585/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [586/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [587/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [588/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [589/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [590/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0124\n",
      "Epoch [591/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [592/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [593/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [594/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [595/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0124\n",
      "Epoch [596/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0124\n",
      "Epoch [597/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [598/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [599/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [600/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [601/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [602/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [603/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [604/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [605/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [606/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [607/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [608/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [609/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [610/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [611/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [612/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [613/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [614/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [615/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [616/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [617/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [618/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [619/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [620/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [621/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [622/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [623/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [624/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [625/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [626/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [627/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [628/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [629/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [630/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [631/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [632/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [633/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [634/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [635/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [636/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [637/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [638/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [639/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [640/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [641/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [642/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [643/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [644/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [645/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [646/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [647/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [648/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [649/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [650/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [651/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [652/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [653/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [654/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [655/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [656/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [657/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [658/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [659/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [660/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [661/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [662/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0123\n",
      "Epoch [663/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0123\n",
      "Epoch [664/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [665/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [666/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [667/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [668/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [669/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [670/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [671/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [672/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [673/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [674/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [675/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [676/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [677/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [678/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [679/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [680/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [681/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [682/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [683/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [684/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [685/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [686/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [687/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [688/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0122\n",
      "Epoch [689/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [690/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [691/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [692/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [693/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [694/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [695/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [696/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [697/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [698/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [699/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [700/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [701/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [702/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [703/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [704/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [705/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [706/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [707/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [708/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [709/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [710/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [711/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [712/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [713/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [714/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [715/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [716/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [717/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [718/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [719/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [720/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [721/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [722/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [723/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [724/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [725/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [726/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [727/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [728/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [729/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [730/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [731/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [732/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [733/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [734/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [735/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [736/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [737/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [738/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [739/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [740/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [741/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [742/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [743/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [744/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [745/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [746/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [747/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [748/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [749/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [750/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [751/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [752/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [753/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [754/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [755/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [756/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [757/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [758/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [759/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [760/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [761/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [762/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [763/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [764/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [765/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [766/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [767/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [768/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [769/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [770/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [771/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [772/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [773/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [774/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [775/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [776/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [777/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [778/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [779/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [780/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [781/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [782/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [783/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [784/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [785/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [786/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [787/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [788/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [789/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [790/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [791/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [792/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [793/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [794/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [795/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [796/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [797/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [798/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [799/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [800/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [801/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [802/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [803/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [804/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [805/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [806/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [807/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [808/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [809/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [810/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [811/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [812/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0127, val_mae: 0.0121\n",
      "Epoch [813/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [814/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [815/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [816/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [817/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [818/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [819/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [820/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [821/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [822/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [823/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [824/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [825/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [826/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [827/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [828/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [829/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [830/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [831/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [832/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [833/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [834/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [835/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [836/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [837/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [838/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [839/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [840/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [841/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [842/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0121\n",
      "Epoch [843/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0120\n",
      "Epoch [844/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0120\n",
      "Epoch [845/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0120\n",
      "Epoch [846/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0120\n",
      "Epoch [847/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0120\n",
      "Epoch [848/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0120\n",
      "Epoch [849/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0120\n",
      "Epoch [850/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0120\n",
      "Epoch [851/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [852/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [853/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [854/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [855/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [856/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [857/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [858/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [859/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [860/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [861/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [862/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0119\n",
      "Epoch [863/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [864/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [865/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [866/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [867/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [868/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [869/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [870/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [871/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [872/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [873/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [874/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [875/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [876/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [877/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [878/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [879/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [880/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [881/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [882/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [883/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [884/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [885/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [886/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [887/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [888/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [889/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [890/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [891/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [892/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [893/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [894/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [895/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [896/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [897/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [898/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [899/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [900/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [901/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [902/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [903/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [904/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [905/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [906/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [907/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [908/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [909/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [910/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [911/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [912/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0119\n",
      "Epoch [913/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0119\n",
      "Epoch [914/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [915/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [916/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [917/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [918/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [919/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [920/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [921/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [922/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [923/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [924/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [925/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [926/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [927/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [928/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [929/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [930/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [931/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [932/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [933/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [934/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [935/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [936/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [937/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [938/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [939/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [940/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [941/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [942/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [943/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [944/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [945/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [946/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [947/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [948/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [949/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [950/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [951/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [952/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [953/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [954/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [955/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [956/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [957/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [958/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [959/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [960/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [961/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [962/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [963/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [964/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [965/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [966/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [967/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [968/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [969/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [970/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [971/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [972/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [973/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0118\n",
      "Epoch [974/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [975/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [976/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [977/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [978/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [979/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [980/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [981/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [982/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [983/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Epoch [984/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0118\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n",
      "Epoch [1/1000] - train_loss: 0.0152, val_loss: 0.0055, train_mae: 0.0873, val_mae: 0.0583\n",
      "Epoch [2/1000] - train_loss: 0.0046, val_loss: 0.0039, train_mae: 0.0531, val_mae: 0.0489\n",
      "Epoch [3/1000] - train_loss: 0.0036, val_loss: 0.0032, train_mae: 0.0469, val_mae: 0.0444\n",
      "Epoch [4/1000] - train_loss: 0.0031, val_loss: 0.0029, train_mae: 0.0440, val_mae: 0.0423\n",
      "Epoch [5/1000] - train_loss: 0.0029, val_loss: 0.0027, train_mae: 0.0420, val_mae: 0.0408\n",
      "Epoch [6/1000] - train_loss: 0.0026, val_loss: 0.0025, train_mae: 0.0401, val_mae: 0.0394\n",
      "Epoch [7/1000] - train_loss: 0.0024, val_loss: 0.0023, train_mae: 0.0387, val_mae: 0.0380\n",
      "Epoch [8/1000] - train_loss: 0.0023, val_loss: 0.0022, train_mae: 0.0373, val_mae: 0.0366\n",
      "Epoch [9/1000] - train_loss: 0.0021, val_loss: 0.0020, train_mae: 0.0361, val_mae: 0.0352\n",
      "Epoch [10/1000] - train_loss: 0.0020, val_loss: 0.0019, train_mae: 0.0347, val_mae: 0.0339\n",
      "Epoch [11/1000] - train_loss: 0.0018, val_loss: 0.0018, train_mae: 0.0334, val_mae: 0.0326\n",
      "Epoch [12/1000] - train_loss: 0.0017, val_loss: 0.0017, train_mae: 0.0324, val_mae: 0.0316\n",
      "Epoch [13/1000] - train_loss: 0.0016, val_loss: 0.0016, train_mae: 0.0312, val_mae: 0.0306\n",
      "Epoch [14/1000] - train_loss: 0.0015, val_loss: 0.0015, train_mae: 0.0303, val_mae: 0.0296\n",
      "Epoch [15/1000] - train_loss: 0.0014, val_loss: 0.0014, train_mae: 0.0295, val_mae: 0.0287\n",
      "Epoch [16/1000] - train_loss: 0.0014, val_loss: 0.0013, train_mae: 0.0288, val_mae: 0.0280\n",
      "Epoch [17/1000] - train_loss: 0.0013, val_loss: 0.0013, train_mae: 0.0282, val_mae: 0.0275\n",
      "Epoch [18/1000] - train_loss: 0.0013, val_loss: 0.0012, train_mae: 0.0278, val_mae: 0.0270\n",
      "Epoch [19/1000] - train_loss: 0.0012, val_loss: 0.0012, train_mae: 0.0274, val_mae: 0.0266\n",
      "Epoch [20/1000] - train_loss: 0.0012, val_loss: 0.0012, train_mae: 0.0270, val_mae: 0.0263\n",
      "Epoch [21/1000] - train_loss: 0.0012, val_loss: 0.0011, train_mae: 0.0267, val_mae: 0.0261\n",
      "Epoch [22/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0263, val_mae: 0.0258\n",
      "Epoch [23/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0262, val_mae: 0.0256\n",
      "Epoch [24/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0258, val_mae: 0.0254\n",
      "Epoch [25/1000] - train_loss: 0.0011, val_loss: 0.0011, train_mae: 0.0256, val_mae: 0.0251\n",
      "Epoch [26/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0253, val_mae: 0.0249\n",
      "Epoch [27/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0251, val_mae: 0.0246\n",
      "Epoch [28/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0248, val_mae: 0.0244\n",
      "Epoch [29/1000] - train_loss: 0.0010, val_loss: 0.0010, train_mae: 0.0246, val_mae: 0.0241\n",
      "Epoch [30/1000] - train_loss: 0.0010, val_loss: 0.0009, train_mae: 0.0243, val_mae: 0.0238\n",
      "Epoch [31/1000] - train_loss: 0.0010, val_loss: 0.0009, train_mae: 0.0241, val_mae: 0.0236\n",
      "Epoch [32/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0238, val_mae: 0.0233\n",
      "Epoch [33/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0236, val_mae: 0.0231\n",
      "Epoch [34/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0234, val_mae: 0.0229\n",
      "Epoch [35/1000] - train_loss: 0.0009, val_loss: 0.0009, train_mae: 0.0231, val_mae: 0.0226\n",
      "Epoch [36/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0229, val_mae: 0.0224\n",
      "Epoch [37/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0229, val_mae: 0.0222\n",
      "Epoch [38/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0226, val_mae: 0.0220\n",
      "Epoch [39/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0224, val_mae: 0.0218\n",
      "Epoch [40/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0222, val_mae: 0.0217\n",
      "Epoch [41/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0221, val_mae: 0.0215\n",
      "Epoch [42/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0219, val_mae: 0.0213\n",
      "Epoch [43/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0217, val_mae: 0.0212\n",
      "Epoch [44/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0215, val_mae: 0.0210\n",
      "Epoch [45/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0213, val_mae: 0.0209\n",
      "Epoch [46/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0212, val_mae: 0.0207\n",
      "Epoch [47/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0210, val_mae: 0.0206\n",
      "Epoch [48/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0208, val_mae: 0.0204\n",
      "Epoch [49/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0206, val_mae: 0.0202\n",
      "Epoch [50/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0205, val_mae: 0.0201\n",
      "Epoch [51/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0203, val_mae: 0.0199\n",
      "Epoch [52/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0201, val_mae: 0.0197\n",
      "Epoch [53/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0200, val_mae: 0.0195\n",
      "Epoch [54/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0198, val_mae: 0.0193\n",
      "Epoch [55/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0197, val_mae: 0.0191\n",
      "Epoch [56/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0196, val_mae: 0.0189\n",
      "Epoch [57/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0194, val_mae: 0.0188\n",
      "Epoch [58/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0193, val_mae: 0.0186\n",
      "Epoch [59/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0192, val_mae: 0.0185\n",
      "Epoch [60/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0191, val_mae: 0.0184\n",
      "Epoch [61/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0190, val_mae: 0.0182\n",
      "Epoch [62/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0189, val_mae: 0.0181\n",
      "Epoch [63/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0187, val_mae: 0.0180\n",
      "Epoch [64/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0186, val_mae: 0.0179\n",
      "Epoch [65/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0186, val_mae: 0.0178\n",
      "Epoch [66/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0185, val_mae: 0.0177\n",
      "Epoch [67/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0184, val_mae: 0.0177\n",
      "Epoch [68/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0182, val_mae: 0.0176\n",
      "Epoch [69/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0182, val_mae: 0.0175\n",
      "Epoch [70/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0181, val_mae: 0.0174\n",
      "Epoch [71/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0179, val_mae: 0.0173\n",
      "Epoch [72/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0179, val_mae: 0.0172\n",
      "Epoch [73/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0180, val_mae: 0.0172\n",
      "Epoch [74/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0178, val_mae: 0.0171\n",
      "Epoch [75/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0177, val_mae: 0.0170\n",
      "Epoch [76/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0176, val_mae: 0.0169\n",
      "Epoch [77/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0176, val_mae: 0.0169\n",
      "Epoch [78/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0175, val_mae: 0.0168\n",
      "Epoch [79/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0175, val_mae: 0.0167\n",
      "Epoch [80/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0174, val_mae: 0.0167\n",
      "Epoch [81/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0174, val_mae: 0.0166\n",
      "Epoch [82/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0172, val_mae: 0.0165\n",
      "Epoch [83/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0172, val_mae: 0.0165\n",
      "Epoch [84/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0164\n",
      "Epoch [85/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0170, val_mae: 0.0164\n",
      "Epoch [86/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0170, val_mae: 0.0164\n",
      "Epoch [87/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0169, val_mae: 0.0163\n",
      "Epoch [88/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0169, val_mae: 0.0163\n",
      "Epoch [89/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0169, val_mae: 0.0163\n",
      "Epoch [90/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0168, val_mae: 0.0163\n",
      "Epoch [91/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0168, val_mae: 0.0163\n",
      "Epoch [92/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0162\n",
      "Epoch [93/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0162\n",
      "Epoch [94/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0161\n",
      "Epoch [95/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0160\n",
      "Epoch [96/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0159\n",
      "Epoch [97/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0166, val_mae: 0.0159\n",
      "Epoch [98/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0165, val_mae: 0.0159\n",
      "Epoch [99/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0158\n",
      "Epoch [100/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0165, val_mae: 0.0158\n",
      "Epoch [101/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0165, val_mae: 0.0157\n",
      "Epoch [102/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0157\n",
      "Epoch [103/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0156\n",
      "Epoch [104/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0156\n",
      "Epoch [105/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0155\n",
      "Epoch [106/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0163, val_mae: 0.0155\n",
      "Epoch [107/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0155\n",
      "Epoch [108/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0154\n",
      "Epoch [109/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0154\n",
      "Epoch [110/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0154\n",
      "Epoch [111/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0153\n",
      "Epoch [112/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0153\n",
      "Epoch [113/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0153\n",
      "Epoch [114/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0152\n",
      "Epoch [115/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0152\n",
      "Epoch [116/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0152\n",
      "Epoch [117/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0151\n",
      "Epoch [118/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0151\n",
      "Epoch [119/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0151\n",
      "Epoch [120/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0151\n",
      "Epoch [121/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0151\n",
      "Epoch [122/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0160, val_mae: 0.0150\n",
      "Epoch [123/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0150\n",
      "Epoch [124/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0150\n",
      "Epoch [125/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0150\n",
      "Epoch [126/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0150\n",
      "Epoch [127/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0149\n",
      "Epoch [128/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0149\n",
      "Epoch [129/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0158, val_mae: 0.0149\n",
      "Epoch [130/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0149\n",
      "Epoch [131/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0149\n",
      "Epoch [132/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0149\n",
      "Epoch [133/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0149\n",
      "Epoch [134/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0149\n",
      "Epoch [135/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0149\n",
      "Epoch [136/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0149\n",
      "Epoch [137/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0150\n",
      "Epoch [138/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0150\n",
      "Epoch [139/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0156, val_mae: 0.0151\n",
      "Epoch [140/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0151\n",
      "Epoch [141/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0152\n",
      "Epoch [142/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0152\n",
      "Epoch [143/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0153\n",
      "Epoch [144/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0152\n",
      "Epoch [145/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0152\n",
      "Epoch [146/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0152\n",
      "Epoch [147/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0151\n",
      "Epoch [148/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0150\n",
      "Epoch [149/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0149\n",
      "Epoch [150/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0149\n",
      "Epoch [151/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0148\n",
      "Epoch [152/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0147\n",
      "Epoch [153/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0147\n",
      "Epoch [154/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0153, val_mae: 0.0146\n",
      "Epoch [155/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0146\n",
      "Epoch [156/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0145\n",
      "Epoch [157/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0145\n",
      "Epoch [158/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0144\n",
      "Epoch [159/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0144\n",
      "Epoch [160/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0152, val_mae: 0.0143\n",
      "Epoch [161/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0152, val_mae: 0.0143\n",
      "Epoch [162/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0152, val_mae: 0.0143\n",
      "Epoch [163/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0143\n",
      "Epoch [164/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0152, val_mae: 0.0142\n",
      "Epoch [165/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0142\n",
      "Epoch [166/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0142\n",
      "Epoch [167/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0142\n",
      "Epoch [168/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0142\n",
      "Epoch [169/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0142\n",
      "Epoch [170/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [171/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0141\n",
      "Epoch [172/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [173/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [174/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [175/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [176/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [177/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0150, val_mae: 0.0141\n",
      "Epoch [178/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0140\n",
      "Epoch [179/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0140\n",
      "Epoch [180/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0140\n",
      "Epoch [181/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0140\n",
      "Epoch [182/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0140\n",
      "Epoch [183/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0140\n",
      "Epoch [184/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0140\n",
      "Epoch [185/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0140\n",
      "Epoch [186/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0139\n",
      "Epoch [187/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0139\n",
      "Epoch [188/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0139\n",
      "Epoch [189/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0139\n",
      "Epoch [190/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0139\n",
      "Epoch [191/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0139\n",
      "Epoch [192/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0139\n",
      "Epoch [193/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0138\n",
      "Epoch [194/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0138\n",
      "Epoch [195/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0148, val_mae: 0.0138\n",
      "Epoch [196/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0138\n",
      "Epoch [197/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0138\n",
      "Epoch [198/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0138\n",
      "Epoch [199/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0137\n",
      "Epoch [200/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0137\n",
      "Epoch [201/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0137\n",
      "Epoch [202/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0137\n",
      "Epoch [203/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0137\n",
      "Epoch [204/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0137\n",
      "Epoch [205/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0137\n",
      "Epoch [206/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0137\n",
      "Epoch [207/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0136\n",
      "Epoch [208/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0146, val_mae: 0.0136\n",
      "Epoch [209/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0136\n",
      "Epoch [210/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0136\n",
      "Epoch [211/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0136\n",
      "Epoch [212/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0135\n",
      "Epoch [213/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0135\n",
      "Epoch [214/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0135\n",
      "Epoch [215/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0135\n",
      "Epoch [216/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0135\n",
      "Epoch [217/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0135\n",
      "Epoch [218/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0135\n",
      "Epoch [219/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0135\n",
      "Epoch [220/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0134\n",
      "Epoch [221/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0144, val_mae: 0.0134\n",
      "Epoch [222/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0134\n",
      "Epoch [223/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0134\n",
      "Epoch [224/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0134\n",
      "Epoch [225/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0134\n",
      "Epoch [226/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0134\n",
      "Epoch [227/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0134\n",
      "Epoch [228/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0133\n",
      "Epoch [229/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0133\n",
      "Epoch [230/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0133\n",
      "Epoch [231/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0133\n",
      "Epoch [232/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0133\n",
      "Epoch [233/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0133\n",
      "Epoch [234/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0133\n",
      "Epoch [235/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0133\n",
      "Epoch [236/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0133\n",
      "Epoch [237/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0133\n",
      "Epoch [238/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0132\n",
      "Epoch [239/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0132\n",
      "Epoch [240/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0132\n",
      "Epoch [241/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0132\n",
      "Epoch [242/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0132\n",
      "Epoch [243/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0132\n",
      "Epoch [244/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0132\n",
      "Epoch [245/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0132\n",
      "Epoch [246/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0132\n",
      "Epoch [247/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0132\n",
      "Epoch [248/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0132\n",
      "Epoch [249/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0132\n",
      "Epoch [250/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0132\n",
      "Epoch [251/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0132\n",
      "Epoch [252/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0131\n",
      "Epoch [253/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0131\n",
      "Epoch [254/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0140, val_mae: 0.0131\n",
      "Epoch [255/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0131\n",
      "Epoch [256/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0131\n",
      "Epoch [257/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0131\n",
      "Epoch [258/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0131\n",
      "Epoch [259/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0131\n",
      "Epoch [260/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0131\n",
      "Epoch [261/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0130\n",
      "Epoch [262/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0139, val_mae: 0.0130\n",
      "Epoch [263/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0130\n",
      "Epoch [264/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0130\n",
      "Epoch [265/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0130\n",
      "Epoch [266/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0130\n",
      "Epoch [267/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0129\n",
      "Epoch [268/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0129\n",
      "Epoch [269/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0129\n",
      "Epoch [270/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0129\n",
      "Epoch [271/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0129\n",
      "Epoch [272/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0129\n",
      "Epoch [273/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0129\n",
      "Epoch [274/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0129\n",
      "Epoch [275/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0129\n",
      "Epoch [276/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0128\n",
      "Epoch [277/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0128\n",
      "Epoch [278/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0128\n",
      "Epoch [279/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0128\n",
      "Epoch [280/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0128\n",
      "Epoch [281/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0128\n",
      "Epoch [282/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0128\n",
      "Epoch [283/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0128\n",
      "Epoch [284/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0128\n",
      "Epoch [285/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0127\n",
      "Epoch [286/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0127\n",
      "Epoch [287/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0127\n",
      "Epoch [288/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0127\n",
      "Epoch [289/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0127\n",
      "Epoch [290/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0127\n",
      "Epoch [291/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0127\n",
      "Epoch [292/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0127\n",
      "Epoch [293/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0127\n",
      "Epoch [294/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0127\n",
      "Epoch [295/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0127\n",
      "Epoch [296/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [297/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [298/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [299/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0126\n",
      "Epoch [300/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [301/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [302/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0126\n",
      "Epoch [303/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [304/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [305/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0135, val_mae: 0.0126\n",
      "Epoch [306/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [307/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [308/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [309/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [310/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [311/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0125\n",
      "Epoch [312/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [313/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [314/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [315/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0125\n",
      "Epoch [316/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0125\n",
      "Epoch [317/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0125\n",
      "Epoch [318/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [319/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0124\n",
      "Epoch [320/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [321/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [322/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [323/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [324/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [325/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [326/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [327/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [328/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [329/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [330/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [331/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0133, val_mae: 0.0124\n",
      "Epoch [332/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [333/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [334/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [335/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [336/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [337/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0124\n",
      "Epoch [338/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0124\n",
      "Epoch [339/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0123\n",
      "Epoch [340/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [341/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0123\n",
      "Epoch [342/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0123\n",
      "Epoch [343/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [344/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [345/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0123\n",
      "Epoch [346/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [347/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [348/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [349/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [350/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [351/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [352/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [353/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0123\n",
      "Epoch [354/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0123\n",
      "Epoch [355/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [356/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0132, val_mae: 0.0122\n",
      "Epoch [357/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0122\n",
      "Epoch [358/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [359/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [360/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0122\n",
      "Epoch [361/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [362/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [363/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [364/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [365/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0122\n",
      "Epoch [366/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0122\n",
      "Epoch [367/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [368/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0122\n",
      "Epoch [369/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [370/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0122\n",
      "Epoch [371/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0121\n",
      "Epoch [372/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0121\n",
      "Epoch [373/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0121\n",
      "Epoch [374/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0121\n",
      "Epoch [375/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [376/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [377/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0121\n",
      "Epoch [378/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [379/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0121\n",
      "Epoch [380/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [381/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0121\n",
      "Epoch [382/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [383/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0121\n",
      "Epoch [384/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [385/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0121\n",
      "Epoch [386/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0120\n",
      "Epoch [387/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0120\n",
      "Epoch [388/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0120\n",
      "Epoch [389/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0120\n",
      "Epoch [390/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0129, val_mae: 0.0120\n",
      "Epoch [391/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0120\n",
      "Epoch [392/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0120\n",
      "Epoch [393/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0129, val_mae: 0.0120\n",
      "Epoch [394/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0120\n",
      "Epoch [395/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0120\n",
      "Epoch [396/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0129, val_mae: 0.0120\n",
      "Epoch [397/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0120\n",
      "Epoch [398/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0120\n",
      "Epoch [399/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0129, val_mae: 0.0119\n",
      "Epoch [400/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [401/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0119\n",
      "Epoch [402/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0119\n",
      "Epoch [403/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0119\n",
      "Epoch [404/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [405/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0119\n",
      "Epoch [406/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [407/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0119\n",
      "Epoch [408/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [409/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [410/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [411/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0128, val_mae: 0.0119\n",
      "Epoch [412/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0119\n",
      "Epoch [413/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [414/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0119\n",
      "Epoch [415/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0118\n",
      "Epoch [416/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0118\n",
      "Epoch [417/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [418/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [419/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0118\n",
      "Epoch [420/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [421/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0118\n",
      "Epoch [422/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [423/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [424/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0127, val_mae: 0.0118\n",
      "Epoch [425/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [426/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [427/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [428/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [429/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0118\n",
      "Epoch [430/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0118\n",
      "Epoch [431/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0117\n",
      "Epoch [432/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0117\n",
      "Epoch [433/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [434/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [435/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [436/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0117\n",
      "Epoch [437/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [438/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0126, val_mae: 0.0117\n",
      "Epoch [439/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [440/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [441/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [442/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [443/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [444/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [445/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [446/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [447/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [448/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [449/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0117\n",
      "Epoch [450/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [451/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [452/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [453/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [454/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [455/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [456/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [457/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [458/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [459/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [460/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [461/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [462/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [463/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [464/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [465/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [466/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [467/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [468/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0117\n",
      "Epoch [469/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [470/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0117\n",
      "Epoch [471/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [472/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0117\n",
      "Epoch [473/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0117\n",
      "Epoch [474/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0116\n",
      "Epoch [475/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [476/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [477/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0116\n",
      "Epoch [478/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0116\n",
      "Epoch [479/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [480/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [481/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [482/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0116\n",
      "Epoch [483/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0116\n",
      "Epoch [484/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [485/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [486/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0116\n",
      "Epoch [487/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0116\n",
      "Epoch [488/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [489/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [490/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [491/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [492/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [493/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [494/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [495/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [496/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [497/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [498/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0115\n",
      "Epoch [499/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [500/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [501/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0115\n",
      "Epoch [502/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [503/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0114\n",
      "Epoch [504/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0114\n",
      "Epoch [505/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [506/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [507/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [508/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [509/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [510/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [511/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0114\n",
      "Epoch [512/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [513/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0114\n",
      "Epoch [514/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [515/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [516/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0114\n",
      "Epoch [517/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0114\n",
      "Epoch [518/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [519/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0114\n",
      "Epoch [520/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [521/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [522/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0114\n",
      "Epoch [523/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0114\n",
      "Epoch [524/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [525/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [526/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0113\n",
      "Epoch [527/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [528/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [529/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [530/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [531/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [532/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [533/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [534/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0113\n",
      "Epoch [535/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0113\n",
      "Epoch [536/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [537/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0113\n",
      "Epoch [538/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [539/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [540/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0113\n",
      "Epoch [541/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [542/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0112\n",
      "Epoch [543/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [544/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0112\n",
      "Epoch [545/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0112\n",
      "Epoch [546/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [547/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0112\n",
      "Epoch [548/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [549/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0112\n",
      "Epoch [550/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [551/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [552/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [553/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [554/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0112\n",
      "Epoch [555/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [556/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [557/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [558/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [559/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [560/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [561/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [562/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0112\n",
      "Epoch [563/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [564/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0112\n",
      "Epoch [565/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0112\n",
      "Epoch [566/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [567/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [568/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [569/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [570/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [571/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [572/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [573/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [574/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [575/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [576/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [577/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [578/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [579/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0111\n",
      "Epoch [580/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [581/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [582/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [583/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [584/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [585/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0111\n",
      "Epoch [586/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [587/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [588/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [589/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [590/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [591/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [592/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0111\n",
      "Epoch [593/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [594/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [595/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [596/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [597/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0110\n",
      "Epoch [598/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [599/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0110\n",
      "Epoch [600/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [601/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [602/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [603/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0110\n",
      "Epoch [604/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [605/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [606/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0110\n",
      "Epoch [607/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [608/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0110\n",
      "Epoch [609/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [610/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [611/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [612/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [613/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [614/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [615/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [616/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [617/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [618/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [619/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [620/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [621/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [622/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [623/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [624/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [625/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [626/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [627/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [628/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [629/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [630/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [631/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0109\n",
      "Epoch [632/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [633/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [634/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [635/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [636/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [637/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [638/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [639/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [640/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [641/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [642/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [643/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [644/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [645/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [646/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [647/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [648/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [649/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [650/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [651/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [652/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [653/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [654/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [655/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [656/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [657/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [658/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [659/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [660/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [661/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [662/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [663/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [664/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [665/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [666/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [667/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [668/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [669/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [670/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [671/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [672/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [673/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [674/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [675/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [676/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [677/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [678/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [679/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0108\n",
      "Epoch [680/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [681/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [682/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [683/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [684/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [685/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [686/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [687/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [688/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [689/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0108\n",
      "Epoch [690/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0109\n",
      "Epoch [691/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [692/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [693/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0117, val_mae: 0.0109\n",
      "Epoch [694/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0109\n",
      "Epoch [695/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [696/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [697/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [698/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [699/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0109\n",
      "Epoch [700/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [701/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [702/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [703/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0109\n",
      "Epoch [704/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [705/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0109\n",
      "Epoch [706/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [707/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0109\n",
      "Epoch [708/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [709/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0109\n",
      "Epoch [710/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0109\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n",
      "Epoch [1/1000] - train_loss: 0.0120, val_loss: 0.0048, train_mae: 0.0789, val_mae: 0.0544\n",
      "Epoch [2/1000] - train_loss: 0.0044, val_loss: 0.0034, train_mae: 0.0521, val_mae: 0.0461\n",
      "Epoch [3/1000] - train_loss: 0.0032, val_loss: 0.0027, train_mae: 0.0446, val_mae: 0.0408\n",
      "Epoch [4/1000] - train_loss: 0.0025, val_loss: 0.0021, train_mae: 0.0390, val_mae: 0.0364\n",
      "Epoch [5/1000] - train_loss: 0.0020, val_loss: 0.0017, train_mae: 0.0352, val_mae: 0.0326\n",
      "Epoch [6/1000] - train_loss: 0.0017, val_loss: 0.0014, train_mae: 0.0319, val_mae: 0.0297\n",
      "Epoch [7/1000] - train_loss: 0.0014, val_loss: 0.0013, train_mae: 0.0297, val_mae: 0.0279\n",
      "Epoch [8/1000] - train_loss: 0.0013, val_loss: 0.0012, train_mae: 0.0282, val_mae: 0.0264\n",
      "Epoch [9/1000] - train_loss: 0.0012, val_loss: 0.0011, train_mae: 0.0269, val_mae: 0.0253\n",
      "Epoch [10/1000] - train_loss: 0.0011, val_loss: 0.0010, train_mae: 0.0258, val_mae: 0.0243\n",
      "Epoch [11/1000] - train_loss: 0.0010, val_loss: 0.0009, train_mae: 0.0248, val_mae: 0.0235\n",
      "Epoch [12/1000] - train_loss: 0.0010, val_loss: 0.0009, train_mae: 0.0241, val_mae: 0.0228\n",
      "Epoch [13/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0235, val_mae: 0.0222\n",
      "Epoch [14/1000] - train_loss: 0.0009, val_loss: 0.0008, train_mae: 0.0230, val_mae: 0.0218\n",
      "Epoch [15/1000] - train_loss: 0.0008, val_loss: 0.0008, train_mae: 0.0223, val_mae: 0.0213\n",
      "Epoch [16/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0219, val_mae: 0.0209\n",
      "Epoch [17/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0215, val_mae: 0.0205\n",
      "Epoch [18/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0212, val_mae: 0.0201\n",
      "Epoch [19/1000] - train_loss: 0.0007, val_loss: 0.0007, train_mae: 0.0207, val_mae: 0.0198\n",
      "Epoch [20/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0203, val_mae: 0.0194\n",
      "Epoch [21/1000] - train_loss: 0.0007, val_loss: 0.0006, train_mae: 0.0200, val_mae: 0.0190\n",
      "Epoch [22/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0196, val_mae: 0.0188\n",
      "Epoch [23/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0192, val_mae: 0.0185\n",
      "Epoch [24/1000] - train_loss: 0.0006, val_loss: 0.0006, train_mae: 0.0189, val_mae: 0.0182\n",
      "Epoch [25/1000] - train_loss: 0.0006, val_loss: 0.0005, train_mae: 0.0187, val_mae: 0.0180\n",
      "Epoch [26/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0183, val_mae: 0.0177\n",
      "Epoch [27/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0180, val_mae: 0.0174\n",
      "Epoch [28/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0178, val_mae: 0.0172\n",
      "Epoch [29/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0176, val_mae: 0.0169\n",
      "Epoch [30/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0171, val_mae: 0.0167\n",
      "Epoch [31/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0169, val_mae: 0.0164\n",
      "Epoch [32/1000] - train_loss: 0.0005, val_loss: 0.0004, train_mae: 0.0167, val_mae: 0.0162\n",
      "Epoch [33/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0164, val_mae: 0.0159\n",
      "Epoch [34/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0162, val_mae: 0.0157\n",
      "Epoch [35/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0161, val_mae: 0.0155\n",
      "Epoch [36/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0159, val_mae: 0.0153\n",
      "Epoch [37/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0157, val_mae: 0.0151\n",
      "Epoch [38/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0155, val_mae: 0.0149\n",
      "Epoch [39/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0154, val_mae: 0.0147\n",
      "Epoch [40/1000] - train_loss: 0.0004, val_loss: 0.0004, train_mae: 0.0151, val_mae: 0.0145\n",
      "Epoch [41/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0151, val_mae: 0.0143\n",
      "Epoch [42/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0142\n",
      "Epoch [43/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0149, val_mae: 0.0140\n",
      "Epoch [44/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0147, val_mae: 0.0139\n",
      "Epoch [45/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0138\n",
      "Epoch [46/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0137\n",
      "Epoch [47/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0143, val_mae: 0.0136\n",
      "Epoch [48/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0142, val_mae: 0.0135\n",
      "Epoch [49/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0141, val_mae: 0.0134\n",
      "Epoch [50/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0133\n",
      "Epoch [51/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0138, val_mae: 0.0132\n",
      "Epoch [52/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0137, val_mae: 0.0132\n",
      "Epoch [53/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0136, val_mae: 0.0131\n",
      "Epoch [54/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0130\n",
      "Epoch [55/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [56/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0134, val_mae: 0.0129\n",
      "Epoch [57/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0128\n",
      "Epoch [58/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0131, val_mae: 0.0127\n",
      "Epoch [59/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0127\n",
      "Epoch [60/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0130, val_mae: 0.0126\n",
      "Epoch [61/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0126\n",
      "Epoch [62/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0128, val_mae: 0.0125\n",
      "Epoch [63/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0124\n",
      "Epoch [64/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0123\n",
      "Epoch [65/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0126, val_mae: 0.0122\n",
      "Epoch [66/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [67/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0125, val_mae: 0.0121\n",
      "Epoch [68/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0124, val_mae: 0.0120\n",
      "Epoch [69/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0123, val_mae: 0.0119\n",
      "Epoch [70/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0119\n",
      "Epoch [71/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0122, val_mae: 0.0118\n",
      "Epoch [72/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0118\n",
      "Epoch [73/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0117\n",
      "Epoch [74/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0120, val_mae: 0.0116\n",
      "Epoch [75/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0116\n",
      "Epoch [76/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0115\n",
      "Epoch [77/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0119, val_mae: 0.0115\n",
      "Epoch [78/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0114\n",
      "Epoch [79/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0113\n",
      "Epoch [80/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0118, val_mae: 0.0113\n",
      "Epoch [81/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0112\n",
      "Epoch [82/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0112\n",
      "Epoch [83/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0111\n",
      "Epoch [84/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0115, val_mae: 0.0111\n",
      "Epoch [85/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0116, val_mae: 0.0111\n",
      "Epoch [86/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0110\n",
      "Epoch [87/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0110\n",
      "Epoch [88/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0114, val_mae: 0.0109\n",
      "Epoch [89/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0109\n",
      "Epoch [90/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0109\n",
      "Epoch [91/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0108\n",
      "Epoch [92/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0113, val_mae: 0.0108\n",
      "Epoch [93/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0112, val_mae: 0.0107\n",
      "Epoch [94/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0107\n",
      "Epoch [95/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0107\n",
      "Epoch [96/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0107\n",
      "Epoch [97/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0107\n",
      "Epoch [98/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0111, val_mae: 0.0106\n",
      "Epoch [99/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0109, val_mae: 0.0106\n",
      "Epoch [100/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0106\n",
      "Epoch [101/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0106\n",
      "Epoch [102/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0108, val_mae: 0.0106\n",
      "Epoch [103/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0106\n",
      "Epoch [104/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0108, val_mae: 0.0106\n",
      "Epoch [105/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0108, val_mae: 0.0106\n",
      "Epoch [106/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0108, val_mae: 0.0106\n",
      "Epoch [107/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0107, val_mae: 0.0106\n",
      "Epoch [108/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0107, val_mae: 0.0107\n",
      "Epoch [109/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0106, val_mae: 0.0107\n",
      "Epoch [110/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0107, val_mae: 0.0106\n",
      "Epoch [111/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0106\n",
      "Epoch [112/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0106\n",
      "Epoch [113/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0106, val_mae: 0.0106\n",
      "Epoch [114/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0106\n",
      "Epoch [115/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0106, val_mae: 0.0105\n",
      "Epoch [116/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0105\n",
      "Epoch [117/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0105\n",
      "Epoch [118/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0104\n",
      "Epoch [119/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0104\n",
      "Epoch [120/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0104, val_mae: 0.0103\n",
      "Epoch [121/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0105, val_mae: 0.0103\n",
      "Epoch [122/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0103, val_mae: 0.0103\n",
      "Epoch [123/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0103, val_mae: 0.0102\n",
      "Epoch [124/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0104, val_mae: 0.0102\n",
      "Epoch [125/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0103, val_mae: 0.0102\n",
      "Epoch [126/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0102, val_mae: 0.0101\n",
      "Epoch [127/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0103, val_mae: 0.0101\n",
      "Epoch [128/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0103, val_mae: 0.0101\n",
      "Epoch [129/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0102, val_mae: 0.0100\n",
      "Epoch [130/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0100\n",
      "Epoch [131/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0103, val_mae: 0.0100\n",
      "Epoch [132/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0100, val_mae: 0.0100\n",
      "Epoch [133/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0102, val_mae: 0.0100\n",
      "Epoch [134/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0100\n",
      "Epoch [135/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0100\n",
      "Epoch [136/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0100\n",
      "Epoch [137/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0100\n",
      "Epoch [138/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0100\n",
      "Epoch [139/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0101, val_mae: 0.0100\n",
      "Epoch [140/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0100, val_mae: 0.0100\n",
      "Epoch [141/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0100\n",
      "Epoch [142/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0101\n",
      "Epoch [143/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0101\n",
      "Epoch [144/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0102\n",
      "Epoch [145/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0102\n",
      "Epoch [146/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0098, val_mae: 0.0103\n",
      "Epoch [147/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0103\n",
      "Epoch [148/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0098, val_mae: 0.0104\n",
      "Epoch [149/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0099, val_mae: 0.0105\n",
      "Epoch [150/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0105\n",
      "Epoch [151/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0105\n",
      "Epoch [152/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0098, val_mae: 0.0105\n",
      "Epoch [153/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0105\n",
      "Epoch [154/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0104\n",
      "Epoch [155/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0103\n",
      "Epoch [156/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0097, val_mae: 0.0103\n",
      "Epoch [157/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0096, val_mae: 0.0102\n",
      "Epoch [158/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0096, val_mae: 0.0101\n",
      "Epoch [159/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0096, val_mae: 0.0100\n",
      "Epoch [160/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0096, val_mae: 0.0099\n",
      "Epoch [161/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0096, val_mae: 0.0099\n",
      "Epoch [162/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0096, val_mae: 0.0098\n",
      "Epoch [163/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0098\n",
      "Epoch [164/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0097\n",
      "Epoch [165/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0097\n",
      "Epoch [166/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0096, val_mae: 0.0096\n",
      "Epoch [167/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0096\n",
      "Epoch [168/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0096\n",
      "Epoch [169/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0095, val_mae: 0.0095\n",
      "Epoch [170/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0095\n",
      "Epoch [171/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0095\n",
      "Epoch [172/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0095\n",
      "Epoch [173/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0093, val_mae: 0.0094\n",
      "Epoch [174/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0094\n",
      "Epoch [175/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0094, val_mae: 0.0094\n",
      "Epoch [176/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0094, val_mae: 0.0094\n",
      "Epoch [177/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0094, val_mae: 0.0094\n",
      "Epoch [178/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0094, val_mae: 0.0093\n",
      "Epoch [179/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0093\n",
      "Epoch [180/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0093\n",
      "Epoch [181/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0093\n",
      "Epoch [182/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0093\n",
      "Epoch [183/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0093\n",
      "Epoch [184/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0093\n",
      "Epoch [185/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0092\n",
      "Epoch [186/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0092\n",
      "Epoch [187/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0092\n",
      "Epoch [188/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0092\n",
      "Epoch [189/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0092, val_mae: 0.0092\n",
      "Epoch [190/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0092\n",
      "Epoch [191/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0092\n",
      "Epoch [192/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0092\n",
      "Epoch [193/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0091\n",
      "Epoch [194/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0091\n",
      "Epoch [195/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0091, val_mae: 0.0091\n",
      "Epoch [196/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [197/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [198/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [199/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [200/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [201/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [202/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [203/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [204/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [205/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0090, val_mae: 0.0091\n",
      "Epoch [206/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0091\n",
      "Epoch [207/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [208/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [209/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [210/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [211/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0091\n",
      "Epoch [212/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0091\n",
      "Epoch [213/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0091\n",
      "Epoch [214/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0091\n",
      "Epoch [215/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0091\n",
      "Epoch [216/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0092\n",
      "Epoch [217/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0089, val_mae: 0.0092\n",
      "Epoch [218/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0092\n",
      "Epoch [219/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0093\n",
      "Epoch [220/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0088, val_mae: 0.0093\n",
      "Epoch [221/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0093\n",
      "Epoch [222/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0087, val_mae: 0.0094\n",
      "Epoch [223/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0087, val_mae: 0.0095\n",
      "Epoch [224/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0087, val_mae: 0.0095\n",
      "Epoch [225/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0096\n",
      "Epoch [226/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0087, val_mae: 0.0097\n",
      "Epoch [227/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0087, val_mae: 0.0099\n",
      "Epoch [228/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0100\n",
      "Epoch [229/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0102\n",
      "Epoch [230/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0087, val_mae: 0.0104\n",
      "Epoch [231/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0106\n",
      "Epoch [232/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0107\n",
      "Epoch [233/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0109\n",
      "Epoch [234/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0111\n",
      "Epoch [235/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0112\n",
      "Epoch [236/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0114\n",
      "Epoch [237/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0114\n",
      "Epoch [238/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0115\n",
      "Epoch [239/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0115\n",
      "Epoch [240/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0115\n",
      "Epoch [241/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0086, val_mae: 0.0115\n",
      "Epoch [242/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0115\n",
      "Epoch [243/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0114\n",
      "Epoch [244/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0114\n",
      "Epoch [245/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0113\n",
      "Epoch [246/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0085, val_mae: 0.0112\n",
      "Epoch [247/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0111\n",
      "Epoch [248/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0110\n",
      "Epoch [249/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0110\n",
      "Epoch [250/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0109\n",
      "Epoch [251/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0108\n",
      "Epoch [252/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0107\n",
      "Epoch [253/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0106\n",
      "Epoch [254/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0105\n",
      "Epoch [255/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0104\n",
      "Epoch [256/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0084, val_mae: 0.0103\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n",
      "Epoch [1/1000] - train_loss: 0.0054, val_loss: 0.0010, train_mae: 0.0477, val_mae: 0.0247\n",
      "Epoch [2/1000] - train_loss: 0.0009, val_loss: 0.0005, train_mae: 0.0229, val_mae: 0.0163\n",
      "Epoch [3/1000] - train_loss: 0.0005, val_loss: 0.0003, train_mae: 0.0178, val_mae: 0.0122\n",
      "Epoch [4/1000] - train_loss: 0.0004, val_loss: 0.0002, train_mae: 0.0150, val_mae: 0.0099\n",
      "Epoch [5/1000] - train_loss: 0.0003, val_loss: 0.0001, train_mae: 0.0132, val_mae: 0.0087\n",
      "Epoch [6/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0118, val_mae: 0.0080\n",
      "Epoch [7/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0113, val_mae: 0.0075\n",
      "Epoch [8/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0107, val_mae: 0.0070\n",
      "Epoch [9/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0099, val_mae: 0.0066\n",
      "Epoch [10/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0094, val_mae: 0.0063\n",
      "Epoch [11/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0061\n",
      "Epoch [12/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0060\n",
      "Epoch [13/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0083, val_mae: 0.0059\n",
      "Epoch [14/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0080, val_mae: 0.0058\n",
      "Epoch [15/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0057\n",
      "Epoch [16/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0055\n",
      "Epoch [17/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0054\n",
      "Epoch [18/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0072, val_mae: 0.0054\n",
      "Epoch [19/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0070, val_mae: 0.0054\n",
      "Epoch [20/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0070, val_mae: 0.0054\n",
      "Epoch [21/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0068, val_mae: 0.0054\n",
      "Epoch [22/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0065, val_mae: 0.0054\n",
      "Epoch [23/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0062, val_mae: 0.0054\n",
      "Epoch [24/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0061, val_mae: 0.0052\n",
      "Epoch [25/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0064, val_mae: 0.0050\n",
      "Epoch [26/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0062, val_mae: 0.0049\n",
      "Epoch [27/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0060, val_mae: 0.0048\n",
      "Epoch [28/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0060, val_mae: 0.0048\n",
      "Epoch [29/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0058, val_mae: 0.0048\n",
      "Epoch [30/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0053, val_mae: 0.0049\n",
      "Epoch [31/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0057, val_mae: 0.0048\n",
      "Epoch [32/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0054, val_mae: 0.0048\n",
      "Epoch [33/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0055, val_mae: 0.0048\n",
      "Epoch [34/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0049\n",
      "Epoch [35/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0054, val_mae: 0.0050\n",
      "Epoch [36/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0052, val_mae: 0.0052\n",
      "Epoch [37/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0052, val_mae: 0.0054\n",
      "Epoch [38/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0053, val_mae: 0.0055\n",
      "Epoch [39/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0053, val_mae: 0.0055\n",
      "Epoch [40/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0050, val_mae: 0.0054\n",
      "Epoch [41/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0053\n",
      "Epoch [42/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0052, val_mae: 0.0051\n",
      "Epoch [43/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0050\n",
      "Epoch [44/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0049\n",
      "Epoch [45/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0048\n",
      "Epoch [46/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0048\n",
      "Epoch [47/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0047, val_mae: 0.0048\n",
      "Epoch [48/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0048\n",
      "Epoch [49/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0047, val_mae: 0.0049\n",
      "Epoch [50/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0049\n",
      "Epoch [51/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0047, val_mae: 0.0049\n",
      "Epoch [52/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0049\n",
      "Epoch [53/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0049\n",
      "Epoch [54/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0050\n",
      "Epoch [55/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0050\n",
      "Epoch [56/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0051\n",
      "Epoch [57/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0052\n",
      "Epoch [58/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0052\n",
      "Epoch [59/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0052\n",
      "Epoch [60/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0052\n",
      "Epoch [61/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0052\n",
      "Epoch [62/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0051\n",
      "Epoch [63/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0050\n",
      "Epoch [64/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0049\n",
      "Epoch [65/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0048\n",
      "Epoch [66/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0047\n",
      "Epoch [67/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0045\n",
      "Epoch [68/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0044\n",
      "Epoch [69/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0043\n",
      "Epoch [70/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0043\n",
      "Epoch [71/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0042\n",
      "Epoch [72/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0042\n",
      "Epoch [73/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0042\n",
      "Epoch [74/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0042\n",
      "Epoch [75/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0042\n",
      "Epoch [76/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0042\n",
      "Epoch [77/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0042\n",
      "Epoch [78/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0042\n",
      "Epoch [79/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0043\n",
      "Epoch [80/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0044\n",
      "Epoch [81/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0045\n",
      "Epoch [82/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0047\n",
      "Epoch [83/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0049\n",
      "Epoch [84/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0051\n",
      "Epoch [85/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0053\n",
      "Epoch [86/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0054\n",
      "Epoch [87/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0036, val_mae: 0.0055\n",
      "Epoch [88/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0056\n",
      "Epoch [89/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0057\n",
      "Epoch [90/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0037, val_mae: 0.0056\n",
      "Epoch [91/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0055\n",
      "Epoch [92/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0054\n",
      "Epoch [93/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0052\n",
      "Epoch [94/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0051\n",
      "Epoch [95/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0050\n",
      "Epoch [96/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0049\n",
      "Epoch [97/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0048\n",
      "Epoch [98/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0047\n",
      "Epoch [99/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0046\n",
      "Epoch [100/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0045\n",
      "Epoch [101/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0044\n",
      "Epoch [102/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0044\n",
      "Epoch [103/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0044\n",
      "Epoch [104/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0044\n",
      "Epoch [105/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0044\n",
      "Epoch [106/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0043\n",
      "Epoch [107/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0043\n",
      "Epoch [108/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0042\n",
      "Epoch [109/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0041\n",
      "Epoch [110/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0041\n",
      "Epoch [111/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0040\n",
      "Epoch [112/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0039\n",
      "Epoch [113/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0039\n",
      "Epoch [114/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0038\n",
      "Epoch [115/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0038\n",
      "Epoch [116/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0038\n",
      "Epoch [117/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0038\n",
      "Epoch [118/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0037\n",
      "Epoch [119/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0037\n",
      "Epoch [120/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0037\n",
      "Epoch [121/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0037\n",
      "Epoch [122/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0038\n",
      "Epoch [123/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0038\n",
      "Epoch [124/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0038\n",
      "Epoch [125/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0038\n",
      "Epoch [126/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0038\n",
      "Epoch [127/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0039\n",
      "Epoch [128/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0039\n",
      "Epoch [129/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0039\n",
      "Epoch [130/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0040\n",
      "Epoch [131/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0040\n",
      "Epoch [132/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0040\n",
      "Epoch [133/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0040\n",
      "Epoch [134/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0040\n",
      "Epoch [135/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0040\n",
      "Epoch [136/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0040\n",
      "Epoch [137/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0040\n",
      "Epoch [138/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0040\n",
      "Epoch [139/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0040\n",
      "Epoch [140/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0039\n",
      "Epoch [141/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0039\n",
      "Epoch [142/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0038\n",
      "Epoch [143/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0038\n",
      "Epoch [144/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0037\n",
      "Epoch [145/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0037\n",
      "Epoch [146/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0037\n",
      "Epoch [147/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0036\n",
      "Epoch [148/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0036\n",
      "Epoch [149/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0036\n",
      "Epoch [150/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0036\n",
      "Epoch [151/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0035\n",
      "Epoch [152/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0035\n",
      "Epoch [153/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [154/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0035\n",
      "Epoch [155/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [156/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [157/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [158/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [159/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [160/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0035\n",
      "Epoch [161/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0035\n",
      "Epoch [162/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [163/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [164/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0036\n",
      "Epoch [165/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0036\n",
      "Epoch [166/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0036\n",
      "Epoch [167/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0036\n",
      "Epoch [168/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0036\n",
      "Epoch [169/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0037\n",
      "Epoch [170/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0037\n",
      "Epoch [171/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0038\n",
      "Epoch [172/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0038\n",
      "Epoch [173/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0038\n",
      "Epoch [174/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0039\n",
      "Epoch [175/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0039\n",
      "Epoch [176/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0040\n",
      "Epoch [177/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0040\n",
      "Epoch [178/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0041\n",
      "Epoch [179/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0041\n",
      "Epoch [180/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0042\n",
      "Epoch [181/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0043\n",
      "Epoch [182/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0044\n",
      "Epoch [183/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0045\n",
      "Epoch [184/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0046\n",
      "Epoch [185/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0047\n",
      "Epoch [186/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0048\n",
      "Epoch [187/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0049\n",
      "Epoch [188/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0050\n",
      "Epoch [189/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0052\n",
      "Epoch [190/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0053\n",
      "Epoch [191/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0054\n",
      "Epoch [192/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0027, val_mae: 0.0055\n",
      "Epoch [193/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0029, val_mae: 0.0056\n",
      "Epoch [194/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0029, val_mae: 0.0057\n",
      "Epoch [195/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0027, val_mae: 0.0058\n",
      "Epoch [196/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0028, val_mae: 0.0058\n",
      "Epoch [197/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0027, val_mae: 0.0058\n",
      "Epoch [198/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0028, val_mae: 0.0059\n",
      "Epoch [199/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0027, val_mae: 0.0059\n",
      "Epoch [200/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0027, val_mae: 0.0060\n",
      "Epoch [201/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0027, val_mae: 0.0060\n",
      "Epoch [202/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0028, val_mae: 0.0061\n",
      "Epoch [203/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0027, val_mae: 0.0061\n",
      "Epoch [204/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0028, val_mae: 0.0062\n",
      "Epoch [205/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0026, val_mae: 0.0062\n",
      "Epoch [206/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0026, val_mae: 0.0062\n",
      "Epoch [207/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0028, val_mae: 0.0063\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "nets = [net_large, net1x30sf, net2x30sf, net3x30sf, net6x50sf, net_largesf]\n",
    "\n",
    "train_losses_list = []\n",
    "val_losses_list = []\n",
    "train_maes_list = []\n",
    "val_maes_list = []\n",
    "best_states_list = []\n",
    "\n",
    "for i, net in enumerate(nets):\n",
    "    if i == 1:\n",
    "        opt = 'adam'\n",
    "    else:\n",
    "        opt = 'schedulefree'\n",
    "\n",
    "    train_losses, val_losses, train_maes, val_maes, best_state = train_loop(net, train_dataloader, val_dataloader, patience=50, num_epochs=1000, opt=opt)\n",
    "    train_losses_list.append(train_losses)\n",
    "    val_losses_list.append(val_losses)\n",
    "    train_maes_list.append(train_maes)\n",
    "    val_maes_list.append(val_maes)\n",
    "    best_states_list.append(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_largesf2 = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 1000), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(1000, 500), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(500, 250), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(250, 125), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(125, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - train_loss: 0.0060, val_loss: 0.0015, train_mae: 0.0519, val_mae: 0.0308\n",
      "Epoch [2/1000] - train_loss: 0.0012, val_loss: 0.0013, train_mae: 0.0269, val_mae: 0.0285\n",
      "Epoch [3/1000] - train_loss: 0.0008, val_loss: 0.0007, train_mae: 0.0216, val_mae: 0.0211\n",
      "Epoch [4/1000] - train_loss: 0.0006, val_loss: 0.0004, train_mae: 0.0188, val_mae: 0.0162\n",
      "Epoch [5/1000] - train_loss: 0.0005, val_loss: 0.0005, train_mae: 0.0168, val_mae: 0.0170\n",
      "Epoch [6/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0160, val_mae: 0.0130\n",
      "Epoch [7/1000] - train_loss: 0.0004, val_loss: 0.0003, train_mae: 0.0145, val_mae: 0.0123\n",
      "Epoch [8/1000] - train_loss: 0.0003, val_loss: 0.0005, train_mae: 0.0138, val_mae: 0.0183\n",
      "Epoch [9/1000] - train_loss: 0.0003, val_loss: 0.0002, train_mae: 0.0134, val_mae: 0.0106\n",
      "Epoch [10/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0121, val_mae: 0.0116\n",
      "Epoch [11/1000] - train_loss: 0.0003, val_loss: 0.0003, train_mae: 0.0125, val_mae: 0.0139\n",
      "Epoch [12/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0112, val_mae: 0.0156\n",
      "Epoch [13/1000] - train_loss: 0.0002, val_loss: 0.0005, train_mae: 0.0111, val_mae: 0.0170\n",
      "Epoch [14/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0108, val_mae: 0.0119\n",
      "Epoch [15/1000] - train_loss: 0.0002, val_loss: 0.0002, train_mae: 0.0110, val_mae: 0.0101\n",
      "Epoch [16/1000] - train_loss: 0.0002, val_loss: 0.0005, train_mae: 0.0100, val_mae: 0.0174\n",
      "Epoch [17/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0098, val_mae: 0.0153\n",
      "Epoch [18/1000] - train_loss: 0.0002, val_loss: 0.0004, train_mae: 0.0100, val_mae: 0.0161\n",
      "Epoch [19/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0093, val_mae: 0.0089\n",
      "Epoch [20/1000] - train_loss: 0.0002, val_loss: 0.0001, train_mae: 0.0097, val_mae: 0.0084\n",
      "Epoch [21/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0091, val_mae: 0.0097\n",
      "Epoch [22/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0091, val_mae: 0.0125\n",
      "Epoch [23/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0076\n",
      "Epoch [24/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0087, val_mae: 0.0074\n",
      "Epoch [25/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0088, val_mae: 0.0097\n",
      "Epoch [26/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0082, val_mae: 0.0116\n",
      "Epoch [27/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0084, val_mae: 0.0091\n",
      "Epoch [28/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0081, val_mae: 0.0097\n",
      "Epoch [29/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0078, val_mae: 0.0097\n",
      "Epoch [30/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0087\n",
      "Epoch [31/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0079, val_mae: 0.0076\n",
      "Epoch [32/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0078, val_mae: 0.0115\n",
      "Epoch [33/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0079, val_mae: 0.0106\n",
      "Epoch [34/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0075, val_mae: 0.0079\n",
      "Epoch [35/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0078, val_mae: 0.0089\n",
      "Epoch [36/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0086\n",
      "Epoch [37/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0063\n",
      "Epoch [38/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0074, val_mae: 0.0065\n",
      "Epoch [39/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0076\n",
      "Epoch [40/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0073, val_mae: 0.0081\n",
      "Epoch [41/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0071, val_mae: 0.0080\n",
      "Epoch [42/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0069, val_mae: 0.0070\n",
      "Epoch [43/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0082\n",
      "Epoch [44/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0072, val_mae: 0.0087\n",
      "Epoch [45/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0061\n",
      "Epoch [46/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0076\n",
      "Epoch [47/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0068, val_mae: 0.0072\n",
      "Epoch [48/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0070\n",
      "Epoch [49/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0062, val_mae: 0.0067\n",
      "Epoch [50/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0066, val_mae: 0.0058\n",
      "Epoch [51/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0063, val_mae: 0.0057\n",
      "Epoch [52/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0067, val_mae: 0.0083\n",
      "Epoch [53/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0060, val_mae: 0.0052\n",
      "Epoch [54/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0060\n",
      "Epoch [55/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0071\n",
      "Epoch [56/1000] - train_loss: 0.0001, val_loss: 0.0002, train_mae: 0.0061, val_mae: 0.0099\n",
      "Epoch [57/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0066\n",
      "Epoch [58/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0056\n",
      "Epoch [59/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0065, val_mae: 0.0064\n",
      "Epoch [60/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0058, val_mae: 0.0050\n",
      "Epoch [61/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0060, val_mae: 0.0071\n",
      "Epoch [62/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0074\n",
      "Epoch [63/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0072\n",
      "Epoch [64/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0061, val_mae: 0.0063\n",
      "Epoch [65/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0060\n",
      "Epoch [66/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0059, val_mae: 0.0050\n",
      "Epoch [67/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0059, val_mae: 0.0081\n",
      "Epoch [68/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0056\n",
      "Epoch [69/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0082\n",
      "Epoch [70/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0069\n",
      "Epoch [71/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0053\n",
      "Epoch [72/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0058, val_mae: 0.0080\n",
      "Epoch [73/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0078\n",
      "Epoch [74/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0056, val_mae: 0.0048\n",
      "Epoch [75/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0096\n",
      "Epoch [76/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0056, val_mae: 0.0059\n",
      "Epoch [77/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0065\n",
      "Epoch [78/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0057, val_mae: 0.0057\n",
      "Epoch [79/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0052, val_mae: 0.0046\n",
      "Epoch [80/1000] - train_loss: 0.0001, val_loss: 0.0000, train_mae: 0.0054, val_mae: 0.0053\n",
      "Epoch [81/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0052, val_mae: 0.0047\n",
      "Epoch [82/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0052, val_mae: 0.0051\n",
      "Epoch [83/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0054, val_mae: 0.0055\n",
      "Epoch [84/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0054, val_mae: 0.0053\n",
      "Epoch [85/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0052, val_mae: 0.0050\n",
      "Epoch [86/1000] - train_loss: 0.0001, val_loss: 0.0001, train_mae: 0.0055, val_mae: 0.0060\n",
      "Epoch [87/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0050, val_mae: 0.0054\n",
      "Epoch [88/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0053, val_mae: 0.0045\n",
      "Epoch [89/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0051, val_mae: 0.0054\n",
      "Epoch [90/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0051, val_mae: 0.0064\n",
      "Epoch [91/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0052, val_mae: 0.0057\n",
      "Epoch [92/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0051, val_mae: 0.0046\n",
      "Epoch [93/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0052, val_mae: 0.0063\n",
      "Epoch [94/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0050, val_mae: 0.0045\n",
      "Epoch [95/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0051, val_mae: 0.0048\n",
      "Epoch [96/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0049, val_mae: 0.0053\n",
      "Epoch [97/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0052, val_mae: 0.0062\n",
      "Epoch [98/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0051\n",
      "Epoch [99/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0053, val_mae: 0.0046\n",
      "Epoch [100/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0045\n",
      "Epoch [101/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0049, val_mae: 0.0058\n",
      "Epoch [102/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0047, val_mae: 0.0063\n",
      "Epoch [103/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0049, val_mae: 0.0076\n",
      "Epoch [104/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0048, val_mae: 0.0057\n",
      "Epoch [105/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0049, val_mae: 0.0057\n",
      "Epoch [106/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0053\n",
      "Epoch [107/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0050, val_mae: 0.0054\n",
      "Epoch [108/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0045, val_mae: 0.0062\n",
      "Epoch [109/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0050, val_mae: 0.0061\n",
      "Epoch [110/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0047\n",
      "Epoch [111/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0045\n",
      "Epoch [112/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0049, val_mae: 0.0094\n",
      "Epoch [113/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0046, val_mae: 0.0090\n",
      "Epoch [114/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0047\n",
      "Epoch [115/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0046, val_mae: 0.0071\n",
      "Epoch [116/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0048, val_mae: 0.0074\n",
      "Epoch [117/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0055\n",
      "Epoch [118/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0045\n",
      "Epoch [119/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0047, val_mae: 0.0043\n",
      "Epoch [120/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0046, val_mae: 0.0060\n",
      "Epoch [121/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0042\n",
      "Epoch [122/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0045\n",
      "Epoch [123/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0046\n",
      "Epoch [124/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0046, val_mae: 0.0056\n",
      "Epoch [125/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0045, val_mae: 0.0071\n",
      "Epoch [126/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0046\n",
      "Epoch [127/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0044, val_mae: 0.0081\n",
      "Epoch [128/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0047, val_mae: 0.0042\n",
      "Epoch [129/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0043, val_mae: 0.0061\n",
      "Epoch [130/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0047, val_mae: 0.0067\n",
      "Epoch [131/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0044, val_mae: 0.0058\n",
      "Epoch [132/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0044, val_mae: 0.0058\n",
      "Epoch [133/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0048, val_mae: 0.0043\n",
      "Epoch [134/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0045, val_mae: 0.0057\n",
      "Epoch [135/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0043\n",
      "Epoch [136/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0038\n",
      "Epoch [137/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0045\n",
      "Epoch [138/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0041\n",
      "Epoch [139/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0053\n",
      "Epoch [140/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0046\n",
      "Epoch [141/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0045, val_mae: 0.0067\n",
      "Epoch [142/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0037\n",
      "Epoch [143/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0045, val_mae: 0.0057\n",
      "Epoch [144/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0043, val_mae: 0.0059\n",
      "Epoch [145/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0048\n",
      "Epoch [146/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0044, val_mae: 0.0078\n",
      "Epoch [147/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0044, val_mae: 0.0040\n",
      "Epoch [148/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0053\n",
      "Epoch [149/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0045, val_mae: 0.0041\n",
      "Epoch [150/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0042, val_mae: 0.0096\n",
      "Epoch [151/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0044, val_mae: 0.0066\n",
      "Epoch [152/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0040\n",
      "Epoch [153/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0043, val_mae: 0.0059\n",
      "Epoch [154/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0050\n",
      "Epoch [155/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0046\n",
      "Epoch [156/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0041, val_mae: 0.0062\n",
      "Epoch [157/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0044, val_mae: 0.0062\n",
      "Epoch [158/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0036\n",
      "Epoch [159/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0042, val_mae: 0.0061\n",
      "Epoch [160/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0042, val_mae: 0.0055\n",
      "Epoch [161/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0047\n",
      "Epoch [162/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0041\n",
      "Epoch [163/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0040\n",
      "Epoch [164/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0042, val_mae: 0.0055\n",
      "Epoch [165/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0042\n",
      "Epoch [166/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0040\n",
      "Epoch [167/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0041\n",
      "Epoch [168/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0040\n",
      "Epoch [169/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0063\n",
      "Epoch [170/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0035\n",
      "Epoch [171/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0051\n",
      "Epoch [172/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0042\n",
      "Epoch [173/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0048\n",
      "Epoch [174/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0049\n",
      "Epoch [175/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0043, val_mae: 0.0036\n",
      "Epoch [176/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0044\n",
      "Epoch [177/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0042\n",
      "Epoch [178/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0038\n",
      "Epoch [179/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0040, val_mae: 0.0064\n",
      "Epoch [180/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0041\n",
      "Epoch [181/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0039, val_mae: 0.0068\n",
      "Epoch [182/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0042, val_mae: 0.0045\n",
      "Epoch [183/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0042\n",
      "Epoch [184/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0043\n",
      "Epoch [185/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0040, val_mae: 0.0061\n",
      "Epoch [186/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0048\n",
      "Epoch [187/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0040\n",
      "Epoch [188/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0039\n",
      "Epoch [189/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0038\n",
      "Epoch [190/1000] - train_loss: 0.0000, val_loss: 0.0002, train_mae: 0.0039, val_mae: 0.0101\n",
      "Epoch [191/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0059\n",
      "Epoch [192/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0047\n",
      "Epoch [193/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0048\n",
      "Epoch [194/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0052\n",
      "Epoch [195/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0038\n",
      "Epoch [196/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0041, val_mae: 0.0050\n",
      "Epoch [197/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0048\n",
      "Epoch [198/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0038\n",
      "Epoch [199/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0040\n",
      "Epoch [200/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0039\n",
      "Epoch [201/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0044\n",
      "Epoch [202/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0032\n",
      "Epoch [203/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0044\n",
      "Epoch [204/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0040, val_mae: 0.0035\n",
      "Epoch [205/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0044\n",
      "Epoch [206/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0043\n",
      "Epoch [207/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0050\n",
      "Epoch [208/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0045\n",
      "Epoch [209/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0035\n",
      "Epoch [210/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0035\n",
      "Epoch [211/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0036\n",
      "Epoch [212/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0038, val_mae: 0.0046\n",
      "Epoch [213/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0055\n",
      "Epoch [214/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0051\n",
      "Epoch [215/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0038\n",
      "Epoch [216/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0045\n",
      "Epoch [217/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0037\n",
      "Epoch [218/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0044\n",
      "Epoch [219/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0037\n",
      "Epoch [220/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0038\n",
      "Epoch [221/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0038, val_mae: 0.0055\n",
      "Epoch [222/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0038\n",
      "Epoch [223/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0045\n",
      "Epoch [224/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0042\n",
      "Epoch [225/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0049\n",
      "Epoch [226/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0057\n",
      "Epoch [227/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0039\n",
      "Epoch [228/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0042\n",
      "Epoch [229/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0041\n",
      "Epoch [230/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0033, val_mae: 0.0055\n",
      "Epoch [231/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0045\n",
      "Epoch [232/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0037\n",
      "Epoch [233/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0047\n",
      "Epoch [234/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0037, val_mae: 0.0042\n",
      "Epoch [235/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0041\n",
      "Epoch [236/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0034\n",
      "Epoch [237/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0047\n",
      "Epoch [238/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0037\n",
      "Epoch [239/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0037\n",
      "Epoch [240/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0033\n",
      "Epoch [241/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0036\n",
      "Epoch [242/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0039, val_mae: 0.0042\n",
      "Epoch [243/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0035\n",
      "Epoch [244/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0033, val_mae: 0.0059\n",
      "Epoch [245/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0040\n",
      "Epoch [246/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0036\n",
      "Epoch [247/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0033, val_mae: 0.0059\n",
      "Epoch [248/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0041\n",
      "Epoch [249/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0037\n",
      "Epoch [250/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0039\n",
      "Epoch [251/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0049\n",
      "Epoch [252/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0037\n",
      "Epoch [253/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0052\n",
      "Epoch [254/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0034, val_mae: 0.0077\n",
      "Epoch [255/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0033, val_mae: 0.0079\n",
      "Epoch [256/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0036, val_mae: 0.0045\n",
      "Epoch [257/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0036\n",
      "Epoch [258/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0044\n",
      "Epoch [259/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0041\n",
      "Epoch [260/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0034\n",
      "Epoch [261/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0040\n",
      "Epoch [262/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0033\n",
      "Epoch [263/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0034, val_mae: 0.0067\n",
      "Epoch [264/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0035\n",
      "Epoch [265/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0049\n",
      "Epoch [266/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0033\n",
      "Epoch [267/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0033\n",
      "Epoch [268/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0039\n",
      "Epoch [269/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0036\n",
      "Epoch [270/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0035\n",
      "Epoch [271/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0035\n",
      "Epoch [272/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0050\n",
      "Epoch [273/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0043\n",
      "Epoch [274/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0036\n",
      "Epoch [275/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0034\n",
      "Epoch [276/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0044\n",
      "Epoch [277/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0046\n",
      "Epoch [278/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0045\n",
      "Epoch [279/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0038\n",
      "Epoch [280/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0041\n",
      "Epoch [281/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0040\n",
      "Epoch [282/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0036\n",
      "Epoch [283/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0034\n",
      "Epoch [284/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0034\n",
      "Epoch [285/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0035\n",
      "Epoch [286/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0034\n",
      "Epoch [287/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0032, val_mae: 0.0076\n",
      "Epoch [288/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0037\n",
      "Epoch [289/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0036\n",
      "Epoch [290/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0042\n",
      "Epoch [291/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0032\n",
      "Epoch [292/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0035\n",
      "Epoch [293/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0040\n",
      "Epoch [294/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0057\n",
      "Epoch [295/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0049\n",
      "Epoch [296/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0032, val_mae: 0.0060\n",
      "Epoch [297/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0033, val_mae: 0.0065\n",
      "Epoch [298/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0043\n",
      "Epoch [299/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0036\n",
      "Epoch [300/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0038\n",
      "Epoch [301/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0035, val_mae: 0.0031\n",
      "Epoch [302/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0032\n",
      "Epoch [303/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0031, val_mae: 0.0058\n",
      "Epoch [304/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [305/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0034, val_mae: 0.0047\n",
      "Epoch [306/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0038\n",
      "Epoch [307/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0041\n",
      "Epoch [308/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0031, val_mae: 0.0058\n",
      "Epoch [309/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0036\n",
      "Epoch [310/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0035\n",
      "Epoch [311/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0032\n",
      "Epoch [312/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0035\n",
      "Epoch [313/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0031\n",
      "Epoch [314/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0042\n",
      "Epoch [315/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0040\n",
      "Epoch [316/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0032, val_mae: 0.0055\n",
      "Epoch [317/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0034\n",
      "Epoch [318/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0051\n",
      "Epoch [319/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0032\n",
      "Epoch [320/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0035\n",
      "Epoch [321/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0038\n",
      "Epoch [322/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0036\n",
      "Epoch [323/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0032\n",
      "Epoch [324/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0048\n",
      "Epoch [325/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0036\n",
      "Epoch [326/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0040\n",
      "Epoch [327/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0041\n",
      "Epoch [328/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0039\n",
      "Epoch [329/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0031\n",
      "Epoch [330/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0050\n",
      "Epoch [331/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0034\n",
      "Epoch [332/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0032\n",
      "Epoch [333/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0047\n",
      "Epoch [334/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0045\n",
      "Epoch [335/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0050\n",
      "Epoch [336/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0053\n",
      "Epoch [337/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0029\n",
      "Epoch [338/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0043\n",
      "Epoch [339/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0034\n",
      "Epoch [340/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0033, val_mae: 0.0045\n",
      "Epoch [341/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0033\n",
      "Epoch [342/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0039\n",
      "Epoch [343/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [344/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0031\n",
      "Epoch [345/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0038\n",
      "Epoch [346/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0039\n",
      "Epoch [347/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0032\n",
      "Epoch [348/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0038\n",
      "Epoch [349/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0045\n",
      "Epoch [350/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0039\n",
      "Epoch [351/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0039\n",
      "Epoch [352/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0032\n",
      "Epoch [353/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0036\n",
      "Epoch [354/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0033\n",
      "Epoch [355/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0039\n",
      "Epoch [356/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [357/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0031\n",
      "Epoch [358/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0033\n",
      "Epoch [359/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0035\n",
      "Epoch [360/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0032, val_mae: 0.0035\n",
      "Epoch [361/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0029, val_mae: 0.0058\n",
      "Epoch [362/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0054\n",
      "Epoch [363/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0041\n",
      "Epoch [364/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [365/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0038\n",
      "Epoch [366/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0032\n",
      "Epoch [367/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0037\n",
      "Epoch [368/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0032\n",
      "Epoch [369/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0032\n",
      "Epoch [370/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0031\n",
      "Epoch [371/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0038\n",
      "Epoch [372/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0043\n",
      "Epoch [373/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0032, val_mae: 0.0068\n",
      "Epoch [374/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0032\n",
      "Epoch [375/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0041\n",
      "Epoch [376/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0031, val_mae: 0.0056\n",
      "Epoch [377/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0038\n",
      "Epoch [378/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0034\n",
      "Epoch [379/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0031\n",
      "Epoch [380/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0043\n",
      "Epoch [381/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0041\n",
      "Epoch [382/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [383/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0038\n",
      "Epoch [384/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0048\n",
      "Epoch [385/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0031\n",
      "Epoch [386/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [387/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0039\n",
      "Epoch [388/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0033\n",
      "Epoch [389/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0037\n",
      "Epoch [390/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0030\n",
      "Epoch [391/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0045\n",
      "Epoch [392/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0030\n",
      "Epoch [393/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0038\n",
      "Epoch [394/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0033\n",
      "Epoch [395/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0035\n",
      "Epoch [396/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0035\n",
      "Epoch [397/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0035\n",
      "Epoch [398/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0033\n",
      "Epoch [399/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0033\n",
      "Epoch [400/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0038\n",
      "Epoch [401/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0032\n",
      "Epoch [402/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [403/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0031\n",
      "Epoch [404/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0031\n",
      "Epoch [405/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0032\n",
      "Epoch [406/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0038\n",
      "Epoch [407/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0044\n",
      "Epoch [408/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0031\n",
      "Epoch [409/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0034\n",
      "Epoch [410/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0030\n",
      "Epoch [411/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0038\n",
      "Epoch [412/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0036\n",
      "Epoch [413/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0033\n",
      "Epoch [414/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0037\n",
      "Epoch [415/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0031, val_mae: 0.0032\n",
      "Epoch [416/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0043\n",
      "Epoch [417/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0030\n",
      "Epoch [418/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0055\n",
      "Epoch [419/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0038\n",
      "Epoch [420/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0031\n",
      "Epoch [421/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0038\n",
      "Epoch [422/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0033\n",
      "Epoch [423/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0035\n",
      "Epoch [424/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [425/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0051\n",
      "Epoch [426/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0031\n",
      "Epoch [427/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0031\n",
      "Epoch [428/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0029, val_mae: 0.0060\n",
      "Epoch [429/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0037\n",
      "Epoch [430/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0049\n",
      "Epoch [431/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0040\n",
      "Epoch [432/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0030\n",
      "Epoch [433/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0036\n",
      "Epoch [434/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0038\n",
      "Epoch [435/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0036\n",
      "Epoch [436/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0029\n",
      "Epoch [437/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0031\n",
      "Epoch [438/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0038\n",
      "Epoch [439/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [440/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0034\n",
      "Epoch [441/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0038\n",
      "Epoch [442/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0030, val_mae: 0.0043\n",
      "Epoch [443/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0035\n",
      "Epoch [444/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [445/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0042\n",
      "Epoch [446/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0032\n",
      "Epoch [447/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0036\n",
      "Epoch [448/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0034\n",
      "Epoch [449/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0039\n",
      "Epoch [450/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0026, val_mae: 0.0053\n",
      "Epoch [451/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0033\n",
      "Epoch [452/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0039\n",
      "Epoch [453/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [454/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0043\n",
      "Epoch [455/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0029\n",
      "Epoch [456/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0037\n",
      "Epoch [457/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0045\n",
      "Epoch [458/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0046\n",
      "Epoch [459/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0041\n",
      "Epoch [460/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0046\n",
      "Epoch [461/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0034\n",
      "Epoch [462/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0032\n",
      "Epoch [463/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0042\n",
      "Epoch [464/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0033\n",
      "Epoch [465/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0033\n",
      "Epoch [466/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0038\n",
      "Epoch [467/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0055\n",
      "Epoch [468/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0031\n",
      "Epoch [469/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0032\n",
      "Epoch [470/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0035\n",
      "Epoch [471/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [472/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0055\n",
      "Epoch [473/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0035\n",
      "Epoch [474/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0029\n",
      "Epoch [475/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0043\n",
      "Epoch [476/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0043\n",
      "Epoch [477/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0055\n",
      "Epoch [478/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0031\n",
      "Epoch [479/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0033\n",
      "Epoch [480/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0031\n",
      "Epoch [481/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [482/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0048\n",
      "Epoch [483/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0028\n",
      "Epoch [484/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0033\n",
      "Epoch [485/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0033\n",
      "Epoch [486/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0033\n",
      "Epoch [487/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0041\n",
      "Epoch [488/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0034\n",
      "Epoch [489/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0034\n",
      "Epoch [490/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0041\n",
      "Epoch [491/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0037\n",
      "Epoch [492/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0035\n",
      "Epoch [493/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0035\n",
      "Epoch [494/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0041\n",
      "Epoch [495/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0035\n",
      "Epoch [496/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0046\n",
      "Epoch [497/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0030\n",
      "Epoch [498/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0038\n",
      "Epoch [499/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0033\n",
      "Epoch [500/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [501/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0037\n",
      "Epoch [502/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0037\n",
      "Epoch [503/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0035\n",
      "Epoch [504/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0041\n",
      "Epoch [505/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0036\n",
      "Epoch [506/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0034\n",
      "Epoch [507/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0034\n",
      "Epoch [508/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0033\n",
      "Epoch [509/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0036\n",
      "Epoch [510/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0036\n",
      "Epoch [511/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0033\n",
      "Epoch [512/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0033\n",
      "Epoch [513/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0031\n",
      "Epoch [514/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0036\n",
      "Epoch [515/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0032\n",
      "Epoch [516/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0033\n",
      "Epoch [517/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0034\n",
      "Epoch [518/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0030\n",
      "Epoch [519/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0033\n",
      "Epoch [520/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0032\n",
      "Epoch [521/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0040\n",
      "Epoch [522/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0033\n",
      "Epoch [523/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [524/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0034\n",
      "Epoch [525/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0036\n",
      "Epoch [526/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0027\n",
      "Epoch [527/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0035\n",
      "Epoch [528/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0040\n",
      "Epoch [529/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0032\n",
      "Epoch [530/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0031\n",
      "Epoch [531/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0030\n",
      "Epoch [532/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0030\n",
      "Epoch [533/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0029, val_mae: 0.0033\n",
      "Epoch [534/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [535/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0035\n",
      "Epoch [536/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0045\n",
      "Epoch [537/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0032\n",
      "Epoch [538/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0028\n",
      "Epoch [539/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [540/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0033\n",
      "Epoch [541/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0042\n",
      "Epoch [542/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0034\n",
      "Epoch [543/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0031\n",
      "Epoch [544/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0036\n",
      "Epoch [545/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0038\n",
      "Epoch [546/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [547/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0034\n",
      "Epoch [548/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0030\n",
      "Epoch [549/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0047\n",
      "Epoch [550/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0034\n",
      "Epoch [551/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0031\n",
      "Epoch [552/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0037\n",
      "Epoch [553/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0034\n",
      "Epoch [554/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0031\n",
      "Epoch [555/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0029\n",
      "Epoch [556/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0033\n",
      "Epoch [557/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0030\n",
      "Epoch [558/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0038\n",
      "Epoch [559/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0040\n",
      "Epoch [560/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0032\n",
      "Epoch [561/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0030\n",
      "Epoch [562/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0031\n",
      "Epoch [563/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0035\n",
      "Epoch [564/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0032\n",
      "Epoch [565/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0032\n",
      "Epoch [566/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0030\n",
      "Epoch [567/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0035\n",
      "Epoch [568/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0028\n",
      "Epoch [569/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0030\n",
      "Epoch [570/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0039\n",
      "Epoch [571/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0029\n",
      "Epoch [572/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0034\n",
      "Epoch [573/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0038\n",
      "Epoch [574/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0029\n",
      "Epoch [575/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0035\n",
      "Epoch [576/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0026\n",
      "Epoch [577/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0029\n",
      "Epoch [578/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0032\n",
      "Epoch [579/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0033\n",
      "Epoch [580/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0034\n",
      "Epoch [581/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0035\n",
      "Epoch [582/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0034\n",
      "Epoch [583/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0034\n",
      "Epoch [584/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0033\n",
      "Epoch [585/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0032\n",
      "Epoch [586/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0033\n",
      "Epoch [587/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0040\n",
      "Epoch [588/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0027\n",
      "Epoch [589/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0032\n",
      "Epoch [590/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0038\n",
      "Epoch [591/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [592/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0030\n",
      "Epoch [593/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0035\n",
      "Epoch [594/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0030\n",
      "Epoch [595/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0048\n",
      "Epoch [596/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0030\n",
      "Epoch [597/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0039\n",
      "Epoch [598/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0028\n",
      "Epoch [599/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0039\n",
      "Epoch [600/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0039\n",
      "Epoch [601/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0032\n",
      "Epoch [602/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0037\n",
      "Epoch [603/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0031\n",
      "Epoch [604/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0028\n",
      "Epoch [605/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [606/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0026, val_mae: 0.0071\n",
      "Epoch [607/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0032\n",
      "Epoch [608/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0033\n",
      "Epoch [609/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0028, val_mae: 0.0036\n",
      "Epoch [610/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0029\n",
      "Epoch [611/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0036\n",
      "Epoch [612/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0036\n",
      "Epoch [613/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0033\n",
      "Epoch [614/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0028\n",
      "Epoch [615/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0028\n",
      "Epoch [616/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [617/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0035\n",
      "Epoch [618/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0032\n",
      "Epoch [619/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0028\n",
      "Epoch [620/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0036\n",
      "Epoch [621/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0038\n",
      "Epoch [622/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0035\n",
      "Epoch [623/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0029\n",
      "Epoch [624/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0032\n",
      "Epoch [625/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0034\n",
      "Epoch [626/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0041\n",
      "Epoch [627/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0028\n",
      "Epoch [628/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0027, val_mae: 0.0032\n",
      "Epoch [629/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0032\n",
      "Epoch [630/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0029\n",
      "Epoch [631/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [632/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0029\n",
      "Epoch [633/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0028\n",
      "Epoch [634/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0034\n",
      "Epoch [635/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [636/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0032\n",
      "Epoch [637/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0037\n",
      "Epoch [638/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0046\n",
      "Epoch [639/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0039\n",
      "Epoch [640/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0032\n",
      "Epoch [641/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [642/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0027\n",
      "Epoch [643/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0030\n",
      "Epoch [644/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0046\n",
      "Epoch [645/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0032\n",
      "Epoch [646/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0029\n",
      "Epoch [647/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [648/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [649/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0030\n",
      "Epoch [650/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [651/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0034\n",
      "Epoch [652/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0041\n",
      "Epoch [653/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [654/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0035\n",
      "Epoch [655/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0035\n",
      "Epoch [656/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0030\n",
      "Epoch [657/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0028\n",
      "Epoch [658/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0027\n",
      "Epoch [659/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0036\n",
      "Epoch [660/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0033\n",
      "Epoch [661/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0036\n",
      "Epoch [662/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0031\n",
      "Epoch [663/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0030\n",
      "Epoch [664/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0047\n",
      "Epoch [665/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0032\n",
      "Epoch [666/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0038\n",
      "Epoch [667/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0030\n",
      "Epoch [668/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0030\n",
      "Epoch [669/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0027\n",
      "Epoch [670/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0030\n",
      "Epoch [671/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0039\n",
      "Epoch [672/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0031\n",
      "Epoch [673/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [674/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0054\n",
      "Epoch [675/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0030\n",
      "Epoch [676/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [677/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0027\n",
      "Epoch [678/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0034\n",
      "Epoch [679/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0028\n",
      "Epoch [680/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0028\n",
      "Epoch [681/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0028\n",
      "Epoch [682/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0041\n",
      "Epoch [683/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [684/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0039\n",
      "Epoch [685/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0033\n",
      "Epoch [686/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0033\n",
      "Epoch [687/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0027\n",
      "Epoch [688/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [689/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0027\n",
      "Epoch [690/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0036\n",
      "Epoch [691/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0032\n",
      "Epoch [692/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0037\n",
      "Epoch [693/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0036\n",
      "Epoch [694/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0035\n",
      "Epoch [695/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0024, val_mae: 0.0088\n",
      "Epoch [696/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0033\n",
      "Epoch [697/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0031\n",
      "Epoch [698/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [699/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0028\n",
      "Epoch [700/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0032\n",
      "Epoch [701/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0032\n",
      "Epoch [702/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [703/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0032\n",
      "Epoch [704/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0028\n",
      "Epoch [705/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0027\n",
      "Epoch [706/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [707/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0033\n",
      "Epoch [708/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0042\n",
      "Epoch [709/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0028\n",
      "Epoch [710/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0028\n",
      "Epoch [711/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0032\n",
      "Epoch [712/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0031\n",
      "Epoch [713/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0036\n",
      "Epoch [714/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0028\n",
      "Epoch [715/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0033\n",
      "Epoch [716/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [717/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0028\n",
      "Epoch [718/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0029\n",
      "Epoch [719/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0041\n",
      "Epoch [720/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0028\n",
      "Epoch [721/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0031\n",
      "Epoch [722/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0035\n",
      "Epoch [723/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0026, val_mae: 0.0031\n",
      "Epoch [724/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0029\n",
      "Epoch [725/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0028\n",
      "Epoch [726/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0034\n",
      "Epoch [727/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0040\n",
      "Epoch [728/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0029\n",
      "Epoch [729/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0029\n",
      "Epoch [730/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0028\n",
      "Epoch [731/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0031\n",
      "Epoch [732/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0043\n",
      "Epoch [733/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0036\n",
      "Epoch [734/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0031\n",
      "Epoch [735/1000] - train_loss: 0.0000, val_loss: 0.0001, train_mae: 0.0024, val_mae: 0.0063\n",
      "Epoch [736/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0031\n",
      "Epoch [737/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0034\n",
      "Epoch [738/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0027\n",
      "Epoch [739/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0039\n",
      "Epoch [740/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0039\n",
      "Epoch [741/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0027\n",
      "Epoch [742/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0032\n",
      "Epoch [743/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0029\n",
      "Epoch [744/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0030\n",
      "Epoch [745/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [746/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0029\n",
      "Epoch [747/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0030\n",
      "Epoch [748/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0032\n",
      "Epoch [749/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0037\n",
      "Epoch [750/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0046\n",
      "Epoch [751/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [752/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0048\n",
      "Epoch [753/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0034\n",
      "Epoch [754/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [755/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0035\n",
      "Epoch [756/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0042\n",
      "Epoch [757/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0035\n",
      "Epoch [758/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0025, val_mae: 0.0036\n",
      "Epoch [759/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0029\n",
      "Epoch [760/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0032\n",
      "Epoch [761/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0028\n",
      "Epoch [762/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0033\n",
      "Epoch [763/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0039\n",
      "Epoch [764/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0029\n",
      "Epoch [765/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0028\n",
      "Epoch [766/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0028\n",
      "Epoch [767/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0034\n",
      "Epoch [768/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0039\n",
      "Epoch [769/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0032\n",
      "Epoch [770/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0028\n",
      "Epoch [771/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0038\n",
      "Epoch [772/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0037\n",
      "Epoch [773/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0036\n",
      "Epoch [774/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0022, val_mae: 0.0027\n",
      "Epoch [775/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0024, val_mae: 0.0033\n",
      "Epoch [776/1000] - train_loss: 0.0000, val_loss: 0.0000, train_mae: 0.0023, val_mae: 0.0037\n",
      "Stopping early (patience of {patience} reached)\n",
      "Training completed\n"
     ]
    }
   ],
   "source": [
    "train_losses_large2, val_losses_large2, train_maes_large2, val_maes_large2, best_state_large2 = train_loop(net_largesf2, train_dataloader, val_dataloader, patience=200, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs_large2 = len(train_losses_large2)\n",
    "\n",
    "plt.plot(range(1, num_epochs_large2+1), train_losses_large2, label=\"train_loss_large2\", color='blue')\n",
    "plt.plot(range(1, num_epochs_large2+1), val_losses_large2, label=\"val_loss_large2\", color='blue', linestyle='--')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs_large2 = len(train_losses_large2)\n",
    "\n",
    "plt.plot(range(1, num_epochs_large2+1), train_maes_large2, label=\"train_maes_large2\", color='blue')\n",
    "plt.plot(range(1, num_epochs_large2+1), val_maes_large2, label=\"val_maes_large2\", color='blue', linestyle='--')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "netnames = ['net_large', 'net1x30sf', 'net2x30sf', 'net3x30sf', 'net6x50sf', 'net_largesf']\n",
    "for i, (netname, tl, vl) in enumerate(zip(netnames, train_losses_list, val_losses_list)):\n",
    "    num_epochs = len(tl)\n",
    "    color = f\"C{i}\"\n",
    "    plt.plot(range(1, num_epochs+1), tl, label=f\"train_loss_{netname}\", color=color)\n",
    "    plt.plot(range(1, num_epochs+1), vl, label=f\"val_loss_{netname}\", color=color, linestyle='--')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs1x30 = len(train_losses1x30)\n",
    "num_epochs2x30 = len(train_losses2x30)\n",
    "num_epochs3x30 = len(train_losses3x30)\n",
    "num_epochs6x50 = len(train_losses6x50)\n",
    "\n",
    "num_epochs1x30sf = len(train_losses_list[1])\n",
    "num_epochs2x30sf = len(train_losses_list[2])\n",
    "num_epochs3x30sf = len(train_losses_list[3])\n",
    "num_epochs6x50sf = len(train_losses_list[4])\n",
    "\n",
    "plt.plot(range(1, num_epochs1x30+1), train_losses1x30, label=\"train_loss1x30\", color='blue')\n",
    "plt.plot(range(1, num_epochs1x30+1), val_losses1x30, color='blue', linestyle='--')\n",
    "plt.plot(range(1, num_epochs1x30sf+1), train_losses_list[1], label=\"train_loss1x30sf\", color='blue', alpha=0.5)\n",
    "plt.plot(range(1, num_epochs1x30sf+1), val_losses_list[1], color='blue', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.plot(range(1, num_epochs2x30+1), train_losses2x30, label=\"train_loss2x30\", color='orange')\n",
    "plt.plot(range(1, num_epochs2x30+1), val_losses2x30, color='orange', linestyle='--')\n",
    "plt.plot(range(1, num_epochs2x30sf+1), train_losses_list[2], label=\"train_loss2x30sf\", color='orange', alpha=0.5)\n",
    "plt.plot(range(1, num_epochs2x30sf+1), val_losses_list[2], color='orange', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.plot(range(1, num_epochs3x30+1), train_losses3x30, label=\"train_loss3x30\", color='red')\n",
    "plt.plot(range(1, num_epochs3x30+1), val_losses3x30, color='red', linestyle='--')\n",
    "plt.plot(range(1, num_epochs3x30sf+1), train_losses_list[3], label=\"train_loss3x30sf\", color='red', alpha=0.5)\n",
    "plt.plot(range(1, num_epochs3x30sf+1), val_losses_list[3], color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.plot(range(1, num_epochs6x50+1), train_losses6x50, label=\"train_loss6x50\", color='green')\n",
    "plt.plot(range(1, num_epochs6x50+1), val_losses6x50, color='green', linestyle='--')\n",
    "plt.plot(range(1, num_epochs6x50sf+1), train_losses_list[4], label=\"train_loss6x50sf\", color='green', alpha=0.5)\n",
    "plt.plot(range(1, num_epochs6x50sf+1), val_losses_list[4], color='green', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, num_epochs1x30+1), train_maes1x30, label=\"train_mae1x30\", color='blue')\n",
    "plt.plot(range(1, num_epochs1x30+1), val_maes1x30, label=\"val_mae1x30\", color='blue', linestyle='--')\n",
    "\n",
    "plt.plot(range(1, num_epochs2x30+1), train_maes2x30, label=\"train_mae2x30\", color='orange')\n",
    "plt.plot(range(1, num_epochs2x30+1), val_maes2x30, label=\"val_mae2x30\", color='orange', linestyle='--')\n",
    "\n",
    "plt.plot(range(1, num_epochs3x30+1), train_maes3x30, label=\"train_mae3x30\", color='red')\n",
    "plt.plot(range(1, num_epochs3x30+1), val_maes3x30, label=\"val_mae3x30\", color='red', linestyle='--')\n",
    "\n",
    "plt.plot(range(1, num_epochs6x50+1), train_maes6x50, label=\"train_mae6x50\", color='green')\n",
    "plt.plot(range(1, num_epochs6x50+1), val_maes6x50, label=\"val_mae6x50\", color='green', linestyle='--')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computes the difference y_true - y_hat for every sample in the given dataset\n",
    "\n",
    "args:\n",
    "    net - neural network\n",
    "    dloader - data loader for the dataset\n",
    "\"\"\"\n",
    "def loss_histogram_data(net, dloader):\n",
    "    all_diffs = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dloader:\n",
    "            y_hat = net(batch_X)\n",
    "            all_diffs.append(batch_y - y_hat)\n",
    "\n",
    "    all_diffs = torch.cat(all_diffs).view(-1).numpy()\n",
    "    return all_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net1x30_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net1x30_best.load_state_dict(best_state1x30)\n",
    "\n",
    "net1x30sf_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net1x30sf_best.load_state_dict(best_states_list[1])\n",
    "\n",
    "diffs_1x30sf = loss_histogram_data(net1x30sf_best, val_dataloader)\n",
    "diffs_1x30   = loss_histogram_data(net1x30_best,   val_dataloader)\n",
    "\n",
    "n_bins = 30\n",
    "plt.hist(diffs_1x30sf, bins=n_bins, label=\"1x30sf\", alpha=0.5)\n",
    "plt.hist(diffs_1x30, bins=n_bins, label='1x30', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net2x30_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net2x30_best.load_state_dict(best_state2x30)\n",
    "\n",
    "net2x30sf_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net2x30sf_best.load_state_dict(best_states_list[2])\n",
    "\n",
    "diffs_2x30sf = loss_histogram_data(net2x30sf_best, val_dataloader)\n",
    "diffs_2x30   = loss_histogram_data(net2x30_best,   val_dataloader)\n",
    "\n",
    "n_bins = 30\n",
    "plt.hist(diffs_2x30sf, bins=n_bins, label=\"2x30sf\", alpha=0.5)\n",
    "plt.hist(diffs_2x30, bins=n_bins, label='2x30', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net3x30_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), torch.nn.ReLU(),  torch.nn.Linear(30, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net3x30_best.load_state_dict(best_state3x30)\n",
    "\n",
    "net3x30sf_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 30), torch.nn.ReLU(), torch.nn.Linear(30, 30), torch.nn.ReLU(),  torch.nn.Linear(30, 30), torch.nn.ReLU(), torch.nn.Linear(30, 1))\n",
    "net3x30sf_best.load_state_dict(best_states_list[3])\n",
    "\n",
    "diffs_3x30sf = loss_histogram_data(net3x30sf_best, val_dataloader)\n",
    "diffs_3x30   = loss_histogram_data(net3x30_best,   val_dataloader)\n",
    "\n",
    "n_bins = 30\n",
    "plt.hist(diffs_3x30sf, bins=n_bins, label=\"3x30sf\", alpha=0.5)\n",
    "plt.hist(diffs_3x30, bins=n_bins, label='3x30', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net6x50_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 1))\n",
    "net6x50_best.load_state_dict(best_state6x50)\n",
    "\n",
    "net6x50sf_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 50), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(50, 1))\n",
    "net6x50sf_best.load_state_dict(best_states_list[4])\n",
    "\n",
    "diffs_6x50sf = loss_histogram_data(net6x50sf_best, val_dataloader)\n",
    "diffs_6x50   = loss_histogram_data(net6x50_best,   val_dataloader)\n",
    "\n",
    "n_bins = 30\n",
    "plt.hist(diffs_6x50sf, bins=n_bins, label=\"6x50sf\", alpha=0.5)\n",
    "plt.hist(diffs_6x50, bins=n_bins, label='6x50', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net_large_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 1000), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(1000, 500), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(500, 250), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(250, 125), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(125, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 1))\n",
    "net_large_best.load_state_dict(best_states_list[0])\n",
    "\n",
    "net_large_long_best = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(3*2*2, 1000), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(1000, 500), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(500, 250), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(250, 125), torch.nn.ReLU(), \n",
    "                              torch.nn.Linear(125, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 30), torch.nn.ReLU(),\n",
    "                              torch.nn.Linear(30, 1))\n",
    "net_large_long_best.load_state_dict(best_state_large2)\n",
    "\n",
    "diffs_large_long = loss_histogram_data(net_large_long_best, val_dataloader)\n",
    "diffs_large      = loss_histogram_data(net_large_best,   val_dataloader)\n",
    "\n",
    "n_bins = 30\n",
    "plt.hist(diffs_large_long, bins=n_bins, label=\"large long\", alpha=0.5)\n",
    "plt.hist(diffs_large, bins=n_bins, label='large', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Format\n",
    "\n",
    "Each input consists of a $2\\times 2$ tensor of `(l, u, alpha)`.\n",
    "\n",
    "In the first layer of the neural network, this input is flattened.\n",
    "I.e. we now have a flat array of `[l1, ..., l4, u1, ..., u4, alpha1, ..., alpha4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.7138, 0.2893],\n",
       "          [0.5006, 0.1497]],\n",
       " \n",
       "         [[0.9137, 0.3436],\n",
       "          [0.7011, 0.7816]],\n",
       " \n",
       "         [[0.5361, 0.0492],\n",
       "          [0.3276, 0.7446]]]),\n",
       " tensor([0.1342]))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7138, 0.2893, 0.5006, 0.1497, 0.9137, 0.3436, 0.7011, 0.7816, 0.5361,\n",
       "        0.0492, 0.3276, 0.7446])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0][0].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blablubb'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'bla' + 'blubb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 2, 2)\n",
    "\n",
    "models = [net1x30sf_best, net2x30sf_best, net6x50_best]\n",
    "onnx_files = ['net1x30_best.onnx', 'net2x30_best.onnx', 'net6x50_best.onnx']\n",
    "\n",
    "for model, filename in zip(models, onnx_files):\n",
    "    torch.onnx.export(model, dummy_input, './models/' + filename, export_params=True, do_constant_folding=True, input_names=['X'], output_names=['Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abcrown-fork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
